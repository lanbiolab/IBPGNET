{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "random.seed(555)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pathways process and network generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the pathway feature generated by GCN\n",
    "pathway_feature = pd.read_csv('./data/Pathways_Feature.csv',index_col =0)\n",
    "\n",
    "#pathway data loading\n",
    "data = pd.read_csv('./data/ReactomePathwaysRelation_new_download.txt',sep = '\\t',header=None)\n",
    "\n",
    "data.columns = ['child','parent']\n",
    "human_hierarchy = data[data['child'].str.contains('HSA')]  \n",
    "\n",
    "# construct pathway graph\n",
    "net = nx.from_pandas_edgelist(human_hierarchy, 'child', 'parent', create_using=nx.DiGraph()) \n",
    "net.name = 'reactome'\n",
    "\n",
    "roots = [n for n, d in net.in_degree() if d == 0]  \n",
    "root_node = 'root'\n",
    "edges = [(root_node, n) for n in roots] \n",
    "net.add_edges_from(edges)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the node of the current layer\n",
    "def get_nodes_at_level(net, distance):\n",
    "    nodes = set(nx.ego_graph(net, 'root', radius=distance))\n",
    "    if distance >= 1.:\n",
    "        nodes -= set(nx.ego_graph(net, 'root', radius=distance - 1))\n",
    "    return list(nodes)\n",
    "\n",
    "def get_nodes(net,num):\n",
    "    net_nodes = [] \n",
    "    \n",
    "    for i in range(1,num+1):\n",
    "        net_nodes.append(get_nodes_at_level(net,i))\n",
    "        \n",
    "    return net_nodes\n",
    "\n",
    "#  define network size. for example,this network is five layer\n",
    "net_num = 5\n",
    "net_nodes = get_nodes(net,net_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read the connection of a single node to the next layer\n",
    "def add_node(net,net_nodes):\n",
    "        \n",
    "    for i in range(len(net_nodes)-2,-1,-1):\n",
    "        \n",
    "        data_temp = copy.deepcopy(net_nodes[i])\n",
    "        \n",
    "        for n in net_nodes[i]:\n",
    "            nexts = net.successors(n)         \n",
    "            temp = [ nex  for nex in nexts ] \n",
    "            if len(temp)==0:\n",
    "                data_temp.remove(n)  # If the node of the current layer has no successor node, remove the node\n",
    "            elif len(set(temp).intersection(set(net_nodes[i+1])))==0:   #if the subsequent node of the node of the current layer is not on the next layer, delete the node\n",
    "                data_temp.remove(n)\n",
    "            else:\n",
    "                continue\n",
    "        net_nodes[i] = data_temp\n",
    "    return net_nodes\n",
    "\n",
    "net_nodes  =  add_node(net,net_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_note_relation(net_nodes):\n",
    "    node_mat = []\n",
    "   \n",
    "    for i in range(len(net_nodes)-1):\n",
    "        dicts = {}\n",
    "        for n in net_nodes[i]:\n",
    "            nexts = net.successors(n)  \n",
    "            x = [ nex   for nex in nexts if nex in net_nodes[i+1] ]\n",
    "            dicts[n] = x\n",
    "\n",
    "        mat = np.zeros((len(net_nodes[i]), len(net_nodes[i+1]))) \n",
    "        for p, gs in dicts.items():     \n",
    "            g_inds = [net_nodes[i+1].index(g) for g in gs]\n",
    "            p_ind = net_nodes[i].index(p)\n",
    "            mat[p_ind, g_inds] = 1\n",
    "\n",
    "        df = pd.DataFrame(mat, index=net_nodes[i], columns=net_nodes[i+1])\n",
    "        node_mat.append(df.T)\n",
    "    return node_mat\n",
    "\n",
    "Get_Node_relation = get_note_relation(net_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link prediction only for adjacent pathways\n",
    "for k in range(0,4):\n",
    "    for col in Get_Node_relation[k].columns:\n",
    "        if col in list(pathway_feature.index):\n",
    "            for row in Get_Node_relation[k].index:\n",
    "                if row in list(pathway_feature.index):\n",
    "                    pos_c = pathway_feature.loc[col].values\n",
    "                    pos_r = pathway_feature.loc[row].values\n",
    "                    score = sigmoid(pos_c.dot(pos_r))\n",
    "\n",
    "                    if score >0.9:  #The similarity is greater than 0.9\n",
    "                        Get_Node_relation[k][col][row] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1745)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Get_Node_relation[3].values.nonzero()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read gene-pathway annotation relationships\n",
    "import re\n",
    "def load_data_dict(filename):\n",
    "\n",
    "    data_dict_list = []\n",
    "    dict = {}\n",
    "    with open( filename) as gmt:\n",
    "        data_list = gmt.readlines()\n",
    "\n",
    "        # print data_list[0]\n",
    "        for row in data_list:\n",
    "            genes = row.split('\\t')\n",
    "            \n",
    "            genes = [ i.replace('\\n','') for i in genes]\n",
    "            dict[genes[1]] = genes[3:]\n",
    "\n",
    "    return dict\n",
    "\n",
    "gene_data = load_data_dict('./data/ReactomePathways.gmt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data preprocessing and multi omics data intergration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading snv data\n",
    "snv_data = pd.read_csv(\"./data/TCGA-LUAD.varscan2_snv.csv\",index_col = 0)\n",
    "\n",
    "\n",
    "#loading cnv data\n",
    "cnv_data = pd.read_csv(\"./data/TCGA-LUAD_cnv.csv\",index_col = 0)\n",
    "\n",
    "\n",
    "#loading label\n",
    "response  = pd.read_csv('./data/response_paper.csv',index_col=0)\n",
    "\n",
    "#Disrupted data set\n",
    "response = response.sample(frac=1)\n",
    "\n",
    "snv_data = snv_data.sample(frac=1)\n",
    "\n",
    "cnv_data = cnv_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split copy number variation data\n",
    "import copy\n",
    "cnv_amp = copy.deepcopy(cnv_data)\n",
    "\n",
    "#cnv_amp\n",
    "cnv_amp[cnv_amp <= 0] = 0.\n",
    "cnv_amp[cnv_amp > 0 ] = 1.\n",
    "\n",
    "#cnv_del\n",
    "cnv_data[cnv_data >= 0] = 0.\n",
    "cnv_data[cnv_data < 0 ] = 1.\n",
    "cnv_del = cnv_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 453943)\n",
      "(2, 317421)\n",
      "(2, 162637)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(cnv_amp.values.nonzero()).shape)\n",
    "print(np.array(cnv_data.values.nonzero()).shape)\n",
    "print(np.array(snv_data.values.nonzero()).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#snv\n",
    "tol_snv = snv_data.join(response,how='inner')\n",
    "model = SelectKBest(chi2, k=3000)\n",
    "x_data1 = model.fit_transform(tol_snv.values[:,0:-1],tol_snv.values[:,-1])\n",
    "fea = model.get_support()\n",
    "snv_data = snv_data.loc[:,fea]\n",
    "\n",
    "#cnv_amp\n",
    "tol_amp = cnv_amp.join(response,how='inner')\n",
    "model = SelectKBest(chi2, k=3000)\n",
    "x_data1 = model.fit_transform(tol_amp.values[:,0:-1],tol_amp.values[:,-1])\n",
    "fea = model.get_support()\n",
    "cnv_amp = cnv_amp.loc[:,fea]\n",
    "\n",
    "#cnv_del\n",
    "tol_del = cnv_del.join(response,how='inner')\n",
    "model = SelectKBest(chi2, k=3000)\n",
    "x_data1 = model.fit_transform(tol_del.values[:,0:-1],tol_del.values[:,-1])\n",
    "fea = model.get_support()\n",
    "cnv_del = cnv_del.loc[:,fea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 3000)\n",
      "(514, 3000)\n",
      "(514, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(snv_data.shape)\n",
    "print(cnv_amp.shape)\n",
    "print(cnv_del.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading Load pre-training data\n",
    "response = pd.read_csv('./data/response.csv',index_col = 0)\n",
    "snv_data = snv_data.loc[response.index]\n",
    "cnv_amp = cnv_amp.loc[response.index]\n",
    "cnv_del = cnv_del.loc[response.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "rows_list = []\n",
    "cols_list = []\n",
    "\n",
    "data_type_list =['snv_data','cnv_amp','cnv_del']\n",
    "\n",
    "for ind in [snv_data,cnv_amp,cnv_del]: \n",
    "    get_data = ind.join(response,how='inner')\n",
    "    del get_data['response']\n",
    "    \n",
    "    row = get_data.index      \n",
    "    col = get_data.columns     \n",
    "    resp = response.loc[row]   \n",
    "    \n",
    "    x_list.append(ind)\n",
    "    y_list.append(resp)\n",
    "    rows_list.append(row)\n",
    "    cols_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data set\n",
    "def combine(x_list, y_list, rows_list, cols_list, data_type_list, combine_type, use_coding_genes_only=True):\n",
    "    \n",
    "    cols_list_set = [set(list(c)) for c in cols_list]  \n",
    "    \n",
    "    print('cols_list_set',len(cols_list_set))\n",
    "\n",
    "    if combine_type == 'intersection':    \n",
    "        cols = set.intersection(*cols_list_set)\n",
    "    else:\n",
    "        cols = set.union(*cols_list_set) \n",
    "    \n",
    "    print('intersection_cols',len(cols))\n",
    "\n",
    "    if use_coding_genes_only: #true\n",
    "        coding_genes_df = pd.read_csv('./data/protein-coding_gene_with_coordinate_minimal.txt', sep='\\t', header=None)\n",
    "        coding_genes_df.columns = ['chr', 'start', 'end', 'name']\n",
    "        coding_genes = set(coding_genes_df['name'].unique())     \n",
    "        cols = cols.intersection(coding_genes)  \n",
    "        print('protein-coding_genes',len(coding_genes))\n",
    "   \n",
    "    print('finally_cols',len(cols))\n",
    "   \n",
    "    all_cols = list(cols)\n",
    "\n",
    "    all_cols_df = pd.DataFrame(index=all_cols) \n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for x, y, r, c in zip(x_list, y_list, rows_list, cols_list):\n",
    "        df = pd.DataFrame(x, columns=c, index=r)\n",
    "        df = df.T.join(all_cols_df, how='right')  \n",
    "        df = df.T\n",
    "        df = df.fillna(0)\n",
    "        df_list.append(df)\n",
    "\n",
    "    all_data = pd.concat(df_list, keys=data_type_list, join='inner', axis=1, )  \n",
    "\n",
    "   \n",
    "    all_data = all_data.swaplevel(i=0, j=1, axis=1)\n",
    "\n",
    "\n",
    "    order = all_data.columns.levels[0] \n",
    "\n",
    "    all_data = all_data.reindex(columns=order, level=0)  \n",
    "\n",
    "    x = all_data\n",
    "\n",
    "    reordering_df = pd.DataFrame(index=all_data.index)  \n",
    "    y = reordering_df.join(y, how='left')   \n",
    "\n",
    "    y = y.values   \n",
    "    cols = all_data.columns   \n",
    "    rows = all_data.index      \n",
    "    print(\n",
    "        'After combining, loaded data %d samples, %d variables, %d responses ' % (x.shape[0], x.shape[1], y.shape[0]))\n",
    "\n",
    "    return x, y, rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_list_set 3\n",
      "intersection_cols 7722\n",
      "protein-coding_genes 19045\n",
      "finally_cols 7034\n",
      "After combining, loaded data 505 samples, 21102 variables, 505 responses \n"
     ]
    }
   ],
   "source": [
    "x, y, rows, cols = combine(x_list, y_list, rows_list, cols_list, data_type_list, combine_type = 'union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TCGA-55-8206', 'TCGA-05-4382', 'TCGA-69-7761', 'TCGA-50-5944',\n",
       "       'TCGA-44-A479', 'TCGA-55-8620', 'TCGA-91-A4BC', 'TCGA-78-7536',\n",
       "       'TCGA-55-8087', 'TCGA-55-7907',\n",
       "       ...\n",
       "       'TCGA-71-6725', 'TCGA-44-8117', 'TCGA-91-8499', 'TCGA-73-4659',\n",
       "       'TCGA-75-6212', 'TCGA-97-8176', 'TCGA-86-8280', 'TCGA-55-6543',\n",
       "       'TCGA-50-6594', 'TCGA-38-4632'],\n",
       "      dtype='object', length=505)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotated relationships between genes and pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7034"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathways  = list(gene_data.keys())  \n",
    "pathway_union = list(set(Get_Node_relation[3].index).intersection(set(pathways)))\n",
    "\n",
    "print(len(pathway_union))\n",
    "Get_Node_relation[3] = Get_Node_relation[3].loc[pathway_union]\n",
    "\n",
    "union_gene = list(cols.levels[0])\n",
    "len(union_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_gene = np.zeros((len(pathway_union), len(union_gene))) \n",
    "\n",
    "for p  in pathway_union:\n",
    "    gs = gene_data[p]      \n",
    "    g_inds = [union_gene.index(g) for g in gs if g in union_gene]  \n",
    "    p_ind = pathway_union.index(p)\n",
    "    pathways_gene[p_ind, g_inds] = 1\n",
    "gene_pathway_df = pd.DataFrame(pathways_gene, index=pathway_union, columns=union_gene)\n",
    "\n",
    "\n",
    "#Drop genes that are not in the pathway\n",
    "gene_pathway_df = gene_pathway_df.loc[:, (gene_pathway_df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 1542)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMOX</th>\n",
       "      <th>DEFB106A</th>\n",
       "      <th>C1R</th>\n",
       "      <th>ST3GAL2</th>\n",
       "      <th>PDIA3</th>\n",
       "      <th>ESRP1</th>\n",
       "      <th>CTDNEP1</th>\n",
       "      <th>NET1</th>\n",
       "      <th>ACKR4</th>\n",
       "      <th>KIFC2</th>\n",
       "      <th>...</th>\n",
       "      <th>PRKAB1</th>\n",
       "      <th>SLC39A7</th>\n",
       "      <th>LAMTOR1</th>\n",
       "      <th>PLA2G4E</th>\n",
       "      <th>PRKAB2</th>\n",
       "      <th>NR1H3</th>\n",
       "      <th>KPNA7</th>\n",
       "      <th>LIN37</th>\n",
       "      <th>MYL12B</th>\n",
       "      <th>IDI1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-HSA-2465910</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-HSA-1483076</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-HSA-5218920</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-HSA-844456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-HSA-3656243</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1542 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SMOX  DEFB106A  C1R  ST3GAL2  PDIA3  ESRP1  CTDNEP1  NET1  \\\n",
       "R-HSA-2465910   0.0       0.0  0.0      0.0    0.0    0.0      0.0   0.0   \n",
       "R-HSA-1483076   0.0       0.0  0.0      0.0    0.0    0.0      0.0   0.0   \n",
       "R-HSA-5218920   0.0       0.0  0.0      0.0    0.0    0.0      0.0   0.0   \n",
       "R-HSA-844456    0.0       0.0  0.0      0.0    0.0    0.0      0.0   0.0   \n",
       "R-HSA-3656243   0.0       0.0  0.0      0.0    0.0    0.0      0.0   0.0   \n",
       "\n",
       "               ACKR4  KIFC2  ...  PRKAB1  SLC39A7  LAMTOR1  PLA2G4E  PRKAB2  \\\n",
       "R-HSA-2465910    0.0    0.0  ...     0.0      0.0      0.0      0.0     0.0   \n",
       "R-HSA-1483076    0.0    0.0  ...     0.0      0.0      0.0      0.0     0.0   \n",
       "R-HSA-5218920    0.0    0.0  ...     0.0      0.0      0.0      0.0     0.0   \n",
       "R-HSA-844456     0.0    0.0  ...     0.0      0.0      0.0      0.0     0.0   \n",
       "R-HSA-3656243    0.0    0.0  ...     0.0      0.0      0.0      0.0     0.0   \n",
       "\n",
       "               NR1H3  KPNA7  LIN37  MYL12B  IDI1  \n",
       "R-HSA-2465910    0.0    0.0    0.0     0.0   0.0  \n",
       "R-HSA-1483076    0.0    0.0    0.0     0.0   0.0  \n",
       "R-HSA-5218920    0.0    0.0    0.0     0.0   0.0  \n",
       "R-HSA-844456     0.0    0.0    0.0     0.0   0.0  \n",
       "R-HSA-3656243    0.0    0.0    0.0     0.0   0.0  \n",
       "\n",
       "[5 rows x 1542 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gene_pathway_df.shape)\n",
    "gene_pathway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505, 4626)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Omics_data = x[list(gene_pathway_df.columns)] \n",
    "Omics_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = gene_pathway_df.columns  \n",
    "mapp = gene_pathway_df.values          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, multiply\n",
    "from keras.regularizers import l2\n",
    "from keras import Input\n",
    "from keras.engine import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.engine import Layer\n",
    "# from keras import initializations\n",
    "from keras.initializers import glorot_uniform, Initializer\n",
    "from keras.layers import activations, initializers, constraints\n",
    "# our layer will take input shape (nb_samples, 1)\n",
    "from keras.regularizers import Regularizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M_Nets(Layer):   \n",
    "    def __init__(self, units, activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 W_regularizer=None,\n",
    "                 b_regularizer=None,\n",
    "                 **kwargs):\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.activation_fn = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.bias_regularize = regularizers.get(b_regularizer)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(W_regularizer)\n",
    "        \n",
    "        super(M_Nets, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):  \n",
    "\n",
    "        input_dimension = input_shape[1]\n",
    "        self.kernel_shape = (input_dimension, self.units)  \n",
    "        self.n_inputs_per_node = input_dimension / self.units\n",
    "\n",
    "        rows = np.arange(input_dimension) \n",
    "        cols = np.arange(self.units)    \n",
    "        cols = np.repeat(cols, self.n_inputs_per_node) \n",
    "        self.nonzero_ind = np.column_stack((rows, cols)) \n",
    "\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_dimension,),  \n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      trainable=True)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        trainable=True\n",
    "                                        \n",
    "                                       )\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        super(M_Nets, self).build(input_shape)  \n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        \n",
    "        n_features = x.shape[1]\n",
    "\n",
    "\n",
    "        kernel = K.reshape(self.kernel, (1, n_features))\n",
    "        mult = x * kernel\n",
    "        mult = K.reshape(mult, (-1, int(self.n_inputs_per_node)))\n",
    "        mult = K.sum(mult, axis=1)\n",
    "        output = K.reshape(mult, (-1, self.units))\n",
    "\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "        if self.activation_fn is not None:\n",
    "            output = self.activation_fn(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': self.activation,\n",
    "            'kernel_initializer' : self.kernel_initializer,\n",
    "            'bias_initializer' : self.bias_initializer,\n",
    "            'use_bias': self.use_bias\n",
    "        }\n",
    "        base_config = super(M_Nets, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nets(Layer):\n",
    "    def __init__(self, units, mapp=None, nonzero_ind=None, kernel_initializer='glorot_uniform', W_regularizer=None,\n",
    "                 activation='tanh', use_bias=True,bias_initializer='zeros', bias_regularizer=None,\n",
    "                 bias_constraint=None,**kwargs):\n",
    "        \n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.mapp = mapp\n",
    "        self.nonzero_ind = nonzero_ind\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(W_regularizer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activation_fn = activations.get(activation)\n",
    "        super(Nets, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        input_dim = input_shape[1]\n",
    "   \n",
    "\n",
    "        if not self.mapp is None:\n",
    "            self.mapp = self.mapp.astype(np.float32)\n",
    "\n",
    "   \n",
    "        if self.nonzero_ind is None:\n",
    "            nonzero_ind = np.array(np.nonzero(self.mapp)).T\n",
    "            self.nonzero_ind = nonzero_ind\n",
    "\n",
    "        self.kernel_shape = (input_dim, self.units)\n",
    "        \n",
    "\n",
    "        nonzero_count = self.nonzero_ind.shape[0]  \n",
    "\n",
    "\n",
    "        self.kernel_vector = self.add_weight(name='kernel_vector',\n",
    "                                             shape=(nonzero_count,),\n",
    "                                             initializer=self.kernel_initializer,\n",
    "                                             regularizer=self.kernel_regularizer,\n",
    "                                             trainable=True)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer\n",
    "                                        )\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        super(Nets, self).build(input_shape)  \n",
    "      \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        \n",
    "        temp_t = tf.scatter_nd(tf.constant(self.nonzero_ind, tf.int32), self.kernel_vector,\n",
    "                           tf.constant(list(self.kernel_shape)))\n",
    "    \n",
    "        output = K.dot(inputs, temp_t)\n",
    "        \n",
    "    \n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "            \n",
    "        if self.activation_fn is not None:\n",
    "            output = self.activation_fn(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': self.activation,\n",
    "            'use_bias': self.use_bias,\n",
    "            'nonzero_ind': np.array(self.nonzero_ind),\n",
    "          \n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'W_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "\n",
    "        }\n",
    "        base_config = super(Nets, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "      \n",
    "        return (input_shape[0], self.units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(Omics_data):\n",
    "    \n",
    "    S_inputs = Input(shape=(Omics_data.shape[1],), dtype='float32',name= 'inputs')\n",
    "\n",
    "    h_0 = M_Nets(cols.shape[0], activation='tanh',name='h_0')(S_inputs)\n",
    "    drop_layer1 =keras.layers.Dropout(0.5)(h_0)\n",
    "\n",
    "    h0 = Nets(gene_pathway_df.shape[0],mapp =gene_pathway_df.values.T, name = 'h0')(drop_layer1)\n",
    "    drop0 = keras.layers.Dropout(0.1)(h0)\n",
    "\n",
    "    h1 = Nets(Get_Node_relation[3].shape[1],mapp =Get_Node_relation[3].values ,name = 'h1')(drop0)\n",
    "    drop_h1 = keras.layers.Dropout(0.1)(h1)\n",
    "\n",
    "\n",
    "    h2 = Nets(Get_Node_relation[2].shape[1],mapp =Get_Node_relation[2].values, name = 'h2')(drop_h1)\n",
    "    drop2 = keras.layers.Dropout(0.1)(h2)\n",
    "\n",
    "\n",
    "    h3 = Nets(Get_Node_relation[1].shape[1],mapp =Get_Node_relation[1].values, name = 'h3')(drop2)\n",
    "    drop3 = keras.layers.Dropout(0.1)(h3)\n",
    "\n",
    "    \n",
    "    h4 = Nets(Get_Node_relation[0].shape[1],mapp =Get_Node_relation[0].values, name = 'h4')(drop3)\n",
    "    drop4 = keras.layers.Dropout(0.1)(h4)\n",
    "\n",
    "    Output = keras.layers.Dense(1,activation='sigmoid')(drop4)\n",
    "\n",
    "    model = Model(inputs=S_inputs, outputs=Output)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr = 0.001) #,decay=-0.0001 ,decay=0.001\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算auc\n",
    "# from lifelines.utils import concordance_index\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "   \n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "def evaluates(y_test, y_pred):\n",
    "    \n",
    "    auc = metrics.roc_auc_score(y_test,y_pred)\n",
    "    \n",
    "    aupr = average_precision_score(y_test, y_pred)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)    \n",
    "    auprc  = metrics.auc(recall, precision)\n",
    "    \n",
    "    pp = [1 if index>=0.5  else 0 for index in  y_pred ]\n",
    "    \n",
    "    pre = metrics.precision_score(y_test,pp)\n",
    "    \n",
    "    f1 = metrics.f1_score(y_test,pp)\n",
    "    \n",
    "    rec = metrics.recall_score(y_test,pp)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test,pp)\n",
    "    \n",
    "    print(confusion_matrix(y_test,pp))\n",
    "    \n",
    "    return pre,acc,rec,f1,auc,aupr,auprc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#梯度信息处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deepexplain.model_utils import get_layers, plot_history, get_coef_importance\n",
    "\n",
    "def get_coef_importances(model, X_train, y_train, target=-1, feature_importance='deepexplain_grad*input'):\n",
    "\n",
    "    coef_ = get_coef_importance(model, X_train, y_train, target, feature_importance, detailed=False)\n",
    "    return coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "def myScheduler(epoch):\n",
    "\n",
    "    if epoch % 150 == 0 and epoch != 0:\n",
    "\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "\n",
    "        K.set_value(model.optimizer.lr, lr * 0.5)\n",
    "    return K.get_value(model.optimizer.lr)\n",
    " \n",
    "myReduce_lr = LearningRateScheduler(myScheduler)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omics_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_355 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_356 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_357 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_358 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_359 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_360 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 25s 61ms/step - loss: 0.6200 - acc: 0.6955 - val_loss: 0.6624 - val_acc: 0.7426\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.6157 - acc: 0.7327 - val_loss: 0.6647 - val_acc: 0.7426\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.6141 - acc: 0.7327 - val_loss: 0.6533 - val_acc: 0.7426\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.6129 - acc: 0.7327 - val_loss: 0.6439 - val_acc: 0.7426\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6126 - acc: 0.7327 - val_loss: 0.6420 - val_acc: 0.7426\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6131 - acc: 0.7327 - val_loss: 0.6439 - val_acc: 0.7426\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6147 - acc: 0.7327 - val_loss: 0.6430 - val_acc: 0.7426\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6133 - acc: 0.7327 - val_loss: 0.6433 - val_acc: 0.7426\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6133 - acc: 0.7327 - val_loss: 0.6502 - val_acc: 0.7426\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6136 - acc: 0.7327 - val_loss: 0.6450 - val_acc: 0.7426\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6131 - acc: 0.7327 - val_loss: 0.6452 - val_acc: 0.7426\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6128 - acc: 0.7327 - val_loss: 0.6475 - val_acc: 0.7426\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6115 - acc: 0.7327 - val_loss: 0.6391 - val_acc: 0.7426\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6110 - acc: 0.7327 - val_loss: 0.6361 - val_acc: 0.7426\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6132 - acc: 0.7327 - val_loss: 0.6381 - val_acc: 0.7426\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6101 - acc: 0.7327 - val_loss: 0.6440 - val_acc: 0.7426\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6114 - acc: 0.7327 - val_loss: 0.6357 - val_acc: 0.7426\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6099 - acc: 0.7327 - val_loss: 0.6383 - val_acc: 0.7426\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6089 - acc: 0.7327 - val_loss: 0.6436 - val_acc: 0.7426\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6078 - acc: 0.7327 - val_loss: 0.6379 - val_acc: 0.7426\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6048 - acc: 0.7327 - val_loss: 0.6283 - val_acc: 0.7426\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5995 - acc: 0.7327 - val_loss: 0.6245 - val_acc: 0.7426\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5956 - acc: 0.7401 - val_loss: 0.6217 - val_acc: 0.7525\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5859 - acc: 0.7624 - val_loss: 0.6079 - val_acc: 0.7624\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5800 - acc: 0.7649 - val_loss: 0.6230 - val_acc: 0.8020\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5727 - acc: 0.7574 - val_loss: 0.5831 - val_acc: 0.7723\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5616 - acc: 0.7624 - val_loss: 0.6233 - val_acc: 0.6931\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5402 - acc: 0.7574 - val_loss: 0.5457 - val_acc: 0.8119\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5324 - acc: 0.6980 - val_loss: 0.5039 - val_acc: 0.7822\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5180 - acc: 0.7772 - val_loss: 0.5558 - val_acc: 0.7921\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4931 - acc: 0.7723 - val_loss: 0.4902 - val_acc: 0.8020\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5055 - acc: 0.7327 - val_loss: 0.4904 - val_acc: 0.8218\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4721 - acc: 0.7995 - val_loss: 0.4902 - val_acc: 0.8218\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4728 - acc: 0.7401 - val_loss: 0.4593 - val_acc: 0.8119\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4628 - acc: 0.7450 - val_loss: 0.5836 - val_acc: 0.6040\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4217 - acc: 0.7822 - val_loss: 0.4584 - val_acc: 0.8515\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4320 - acc: 0.7698 - val_loss: 0.5010 - val_acc: 0.7030\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4628 - acc: 0.7698 - val_loss: 0.5246 - val_acc: 0.6832\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4338 - acc: 0.8020 - val_loss: 0.6119 - val_acc: 0.6040\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4067 - acc: 0.7896 - val_loss: 0.4333 - val_acc: 0.8020\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4420 - acc: 0.7550 - val_loss: 0.4333 - val_acc: 0.8416\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4110 - acc: 0.8267 - val_loss: 0.5141 - val_acc: 0.7030\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4138 - acc: 0.7599 - val_loss: 0.4414 - val_acc: 0.8317\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3721 - acc: 0.7946 - val_loss: 0.4390 - val_acc: 0.8317\n",
      "Epoch 45/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3905 - acc: 0.7847 - val_loss: 0.4187 - val_acc: 0.8119\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3718 - acc: 0.8416 - val_loss: 0.5055 - val_acc: 0.6931\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3715 - acc: 0.7995 - val_loss: 0.4352 - val_acc: 0.8515\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3555 - acc: 0.8292 - val_loss: 0.4142 - val_acc: 0.8416\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3417 - acc: 0.8564 - val_loss: 0.4100 - val_acc: 0.8317\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3578 - acc: 0.8193 - val_loss: 0.4254 - val_acc: 0.8317\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.3649 - acc: 0.8119 - val_loss: 0.4402 - val_acc: 0.7624\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3582 - acc: 0.8069 - val_loss: 0.4287 - val_acc: 0.8020\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3478 - acc: 0.8391 - val_loss: 0.5132 - val_acc: 0.7129\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3416 - acc: 0.8490 - val_loss: 0.4390 - val_acc: 0.7624\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3664 - acc: 0.7896 - val_loss: 0.4277 - val_acc: 0.8119\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3513 - acc: 0.8218 - val_loss: 0.4249 - val_acc: 0.7822\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3455 - acc: 0.8069 - val_loss: 0.4138 - val_acc: 0.8317\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3441 - acc: 0.8342 - val_loss: 0.5016 - val_acc: 0.7228\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3460 - acc: 0.8317 - val_loss: 0.4525 - val_acc: 0.7624\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3322 - acc: 0.8366 - val_loss: 0.3963 - val_acc: 0.8614\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3250 - acc: 0.8391 - val_loss: 0.4574 - val_acc: 0.7624\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3459 - acc: 0.8168 - val_loss: 0.4565 - val_acc: 0.7525\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3245 - acc: 0.8391 - val_loss: 0.4076 - val_acc: 0.8218\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2978 - acc: 0.8292 - val_loss: 0.4398 - val_acc: 0.7921\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3429 - acc: 0.8243 - val_loss: 0.3970 - val_acc: 0.8317\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3185 - acc: 0.8614 - val_loss: 0.6180 - val_acc: 0.6733\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3363 - acc: 0.8168 - val_loss: 0.4005 - val_acc: 0.8614\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2821 - acc: 0.8614 - val_loss: 0.4067 - val_acc: 0.8317\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2905 - acc: 0.8639 - val_loss: 0.3943 - val_acc: 0.8515\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2723 - acc: 0.8837 - val_loss: 0.5213 - val_acc: 0.7327\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3177 - acc: 0.8391 - val_loss: 0.4120 - val_acc: 0.7822\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2848 - acc: 0.8663 - val_loss: 0.4173 - val_acc: 0.7624\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2874 - acc: 0.8564 - val_loss: 0.3756 - val_acc: 0.8713\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2779 - acc: 0.8465 - val_loss: 0.3785 - val_acc: 0.8812\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2780 - acc: 0.8762 - val_loss: 0.4022 - val_acc: 0.7921\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3050 - acc: 0.8564 - val_loss: 0.4171 - val_acc: 0.7723\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2577 - acc: 0.9010 - val_loss: 0.3937 - val_acc: 0.7921\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3104 - acc: 0.8342 - val_loss: 0.3992 - val_acc: 0.8416\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2540 - acc: 0.8713 - val_loss: 0.3816 - val_acc: 0.8416\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2296 - acc: 0.9035 - val_loss: 0.4194 - val_acc: 0.7723\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2527 - acc: 0.8812 - val_loss: 0.3671 - val_acc: 0.8911\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2859 - acc: 0.8564 - val_loss: 0.3691 - val_acc: 0.8812\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2718 - acc: 0.8465 - val_loss: 0.3629 - val_acc: 0.8812\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2745 - acc: 0.8738 - val_loss: 0.3647 - val_acc: 0.8713\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2716 - acc: 0.8837 - val_loss: 0.3826 - val_acc: 0.7921\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2317 - acc: 0.8911 - val_loss: 0.3601 - val_acc: 0.8713\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2655 - acc: 0.8762 - val_loss: 0.3601 - val_acc: 0.8614\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2726 - acc: 0.8639 - val_loss: 0.3603 - val_acc: 0.8614\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2407 - acc: 0.8762 - val_loss: 0.3880 - val_acc: 0.7921\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2485 - acc: 0.8787 - val_loss: 0.3616 - val_acc: 0.8515\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2487 - acc: 0.8787 - val_loss: 0.5128 - val_acc: 0.7327\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2487 - acc: 0.8861 - val_loss: 0.3685 - val_acc: 0.8515\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2750 - acc: 0.8663 - val_loss: 0.3581 - val_acc: 0.8515\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2483 - acc: 0.8861 - val_loss: 0.3607 - val_acc: 0.8416\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2318 - acc: 0.8985 - val_loss: 0.3735 - val_acc: 0.8020\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2636 - acc: 0.8614 - val_loss: 0.3810 - val_acc: 0.7921\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2505 - acc: 0.8812 - val_loss: 0.3619 - val_acc: 0.8416\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2964 - acc: 0.8441 - val_loss: 0.3499 - val_acc: 0.8614\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2196 - acc: 0.8861 - val_loss: 0.3844 - val_acc: 0.7921\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2616 - acc: 0.8639 - val_loss: 0.3480 - val_acc: 0.8812\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2570 - acc: 0.8688 - val_loss: 0.3482 - val_acc: 0.8812\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2492 - acc: 0.8861 - val_loss: 0.3519 - val_acc: 0.9010\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2696 - acc: 0.8515 - val_loss: 0.3783 - val_acc: 0.8515\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3171 - acc: 0.8416 - val_loss: 0.3726 - val_acc: 0.8812\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2506 - acc: 0.8936 - val_loss: 0.3449 - val_acc: 0.9010\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2439 - acc: 0.8861 - val_loss: 0.3529 - val_acc: 0.8614\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2306 - acc: 0.9084 - val_loss: 0.3442 - val_acc: 0.8812\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2171 - acc: 0.9059 - val_loss: 0.4577 - val_acc: 0.7624\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2969 - acc: 0.8614 - val_loss: 0.4133 - val_acc: 0.8218\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2728 - acc: 0.8663 - val_loss: 0.3463 - val_acc: 0.9109\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2394 - acc: 0.8960 - val_loss: 0.3503 - val_acc: 0.8713\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1988 - acc: 0.9134 - val_loss: 0.3414 - val_acc: 0.9010\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2420 - acc: 0.8837 - val_loss: 0.3418 - val_acc: 0.8713\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2209 - acc: 0.8936 - val_loss: 0.3563 - val_acc: 0.8515\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2025 - acc: 0.8911 - val_loss: 0.3394 - val_acc: 0.9010\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2308 - acc: 0.8960 - val_loss: 0.3437 - val_acc: 0.8713\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2103 - acc: 0.8812 - val_loss: 0.3586 - val_acc: 0.8812\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2826 - acc: 0.8465 - val_loss: 0.3382 - val_acc: 0.8911\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2631 - acc: 0.8663 - val_loss: 0.3746 - val_acc: 0.7921\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2303 - acc: 0.9059 - val_loss: 0.3452 - val_acc: 0.8515\n",
      "[[67  8]\n",
      " [ 7 19]]\n",
      "[[67  8]\n",
      " [ 7 19]]\n",
      "results :  pre = 0.704,acc = 0.851,rec = 0.731,f1 = 0.717,auc = 0.903,aupr = 0.857,auprc = 0.855\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_361 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_362 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_363 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_364 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_365 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_366 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 25s 61ms/step - loss: 0.6167 - acc: 0.7203 - val_loss: 0.6586 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.6136 - acc: 0.7351 - val_loss: 0.6578 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6496 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6104 - acc: 0.7351 - val_loss: 0.6458 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.6070 - acc: 0.742 - 1s 2ms/step - loss: 0.6129 - acc: 0.7351 - val_loss: 0.6393 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6451 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 4ms/step - loss: 0.6102 - acc: 0.7351 - val_loss: 0.6438 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.6102 - acc: 0.7351 - val_loss: 0.6398 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6445 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6097 - acc: 0.7351 - val_loss: 0.6433 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6100 - acc: 0.7351 - val_loss: 0.6427 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6106 - acc: 0.7351 - val_loss: 0.6368 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6089 - acc: 0.7351 - val_loss: 0.6403 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6100 - acc: 0.7351 - val_loss: 0.6445 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6066 - acc: 0.7351 - val_loss: 0.6372 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6090 - acc: 0.7351 - val_loss: 0.6410 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6062 - acc: 0.7351 - val_loss: 0.6401 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6029 - acc: 0.7351 - val_loss: 0.6403 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5967 - acc: 0.7351 - val_loss: 0.6318 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5955 - acc: 0.7327 - val_loss: 0.6283 - val_acc: 0.7426\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5897 - acc: 0.7426 - val_loss: 0.6359 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5807 - acc: 0.7574 - val_loss: 0.6257 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5711 - acc: 0.6658 - val_loss: 0.6183 - val_acc: 0.7228\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5610 - acc: 0.7574 - val_loss: 0.6093 - val_acc: 0.7228\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.5608 - acc: 0.7203 - val_loss: 0.6457 - val_acc: 0.7624\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.5370 - acc: 0.7500 - val_loss: 0.6270 - val_acc: 0.7822\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5278 - acc: 0.7302 - val_loss: 0.5797 - val_acc: 0.7426\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5133 - acc: 0.7475 - val_loss: 0.5897 - val_acc: 0.7624\n",
      "Epoch 29/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4998 - acc: 0.7277 - val_loss: 0.5681 - val_acc: 0.7624\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4921 - acc: 0.7847 - val_loss: 0.5766 - val_acc: 0.7921\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4979 - acc: 0.7500 - val_loss: 0.5921 - val_acc: 0.6931\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4871 - acc: 0.7203 - val_loss: 0.5309 - val_acc: 0.7723\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4446 - acc: 0.7797 - val_loss: 0.5665 - val_acc: 0.8119\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4495 - acc: 0.7500 - val_loss: 0.5508 - val_acc: 0.8416\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4390 - acc: 0.7995 - val_loss: 0.6398 - val_acc: 0.6436\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4261 - acc: 0.7797 - val_loss: 0.5810 - val_acc: 0.7030\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4121 - acc: 0.7995 - val_loss: 0.5317 - val_acc: 0.8317\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4000 - acc: 0.8168 - val_loss: 0.5775 - val_acc: 0.7129\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4289 - acc: 0.7871 - val_loss: 0.5892 - val_acc: 0.7129\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3726 - acc: 0.7921 - val_loss: 0.4943 - val_acc: 0.7921\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3904 - acc: 0.7946 - val_loss: 0.6233 - val_acc: 0.7129\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3936 - acc: 0.7673 - val_loss: 0.6828 - val_acc: 0.5941\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3783 - acc: 0.8168 - val_loss: 0.5822 - val_acc: 0.7129\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3514 - acc: 0.7970 - val_loss: 0.4789 - val_acc: 0.8020\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4170 - acc: 0.7450 - val_loss: 0.4610 - val_acc: 0.8020\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4058 - acc: 0.7946 - val_loss: 0.5915 - val_acc: 0.7129\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3693 - acc: 0.8391 - val_loss: 0.5766 - val_acc: 0.7129\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3673 - acc: 0.7822 - val_loss: 0.4658 - val_acc: 0.8317\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3134 - acc: 0.8713 - val_loss: 0.5294 - val_acc: 0.7525\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3226 - acc: 0.8292 - val_loss: 0.4643 - val_acc: 0.8317\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3373 - acc: 0.8366 - val_loss: 0.4962 - val_acc: 0.8416\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3397 - acc: 0.8317 - val_loss: 0.4481 - val_acc: 0.8020\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3446 - acc: 0.8267 - val_loss: 0.5214 - val_acc: 0.7525\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3177 - acc: 0.8193 - val_loss: 0.4471 - val_acc: 0.8317\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3459 - acc: 0.8218 - val_loss: 0.5268 - val_acc: 0.7426\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3462 - acc: 0.8317 - val_loss: 0.8245 - val_acc: 0.5842\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3597 - acc: 0.8144 - val_loss: 0.5595 - val_acc: 0.7129\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3063 - acc: 0.8416 - val_loss: 0.4860 - val_acc: 0.8416\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3404 - acc: 0.8069 - val_loss: 0.4742 - val_acc: 0.8416\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3172 - acc: 0.8267 - val_loss: 0.4507 - val_acc: 0.8416\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3278 - acc: 0.8069 - val_loss: 0.4496 - val_acc: 0.8416\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2981 - acc: 0.8465 - val_loss: 0.4833 - val_acc: 0.8218\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2828 - acc: 0.8762 - val_loss: 0.5163 - val_acc: 0.7624\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3095 - acc: 0.8614 - val_loss: 0.6079 - val_acc: 0.7030\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3022 - acc: 0.8465 - val_loss: 0.5066 - val_acc: 0.7723\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2662 - acc: 0.8738 - val_loss: 0.4616 - val_acc: 0.8218\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2821 - acc: 0.8342 - val_loss: 0.4816 - val_acc: 0.8317\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2800 - acc: 0.8787 - val_loss: 0.5074 - val_acc: 0.7624\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2495 - acc: 0.8837 - val_loss: 0.5333 - val_acc: 0.7327\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2978 - acc: 0.8515 - val_loss: 0.4409 - val_acc: 0.8515\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3027 - acc: 0.8193 - val_loss: 0.4629 - val_acc: 0.8317\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2549 - acc: 0.8985 - val_loss: 0.4916 - val_acc: 0.8317\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2709 - acc: 0.8738 - val_loss: 0.4687 - val_acc: 0.8317\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2397 - acc: 0.8787 - val_loss: 0.4355 - val_acc: 0.8515\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2736 - acc: 0.8490 - val_loss: 0.4486 - val_acc: 0.8515\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2436 - acc: 0.8911 - val_loss: 0.4773 - val_acc: 0.8317\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2741 - acc: 0.8465 - val_loss: 0.4505 - val_acc: 0.8515\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2539 - acc: 0.8812 - val_loss: 0.4495 - val_acc: 0.8515\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2756 - acc: 0.8540 - val_loss: 0.4382 - val_acc: 0.8515\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2937 - acc: 0.8490 - val_loss: 0.4422 - val_acc: 0.8416\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2683 - acc: 0.8589 - val_loss: 0.5264 - val_acc: 0.7525\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2314 - acc: 0.9010 - val_loss: 0.5495 - val_acc: 0.7228\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2526 - acc: 0.8465 - val_loss: 0.4616 - val_acc: 0.8614\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2342 - acc: 0.8861 - val_loss: 0.5251 - val_acc: 0.7624\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2273 - acc: 0.8861 - val_loss: 0.4527 - val_acc: 0.8515\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2667 - acc: 0.8639 - val_loss: 0.4688 - val_acc: 0.8416\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2418 - acc: 0.8787 - val_loss: 0.6345 - val_acc: 0.7129\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2446 - acc: 0.8861 - val_loss: 0.6121 - val_acc: 0.7129\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3004 - acc: 0.8564 - val_loss: 0.4647 - val_acc: 0.8614\n",
      "Epoch 90/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2280 - acc: 0.8614 - val_loss: 0.4501 - val_acc: 0.8416\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2475 - acc: 0.8911 - val_loss: 0.5816 - val_acc: 0.7228\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2378 - acc: 0.8812 - val_loss: 0.5404 - val_acc: 0.7228\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2231 - acc: 0.8886 - val_loss: 0.5043 - val_acc: 0.8317\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2409 - acc: 0.8787 - val_loss: 0.4546 - val_acc: 0.8515\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2547 - acc: 0.8861 - val_loss: 0.4653 - val_acc: 0.8515\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2276 - acc: 0.8713 - val_loss: 0.4668 - val_acc: 0.8515\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2501 - acc: 0.8812 - val_loss: 0.4794 - val_acc: 0.8416\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2611 - acc: 0.8639 - val_loss: 0.4631 - val_acc: 0.8515\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2260 - acc: 0.8936 - val_loss: 0.4608 - val_acc: 0.8515\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2315 - acc: 0.8688 - val_loss: 0.5155 - val_acc: 0.8317\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2475 - acc: 0.8688 - val_loss: 0.4912 - val_acc: 0.8218\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2066 - acc: 0.9233 - val_loss: 0.6008 - val_acc: 0.7327\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2711 - acc: 0.8465 - val_loss: 0.4726 - val_acc: 0.8614\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1921 - acc: 0.9035 - val_loss: 0.4625 - val_acc: 0.8515\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2283 - acc: 0.8837 - val_loss: 0.5166 - val_acc: 0.8317\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2039 - acc: 0.9109 - val_loss: 0.5879 - val_acc: 0.7327\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2373 - acc: 0.8985 - val_loss: 0.6020 - val_acc: 0.7327\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2366 - acc: 0.8614 - val_loss: 0.5064 - val_acc: 0.8218\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2151 - acc: 0.8911 - val_loss: 0.5300 - val_acc: 0.7723\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2227 - acc: 0.8960 - val_loss: 0.4798 - val_acc: 0.8614\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2106 - acc: 0.8762 - val_loss: 0.5012 - val_acc: 0.8416\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1947 - acc: 0.9035 - val_loss: 0.5733 - val_acc: 0.7426\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1992 - acc: 0.9158 - val_loss: 0.6347 - val_acc: 0.7426\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1985 - acc: 0.9010 - val_loss: 0.4831 - val_acc: 0.8614\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2217 - acc: 0.8812 - val_loss: 0.4847 - val_acc: 0.8614\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2010 - acc: 0.9059 - val_loss: 0.5040 - val_acc: 0.8416\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1772 - acc: 0.9084 - val_loss: 0.5111 - val_acc: 0.8317\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2070 - acc: 0.8837 - val_loss: 0.4824 - val_acc: 0.8614\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1977 - acc: 0.8985 - val_loss: 0.4979 - val_acc: 0.8515\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2160 - acc: 0.8911 - val_loss: 0.4921 - val_acc: 0.8614\n",
      "[[68  6]\n",
      " [ 8 19]]\n",
      "[[68  6]\n",
      " [ 8 19]]\n",
      "results :  pre = 0.76,acc = 0.861,rec = 0.704,f1 = 0.731,auc = 0.847,aupr = 0.768,auprc = 0.764\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_367 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_368 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_369 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_370 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_371 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_372 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.6172 - acc: 0.7252 - val_loss: 0.6664 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6125 - acc: 0.7351 - val_loss: 0.6585 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6490 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6140 - acc: 0.7351 - val_loss: 0.6494 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6426 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6443 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6462 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6426 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6442 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6437 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6427 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6444 - val_acc: 0.7327\n",
      "Epoch 13/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6432 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6085 - acc: 0.7351 - val_loss: 0.6453 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6083 - acc: 0.7351 - val_loss: 0.6467 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6084 - acc: 0.7351 - val_loss: 0.6374 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6086 - acc: 0.7351 - val_loss: 0.6424 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6068 - acc: 0.7351 - val_loss: 0.6443 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6045 - acc: 0.7351 - val_loss: 0.6374 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6039 - acc: 0.7351 - val_loss: 0.6408 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5973 - acc: 0.7376 - val_loss: 0.6383 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5930 - acc: 0.7500 - val_loss: 0.6485 - val_acc: 0.7129\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5840 - acc: 0.7500 - val_loss: 0.6332 - val_acc: 0.7129\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5807 - acc: 0.7550 - val_loss: 0.6397 - val_acc: 0.7129\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5731 - acc: 0.7550 - val_loss: 0.6355 - val_acc: 0.6931\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5560 - acc: 0.7649 - val_loss: 0.6147 - val_acc: 0.7030\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5439 - acc: 0.7450 - val_loss: 0.6053 - val_acc: 0.6931\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5220 - acc: 0.7847 - val_loss: 0.6119 - val_acc: 0.7228\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5197 - acc: 0.7624 - val_loss: 0.5973 - val_acc: 0.7228\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5244 - acc: 0.7450 - val_loss: 0.6361 - val_acc: 0.6535\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4922 - acc: 0.7673 - val_loss: 0.5750 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4938 - acc: 0.7401 - val_loss: 0.5997 - val_acc: 0.7822\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4786 - acc: 0.7723 - val_loss: 0.6712 - val_acc: 0.5644\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4639 - acc: 0.7698 - val_loss: 0.5694 - val_acc: 0.7723\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4429 - acc: 0.7772 - val_loss: 0.6190 - val_acc: 0.6436\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4336 - acc: 0.7946 - val_loss: 0.5528 - val_acc: 0.7723\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4440 - acc: 0.7475 - val_loss: 0.5389 - val_acc: 0.7525\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4308 - acc: 0.7772 - val_loss: 0.5326 - val_acc: 0.7624\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4144 - acc: 0.7970 - val_loss: 0.5579 - val_acc: 0.7228\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4213 - acc: 0.7822 - val_loss: 0.5319 - val_acc: 0.7822\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4059 - acc: 0.7723 - val_loss: 0.5000 - val_acc: 0.7426\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3942 - acc: 0.8020 - val_loss: 0.6114 - val_acc: 0.6238\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3917 - acc: 0.8045 - val_loss: 0.5332 - val_acc: 0.7624\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3510 - acc: 0.8342 - val_loss: 0.4951 - val_acc: 0.8218\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3847 - acc: 0.8342 - val_loss: 0.5477 - val_acc: 0.7129\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3863 - acc: 0.8020 - val_loss: 0.5289 - val_acc: 0.7129\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3466 - acc: 0.8490 - val_loss: 0.5580 - val_acc: 0.6931\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3945 - acc: 0.7896 - val_loss: 0.5963 - val_acc: 0.6535\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3672 - acc: 0.8416 - val_loss: 0.5185 - val_acc: 0.7624\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3393 - acc: 0.8589 - val_loss: 0.4983 - val_acc: 0.7822\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3606 - acc: 0.7847 - val_loss: 0.4658 - val_acc: 0.8218\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 4ms/step - loss: 0.3423 - acc: 0.8119 - val_loss: 0.4638 - val_acc: 0.8218\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.3475 - acc: 0.8465 - val_loss: 0.4640 - val_acc: 0.8119\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3497 - acc: 0.8218 - val_loss: 0.4623 - val_acc: 0.8119\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3498 - acc: 0.8267 - val_loss: 0.5006 - val_acc: 0.7723\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3159 - acc: 0.8515 - val_loss: 0.4591 - val_acc: 0.8119\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3632 - acc: 0.8144 - val_loss: 0.4870 - val_acc: 0.7822\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3277 - acc: 0.8564 - val_loss: 0.6006 - val_acc: 0.6535\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3059 - acc: 0.8564 - val_loss: 0.5514 - val_acc: 0.7129\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3647 - acc: 0.7871 - val_loss: 0.4583 - val_acc: 0.8218\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3383 - acc: 0.8119 - val_loss: 0.4638 - val_acc: 0.8020\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.3147 - acc: 0.8416 - val_loss: 0.5372 - val_acc: 0.7228\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 3s 6ms/step - loss: 0.3212 - acc: 0.8589 - val_loss: 0.5322 - val_acc: 0.7228\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.3024 - acc: 0.8639 - val_loss: 0.4605 - val_acc: 0.8020\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.3132 - acc: 0.8366 - val_loss: 0.4584 - val_acc: 0.8020\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.2865 - acc: 0.8564 - val_loss: 0.5640 - val_acc: 0.6832\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 3s 7ms/step - loss: 0.3145 - acc: 0.8540 - val_loss: 0.5010 - val_acc: 0.7327\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.2824 - acc: 0.8886 - val_loss: 0.4524 - val_acc: 0.8119\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.3164 - acc: 0.8366 - val_loss: 0.4507 - val_acc: 0.8218\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.2871 - acc: 0.8465 - val_loss: 0.4676 - val_acc: 0.7822\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3070 - acc: 0.8861 - val_loss: 0.5026 - val_acc: 0.7327\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 4ms/step - loss: 0.2924 - acc: 0.8589 - val_loss: 0.4487 - val_acc: 0.8119\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2961 - acc: 0.8465 - val_loss: 0.4515 - val_acc: 0.8317\n",
      "Epoch 74/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3202 - acc: 0.8168 - val_loss: 0.4865 - val_acc: 0.7723\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.2874 - acc: 0.8663 - val_loss: 0.5149 - val_acc: 0.7327\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.2592 - acc: 0.8762 - val_loss: 0.4654 - val_acc: 0.7921\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2433 - acc: 0.8960 - val_loss: 0.4764 - val_acc: 0.7723\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2704 - acc: 0.8663 - val_loss: 0.4561 - val_acc: 0.7822\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2407 - acc: 0.8985 - val_loss: 0.4470 - val_acc: 0.8119\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2467 - acc: 0.8762 - val_loss: 0.4566 - val_acc: 0.7822\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2456 - acc: 0.9059 - val_loss: 0.5400 - val_acc: 0.7228\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2591 - acc: 0.8663 - val_loss: 0.5024 - val_acc: 0.7228\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2519 - acc: 0.8738 - val_loss: 0.4571 - val_acc: 0.8020\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2211 - acc: 0.9084 - val_loss: 0.4588 - val_acc: 0.8020\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2313 - acc: 0.8762 - val_loss: 0.4491 - val_acc: 0.8317\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2377 - acc: 0.8812 - val_loss: 0.5530 - val_acc: 0.7228\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2596 - acc: 0.8738 - val_loss: 0.5586 - val_acc: 0.7030\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2939 - acc: 0.8416 - val_loss: 0.5144 - val_acc: 0.7426\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3069 - acc: 0.8465 - val_loss: 0.4389 - val_acc: 0.8218\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2217 - acc: 0.8762 - val_loss: 0.4387 - val_acc: 0.8020\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2446 - acc: 0.8911 - val_loss: 0.4902 - val_acc: 0.7327\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2393 - acc: 0.8861 - val_loss: 0.4599 - val_acc: 0.8020\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2565 - acc: 0.8540 - val_loss: 0.4522 - val_acc: 0.8020\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2496 - acc: 0.8911 - val_loss: 0.4411 - val_acc: 0.8317\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1970 - acc: 0.9158 - val_loss: 0.4490 - val_acc: 0.8020\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2374 - acc: 0.8886 - val_loss: 0.4390 - val_acc: 0.8119\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2462 - acc: 0.8713 - val_loss: 0.4693 - val_acc: 0.7921\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2450 - acc: 0.8861 - val_loss: 0.4538 - val_acc: 0.8020\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2204 - acc: 0.9084 - val_loss: 0.5038 - val_acc: 0.7327\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2333 - acc: 0.8936 - val_loss: 0.4934 - val_acc: 0.7426\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2521 - acc: 0.8787 - val_loss: 0.4604 - val_acc: 0.8020\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1905 - acc: 0.9109 - val_loss: 0.4529 - val_acc: 0.8317\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2621 - acc: 0.8886 - val_loss: 0.4805 - val_acc: 0.7525\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2439 - acc: 0.9010 - val_loss: 0.4750 - val_acc: 0.7624\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2283 - acc: 0.8861 - val_loss: 0.4342 - val_acc: 0.8119\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2155 - acc: 0.8738 - val_loss: 0.4375 - val_acc: 0.8119\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2144 - acc: 0.8861 - val_loss: 0.4887 - val_acc: 0.7525\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2268 - acc: 0.9059 - val_loss: 0.4756 - val_acc: 0.7822\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2521 - acc: 0.8837 - val_loss: 0.4437 - val_acc: 0.8020\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2026 - acc: 0.8985 - val_loss: 0.4366 - val_acc: 0.8218\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2098 - acc: 0.9010 - val_loss: 0.4398 - val_acc: 0.8218\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2190 - acc: 0.8936 - val_loss: 0.5664 - val_acc: 0.7030\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1987 - acc: 0.9158 - val_loss: 0.4438 - val_acc: 0.8317\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2231 - acc: 0.8886 - val_loss: 0.4414 - val_acc: 0.8317\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2549 - acc: 0.8614 - val_loss: 0.4489 - val_acc: 0.8119\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1940 - acc: 0.9208 - val_loss: 0.4604 - val_acc: 0.8020\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2073 - acc: 0.9134 - val_loss: 0.4510 - val_acc: 0.8119\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2080 - acc: 0.8985 - val_loss: 0.4883 - val_acc: 0.7426\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2115 - acc: 0.8936 - val_loss: 0.4500 - val_acc: 0.8119\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2157 - acc: 0.8985 - val_loss: 0.4992 - val_acc: 0.7525\n",
      "[[56 18]\n",
      " [ 7 20]]\n",
      "[[56 18]\n",
      " [ 7 20]]\n",
      "results :  pre = 0.526,acc = 0.752,rec = 0.741,f1 = 0.615,auc = 0.856,aupr = 0.745,auprc = 0.742\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_373 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_374 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_375 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_376 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_377 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_378 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 21s 52ms/step - loss: 0.6159 - acc: 0.7277 - val_loss: 0.6702 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6126 - acc: 0.7351 - val_loss: 0.6468 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6380 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6133 - acc: 0.7351 - val_loss: 0.6467 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6485 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6116 - acc: 0.7351 - val_loss: 0.6435 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6413 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6465 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6430 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6393 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6104 - acc: 0.7351 - val_loss: 0.6417 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6439 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6097 - acc: 0.7351 - val_loss: 0.6449 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6406 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6088 - acc: 0.7351 - val_loss: 0.6386 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6414 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6416 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6091 - acc: 0.7351 - val_loss: 0.6371 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6091 - acc: 0.7351 - val_loss: 0.6402 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6081 - acc: 0.7351 - val_loss: 0.6362 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6070 - acc: 0.7351 - val_loss: 0.6395 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6058 - acc: 0.7351 - val_loss: 0.6388 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6030 - acc: 0.7351 - val_loss: 0.6302 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5980 - acc: 0.7351 - val_loss: 0.6309 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5949 - acc: 0.7450 - val_loss: 0.6182 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5875 - acc: 0.7550 - val_loss: 0.6125 - val_acc: 0.7426\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5767 - acc: 0.7797 - val_loss: 0.5986 - val_acc: 0.7426\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5650 - acc: 0.7896 - val_loss: 0.5774 - val_acc: 0.7525\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5492 - acc: 0.7822 - val_loss: 0.5651 - val_acc: 0.7921\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5358 - acc: 0.7673 - val_loss: 0.5122 - val_acc: 0.7426\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5307 - acc: 0.7624 - val_loss: 0.5455 - val_acc: 0.8119\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5258 - acc: 0.7649 - val_loss: 0.4997 - val_acc: 0.8119\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4906 - acc: 0.7599 - val_loss: 0.4648 - val_acc: 0.7624\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4881 - acc: 0.7871 - val_loss: 0.4550 - val_acc: 0.8119\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4710 - acc: 0.8094 - val_loss: 0.4466 - val_acc: 0.8119\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4537 - acc: 0.8193 - val_loss: 0.4624 - val_acc: 0.8218\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4605 - acc: 0.7426 - val_loss: 0.4118 - val_acc: 0.8218\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4237 - acc: 0.8168 - val_loss: 0.4059 - val_acc: 0.7822\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4327 - acc: 0.7970 - val_loss: 0.3888 - val_acc: 0.8020\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3926 - acc: 0.8342 - val_loss: 0.3835 - val_acc: 0.8218\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4071 - acc: 0.7797 - val_loss: 0.3727 - val_acc: 0.8020\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4532 - acc: 0.7896 - val_loss: 0.3702 - val_acc: 0.8020\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3887 - acc: 0.8045 - val_loss: 0.3785 - val_acc: 0.8713\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3768 - acc: 0.8515 - val_loss: 0.3660 - val_acc: 0.8515\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3724 - acc: 0.8391 - val_loss: 0.3725 - val_acc: 0.7822\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3929 - acc: 0.8342 - val_loss: 0.3616 - val_acc: 0.7822\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3606 - acc: 0.8515 - val_loss: 0.3513 - val_acc: 0.8614\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3762 - acc: 0.8243 - val_loss: 0.3475 - val_acc: 0.8911\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3828 - acc: 0.8094 - val_loss: 0.3593 - val_acc: 0.7822\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3623 - acc: 0.8119 - val_loss: 0.3342 - val_acc: 0.8020\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3412 - acc: 0.8540 - val_loss: 0.3283 - val_acc: 0.8317\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3455 - acc: 0.8292 - val_loss: 0.3844 - val_acc: 0.8614\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3882 - acc: 0.8218 - val_loss: 0.3418 - val_acc: 0.8614\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3578 - acc: 0.8144 - val_loss: 0.3330 - val_acc: 0.7723\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3661 - acc: 0.8292 - val_loss: 0.3319 - val_acc: 0.7822\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3406 - acc: 0.8243 - val_loss: 0.3740 - val_acc: 0.7822\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3030 - acc: 0.8787 - val_loss: 0.3429 - val_acc: 0.8614\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3461 - acc: 0.8366 - val_loss: 0.3128 - val_acc: 0.8317\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3553 - acc: 0.8218 - val_loss: 0.3431 - val_acc: 0.7921\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3017 - acc: 0.8663 - val_loss: 0.3214 - val_acc: 0.8119\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3132 - acc: 0.8663 - val_loss: 0.3336 - val_acc: 0.7921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3264 - acc: 0.8663 - val_loss: 0.3083 - val_acc: 0.9010\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3132 - acc: 0.8515 - val_loss: 0.3553 - val_acc: 0.7921\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2959 - acc: 0.8688 - val_loss: 0.3127 - val_acc: 0.8119\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2971 - acc: 0.8564 - val_loss: 0.3414 - val_acc: 0.8020\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3257 - acc: 0.8515 - val_loss: 0.3041 - val_acc: 0.8218\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2997 - acc: 0.8713 - val_loss: 0.2982 - val_acc: 0.8911\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2770 - acc: 0.8688 - val_loss: 0.3449 - val_acc: 0.8020\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2837 - acc: 0.8540 - val_loss: 0.3117 - val_acc: 0.8119\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3228 - acc: 0.8416 - val_loss: 0.2906 - val_acc: 0.8614\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2875 - acc: 0.8639 - val_loss: 0.2946 - val_acc: 0.8317\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2817 - acc: 0.8589 - val_loss: 0.3169 - val_acc: 0.8119\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2879 - acc: 0.8762 - val_loss: 0.2884 - val_acc: 0.8911\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3029 - acc: 0.8787 - val_loss: 0.3105 - val_acc: 0.8713\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2728 - acc: 0.8564 - val_loss: 0.2898 - val_acc: 0.8713\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2944 - acc: 0.8564 - val_loss: 0.2918 - val_acc: 0.8713\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2692 - acc: 0.8688 - val_loss: 0.3212 - val_acc: 0.8020\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2840 - acc: 0.8960 - val_loss: 0.2906 - val_acc: 0.8713\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3010 - acc: 0.8243 - val_loss: 0.4169 - val_acc: 0.7921\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2426 - acc: 0.8886 - val_loss: 0.3481 - val_acc: 0.8020\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2904 - acc: 0.8762 - val_loss: 0.3395 - val_acc: 0.8020\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2778 - acc: 0.8762 - val_loss: 0.3132 - val_acc: 0.8218\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2426 - acc: 0.8911 - val_loss: 0.2926 - val_acc: 0.8515\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2824 - acc: 0.8639 - val_loss: 0.2858 - val_acc: 0.9010\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2471 - acc: 0.8960 - val_loss: 0.2855 - val_acc: 0.9010\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2478 - acc: 0.8762 - val_loss: 0.3202 - val_acc: 0.8020\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2589 - acc: 0.8812 - val_loss: 0.2906 - val_acc: 0.8416\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2504 - acc: 0.8985 - val_loss: 0.2940 - val_acc: 0.8416\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2512 - acc: 0.8812 - val_loss: 0.3188 - val_acc: 0.8317\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2481 - acc: 0.8985 - val_loss: 0.2907 - val_acc: 0.8515\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2294 - acc: 0.8960 - val_loss: 0.2906 - val_acc: 0.8515\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2514 - acc: 0.8812 - val_loss: 0.3431 - val_acc: 0.8218\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2575 - acc: 0.8688 - val_loss: 0.3025 - val_acc: 0.8416\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2663 - acc: 0.8688 - val_loss: 0.3209 - val_acc: 0.8317\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2352 - acc: 0.9183 - val_loss: 0.2796 - val_acc: 0.8812\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2663 - acc: 0.8812 - val_loss: 0.3242 - val_acc: 0.8317\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2763 - acc: 0.8787 - val_loss: 0.3181 - val_acc: 0.8317\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2294 - acc: 0.9035 - val_loss: 0.2971 - val_acc: 0.8515\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2512 - acc: 0.8762 - val_loss: 0.3094 - val_acc: 0.8515\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2133 - acc: 0.8985 - val_loss: 0.4111 - val_acc: 0.7921\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2537 - acc: 0.8886 - val_loss: 0.3023 - val_acc: 0.8515\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2347 - acc: 0.8861 - val_loss: 0.3243 - val_acc: 0.8317\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2174 - acc: 0.9035 - val_loss: 0.3208 - val_acc: 0.8416\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2248 - acc: 0.8985 - val_loss: 0.3069 - val_acc: 0.8515\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2356 - acc: 0.9109 - val_loss: 0.3006 - val_acc: 0.8515\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.2230 - acc: 0.8886 - val_loss: 0.3595 - val_acc: 0.8416\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2384 - acc: 0.8911 - val_loss: 0.4050 - val_acc: 0.7921\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2220 - acc: 0.8985 - val_loss: 0.3269 - val_acc: 0.8416\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2623 - acc: 0.8886 - val_loss: 0.2826 - val_acc: 0.8911\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2486 - acc: 0.8911 - val_loss: 0.2983 - val_acc: 0.8614\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2369 - acc: 0.8960 - val_loss: 0.2867 - val_acc: 0.8812\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2502 - acc: 0.8688 - val_loss: 0.5030 - val_acc: 0.7921\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2451 - acc: 0.8861 - val_loss: 0.3137 - val_acc: 0.8515\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2052 - acc: 0.9134 - val_loss: 0.2914 - val_acc: 0.8713\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2466 - acc: 0.8787 - val_loss: 0.2943 - val_acc: 0.8614\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2100 - acc: 0.9208 - val_loss: 0.2886 - val_acc: 0.8416\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2626 - acc: 0.8713 - val_loss: 0.3136 - val_acc: 0.8515\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2670 - acc: 0.8540 - val_loss: 0.4499 - val_acc: 0.7921\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2426 - acc: 0.8861 - val_loss: 0.3677 - val_acc: 0.8317\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1908 - acc: 0.9307 - val_loss: 0.3398 - val_acc: 0.8515\n",
      "[[73  1]\n",
      " [14 13]]\n",
      "[[73  1]\n",
      " [14 13]]\n",
      "results :  pre = 0.929,acc = 0.851,rec = 0.481,f1 = 0.634,auc = 0.933,aupr = 0.828,auprc = 0.823\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_379 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_380 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_381 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_382 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_383 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_384 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 16s 40ms/step - loss: 0.6162 - acc: 0.7104 - val_loss: 0.6663 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6134 - acc: 0.7351 - val_loss: 0.6548 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6507 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6422 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6433 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6432 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6433 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6437 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6411 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6499 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6463 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6411 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6358 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6087 - acc: 0.7351 - val_loss: 0.6460 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6085 - acc: 0.7351 - val_loss: 0.6513 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6077 - acc: 0.7351 - val_loss: 0.6485 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6068 - acc: 0.7351 - val_loss: 0.6452 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6010 - acc: 0.7351 - val_loss: 0.6335 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6038 - acc: 0.7351 - val_loss: 0.6309 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5978 - acc: 0.7351 - val_loss: 0.6380 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5932 - acc: 0.7525 - val_loss: 0.6390 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5871 - acc: 0.7624 - val_loss: 0.6354 - val_acc: 0.7228\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5695 - acc: 0.7921 - val_loss: 0.6233 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5743 - acc: 0.7698 - val_loss: 0.6312 - val_acc: 0.7129\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5502 - acc: 0.7847 - val_loss: 0.6234 - val_acc: 0.7030\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.5444 - acc: 0.7871 - val_loss: 0.6167 - val_acc: 0.7030\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5408 - acc: 0.7500 - val_loss: 0.6016 - val_acc: 0.7030\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5145 - acc: 0.7896 - val_loss: 0.6211 - val_acc: 0.6733\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5020 - acc: 0.7772 - val_loss: 0.5620 - val_acc: 0.7228\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4836 - acc: 0.7797 - val_loss: 0.6099 - val_acc: 0.6931\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4884 - acc: 0.7847 - val_loss: 0.6126 - val_acc: 0.7030\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4628 - acc: 0.7525 - val_loss: 0.5277 - val_acc: 0.7327\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4482 - acc: 0.8119 - val_loss: 0.5713 - val_acc: 0.6931\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4285 - acc: 0.8144 - val_loss: 0.5356 - val_acc: 0.7129\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4532 - acc: 0.7673 - val_loss: 0.5403 - val_acc: 0.7129\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4117 - acc: 0.8292 - val_loss: 0.5209 - val_acc: 0.7426\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4086 - acc: 0.8193 - val_loss: 0.5946 - val_acc: 0.7129\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4066 - acc: 0.8144 - val_loss: 0.5365 - val_acc: 0.7030\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.4214 - acc: 0.776 - 1s 3ms/step - loss: 0.4260 - acc: 0.7772 - val_loss: 0.5011 - val_acc: 0.7426\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4070 - acc: 0.8144 - val_loss: 0.5745 - val_acc: 0.7030\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4170 - acc: 0.7847 - val_loss: 0.5870 - val_acc: 0.7228\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3774 - acc: 0.8168 - val_loss: 0.4985 - val_acc: 0.7723\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3666 - acc: 0.8540 - val_loss: 0.4965 - val_acc: 0.7624\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3767 - acc: 0.8366 - val_loss: 0.5265 - val_acc: 0.7327\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3837 - acc: 0.8119 - val_loss: 0.4809 - val_acc: 0.7624\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3334 - acc: 0.8391 - val_loss: 0.4770 - val_acc: 0.7822\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4103 - acc: 0.7970 - val_loss: 0.4773 - val_acc: 0.7624\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3812 - acc: 0.8094 - val_loss: 0.4985 - val_acc: 0.7327\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3558 - acc: 0.8540 - val_loss: 0.5633 - val_acc: 0.7129\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3533 - acc: 0.8391 - val_loss: 0.4869 - val_acc: 0.7327\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3615 - acc: 0.8515 - val_loss: 0.5299 - val_acc: 0.7624\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3653 - acc: 0.8144 - val_loss: 0.4578 - val_acc: 0.7921\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3412 - acc: 0.8342 - val_loss: 0.4546 - val_acc: 0.7822\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3423 - acc: 0.8787 - val_loss: 0.4921 - val_acc: 0.7921\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3457 - acc: 0.8441 - val_loss: 0.4573 - val_acc: 0.7426\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3157 - acc: 0.8490 - val_loss: 0.4663 - val_acc: 0.7723\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3330 - acc: 0.8490 - val_loss: 0.5548 - val_acc: 0.7327\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3495 - acc: 0.8317 - val_loss: 0.5139 - val_acc: 0.7624\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3548 - acc: 0.7871 - val_loss: 0.4453 - val_acc: 0.7624\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3081 - acc: 0.8416 - val_loss: 0.4397 - val_acc: 0.7822\n",
      "Epoch 61/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3569 - acc: 0.8144 - val_loss: 0.4370 - val_acc: 0.7822\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 4ms/step - loss: 0.3337 - acc: 0.8267 - val_loss: 0.4539 - val_acc: 0.8020\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2880 - acc: 0.8837 - val_loss: 0.5124 - val_acc: 0.7723\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3069 - acc: 0.8639 - val_loss: 0.4840 - val_acc: 0.8119\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3130 - acc: 0.8564 - val_loss: 0.4478 - val_acc: 0.8020\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2976 - acc: 0.8515 - val_loss: 0.4785 - val_acc: 0.8119\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2779 - acc: 0.8837 - val_loss: 0.4576 - val_acc: 0.8218\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2757 - acc: 0.8936 - val_loss: 0.4345 - val_acc: 0.8020\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2897 - acc: 0.8762 - val_loss: 0.5330 - val_acc: 0.7822\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2714 - acc: 0.8861 - val_loss: 0.5450 - val_acc: 0.7624\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3244 - acc: 0.8267 - val_loss: 0.4251 - val_acc: 0.8020\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2817 - acc: 0.8589 - val_loss: 0.4255 - val_acc: 0.8020\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3014 - acc: 0.8614 - val_loss: 0.4508 - val_acc: 0.8119\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2751 - acc: 0.8762 - val_loss: 0.4406 - val_acc: 0.8119\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2865 - acc: 0.8515 - val_loss: 0.5238 - val_acc: 0.8020\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2920 - acc: 0.8391 - val_loss: 0.4564 - val_acc: 0.8218\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2789 - acc: 0.8713 - val_loss: 0.4294 - val_acc: 0.7921\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2703 - acc: 0.8837 - val_loss: 0.4154 - val_acc: 0.8119\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2892 - acc: 0.8614 - val_loss: 0.4847 - val_acc: 0.8218\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2744 - acc: 0.8762 - val_loss: 0.4426 - val_acc: 0.8317\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2413 - acc: 0.8960 - val_loss: 0.4808 - val_acc: 0.7723\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2722 - acc: 0.8639 - val_loss: 0.4281 - val_acc: 0.8119\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2700 - acc: 0.8762 - val_loss: 0.4326 - val_acc: 0.8119\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2984 - acc: 0.8564 - val_loss: 0.4859 - val_acc: 0.8218\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2707 - acc: 0.8540 - val_loss: 0.4563 - val_acc: 0.8218\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2546 - acc: 0.9109 - val_loss: 0.4209 - val_acc: 0.8218\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2819 - acc: 0.8490 - val_loss: 0.4243 - val_acc: 0.8218\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2525 - acc: 0.8812 - val_loss: 0.4119 - val_acc: 0.7921\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2513 - acc: 0.8812 - val_loss: 0.4128 - val_acc: 0.8020\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2497 - acc: 0.8738 - val_loss: 0.4293 - val_acc: 0.8317\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2479 - acc: 0.8812 - val_loss: 0.4396 - val_acc: 0.8218\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2354 - acc: 0.8837 - val_loss: 0.4100 - val_acc: 0.8119\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2266 - acc: 0.8936 - val_loss: 0.4168 - val_acc: 0.8020\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2479 - acc: 0.8911 - val_loss: 0.4236 - val_acc: 0.8317\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2391 - acc: 0.8886 - val_loss: 0.4114 - val_acc: 0.8119\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2559 - acc: 0.8688 - val_loss: 0.4086 - val_acc: 0.8020\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2448 - acc: 0.8416 - val_loss: 0.5122 - val_acc: 0.7822\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2884 - acc: 0.8391 - val_loss: 0.4047 - val_acc: 0.8020\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2579 - acc: 0.8911 - val_loss: 0.4272 - val_acc: 0.8416\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2447 - acc: 0.9035 - val_loss: 0.4861 - val_acc: 0.8218\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2258 - acc: 0.9035 - val_loss: 0.4380 - val_acc: 0.8218\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2438 - acc: 0.8812 - val_loss: 0.4146 - val_acc: 0.8119\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2228 - acc: 0.9084 - val_loss: 0.4055 - val_acc: 0.8218\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2370 - acc: 0.8762 - val_loss: 0.3973 - val_acc: 0.8119\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2183 - acc: 0.8985 - val_loss: 0.4434 - val_acc: 0.8119\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2591 - acc: 0.8911 - val_loss: 0.4093 - val_acc: 0.8317\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2285 - acc: 0.8985 - val_loss: 0.4190 - val_acc: 0.8416\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2150 - acc: 0.8960 - val_loss: 0.4011 - val_acc: 0.8119\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 4ms/step - loss: 0.1944 - acc: 0.9084 - val_loss: 0.4147 - val_acc: 0.8317\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2270 - acc: 0.8960 - val_loss: 0.4058 - val_acc: 0.8020\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2089 - acc: 0.9158 - val_loss: 0.4277 - val_acc: 0.8218\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2341 - acc: 0.8812 - val_loss: 0.4290 - val_acc: 0.8317\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1940 - acc: 0.8936 - val_loss: 0.4049 - val_acc: 0.8020\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2054 - acc: 0.9134 - val_loss: 0.4019 - val_acc: 0.8020\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2365 - acc: 0.8738 - val_loss: 0.4043 - val_acc: 0.8119\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2074 - acc: 0.8960 - val_loss: 0.3990 - val_acc: 0.8020\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2069 - acc: 0.8985 - val_loss: 0.3996 - val_acc: 0.8119\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1869 - acc: 0.9208 - val_loss: 0.3980 - val_acc: 0.8119\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1873 - acc: 0.9059 - val_loss: 0.3969 - val_acc: 0.8119\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1909 - acc: 0.8985 - val_loss: 0.3998 - val_acc: 0.8119\n",
      "[[68  6]\n",
      " [13 14]]\n",
      "[[68  6]\n",
      " [13 14]]\n",
      "results :  pre = 0.7,acc = 0.812,rec = 0.519,f1 = 0.596,auc = 0.892,aupr = 0.743,auprc = 0.737\n",
      "average value :  pre = 0.724,acc = 0.826,rec = 0.635,f1 = 0.659,auc = 0.886,aupr = 0.788,auprc = 0.784\n"
     ]
    }
   ],
   "source": [
    "#交叉验证\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590) \n",
    "\n",
    "\n",
    "kfscore = []\n",
    "\n",
    "p = 0\n",
    "x = Omics_data.values\n",
    "y = y.reshape(-1)\n",
    "x_0 =  0.68\n",
    "x_1 =  1.48\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = create_model(x)\n",
    "\n",
    "    history = model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=120,class_weight={0:x_0,1:x_1},batch_size = 32)  #epochs=50,class_weight={0:0.5,1:1.35},batch_size = 64\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    kfscore.append(evaluates(y_test, y_pred))\n",
    "    results = evaluates(y_test, y_pred)\n",
    "    print(\"results :  pre = {},acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(results[0],3),round(results[1],3),round(results[2],3),round(results[3],3),round(results[4],3),round(results[5],3),round(results[6],3)))\n",
    "\n",
    "    # feature importance\n",
    "    explain_x = X_train[np.where(y_train!=0)]\n",
    "    explain_y = y_train[np.where(y_train!=0)]\n",
    "    coef_ = get_coef_importance(model,explain_x, explain_y, target=-1,feature_importance='deepexplain_deeplift')\n",
    "    cof_values = ['inputs','h_0','h0','h1','h2','h3','h4']\n",
    "    name = [np.array(Omics_data.columns),gene_pathway_df.columns,Get_Node_relation[3].index,Get_Node_relation[2].index,Get_Node_relation[1].index,Get_Node_relation[0].index,Get_Node_relation[0].columns]\n",
    "#     os.mkdir('./data/coef/h{}/'.format(p))\n",
    "    for i in range(0,7):\n",
    "        X = pd.DataFrame()\n",
    "        X['name'] = name[i]\n",
    "        X['values'] = coef_[0][cof_values[i]]\n",
    "        X.to_csv('./data/coef/h{}/{}.csv'.format(p,cof_values[i]),index=False,encoding='UTF-8')\n",
    "    p =p+1\n",
    "#avrrage\n",
    "kfscores = np.array(kfscore).sum(axis= 0)/5.0\n",
    "print(\"average value :  pre = {},acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(kfscores[0],3),round(kfscores[1],3),round(kfscores[2],3),round(kfscores[3],3),round(kfscores[4],3),round(kfscores[5],3),round(kfscores[6],3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  average  five result\n",
    "file_name = ['inputs.csv','h_0.csv','h0.csv','h1.csv','h2.csv','h3.csv','h4.csv']\n",
    "os.mkdir('./data/coef/average')\n",
    "for j in file_name:\n",
    "    result0 =pd.DataFrame()\n",
    "    for i in range(0,5):\n",
    "         result  = pd.read_csv('./data/coef/h{}/{}'.format(i,j))\n",
    "         result0 = result0.append(result)\n",
    "    results = pd.DataFrame(result0.groupby('name')['values'].mean()).reset_index().sort_values('values',ascending=False)\n",
    "    results.to_csv('./data/coef/average/{}'.format(j),index = False)\n",
    "    print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单一组学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_model(omics_data):\n",
    "    S_inputs = Input(shape=(omics_data.shape[1],), dtype='float32',name= 'inputs')\n",
    "    #gene and pathway\n",
    "\n",
    "    h0 = SparseTF(gene_pathway_df.shape[0],mapp =gene_pathway_df.values.T, name = 'h0')(S_inputs)\n",
    "    drop0 = keras.layers.Dropout(0.5)(h0)\n",
    "\n",
    "    h1 = SparseTF(Get_Node_relation[3].shape[1],mapp =Get_Node_relation[3].values ,name = 'h1')(drop0)\n",
    "    drop_h1 = keras.layers.Dropout(0.1)(h1)\n",
    "\n",
    "\n",
    "    h2 = SparseTF(Get_Node_relation[2].shape[1],mapp =Get_Node_relation[2].values, name = 'h2')(drop_h1)\n",
    "    drop2 = keras.layers.Dropout(0.1)(h2)\n",
    "\n",
    "\n",
    "    h3 = SparseTF(Get_Node_relation[1].shape[1],mapp =Get_Node_relation[1].values, name = 'h3')(drop2)\n",
    "    drop3 = keras.layers.Dropout(0.1)(h3)\n",
    "\n",
    "    \n",
    "    h4 = SparseTF(Get_Node_relation[0].shape[1],mapp =Get_Node_relation[0].values, name = 'h4')(drop3)\n",
    "    drop4 = keras.layers.Dropout(0.1)(h4)\n",
    "\n",
    "    Output = keras.layers.Dense(1,activation='sigmoid')(drop4)\n",
    "\n",
    "    model = Model(inputs=S_inputs, outputs=Output)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr = 0.001) #,decay=-0.0001\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single omics\n",
    "#snv_data; cnv_amp; cnv_del\n",
    "single_snv =Omics_data.swaplevel(i=0, j=1, axis=1)['snv_data']\n",
    "single_snv = single_snv.join(response,how='inner')\n",
    "single_snv.shape\n",
    "\n",
    "single_x = single_snv.values[:,0:-1]\n",
    "single_y =  single_snv.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_211 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_212 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_213 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_214 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_215 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_216 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 6s 15ms/step - loss: 0.6175 - acc: 0.7104 - val_loss: 0.6653 - val_acc: 0.7426\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6148 - acc: 0.7327 - val_loss: 0.6540 - val_acc: 0.7426\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6140 - acc: 0.7327 - val_loss: 0.6495 - val_acc: 0.7426\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6137 - acc: 0.7327 - val_loss: 0.6466 - val_acc: 0.7426\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6149 - acc: 0.7327 - val_loss: 0.6405 - val_acc: 0.7426\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6139 - acc: 0.7327 - val_loss: 0.6456 - val_acc: 0.7426\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6155 - acc: 0.7327 - val_loss: 0.6469 - val_acc: 0.7426\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6142 - acc: 0.7327 - val_loss: 0.6458 - val_acc: 0.7426\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6141 - acc: 0.7327 - val_loss: 0.6481 - val_acc: 0.7426\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6143 - acc: 0.7327 - val_loss: 0.6453 - val_acc: 0.7426\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6134 - acc: 0.7327 - val_loss: 0.6444 - val_acc: 0.7426\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6131 - acc: 0.7327 - val_loss: 0.6430 - val_acc: 0.7426\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6142 - acc: 0.7327 - val_loss: 0.6466 - val_acc: 0.7426\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6133 - acc: 0.7327 - val_loss: 0.6483 - val_acc: 0.7426\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6133 - acc: 0.7327 - val_loss: 0.6450 - val_acc: 0.7426\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6164 - acc: 0.7327 - val_loss: 0.6348 - val_acc: 0.7426\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6142 - acc: 0.7327 - val_loss: 0.6490 - val_acc: 0.7426\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6138 - acc: 0.7327 - val_loss: 0.6505 - val_acc: 0.7426\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6134 - acc: 0.7327 - val_loss: 0.6495 - val_acc: 0.7426\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6137 - acc: 0.7327 - val_loss: 0.6465 - val_acc: 0.7426\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6140 - acc: 0.7327 - val_loss: 0.6377 - val_acc: 0.7426\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6132 - acc: 0.7327 - val_loss: 0.6391 - val_acc: 0.7426\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6140 - acc: 0.7327 - val_loss: 0.6455 - val_acc: 0.7426\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6132 - acc: 0.7327 - val_loss: 0.6414 - val_acc: 0.7426\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6127 - acc: 0.7327 - val_loss: 0.6466 - val_acc: 0.7426\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6126 - acc: 0.7327 - val_loss: 0.6436 - val_acc: 0.7426\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6138 - acc: 0.7327 - val_loss: 0.6370 - val_acc: 0.7426\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6112 - acc: 0.7327 - val_loss: 0.6406 - val_acc: 0.7426\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6125 - acc: 0.7327 - val_loss: 0.6470 - val_acc: 0.7426\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6115 - acc: 0.7327 - val_loss: 0.6439 - val_acc: 0.7426\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6119 - acc: 0.7327 - val_loss: 0.6449 - val_acc: 0.7426\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6108 - acc: 0.7327 - val_loss: 0.6446 - val_acc: 0.7426\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6100 - acc: 0.7327 - val_loss: 0.6336 - val_acc: 0.7426\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6095 - acc: 0.7327 - val_loss: 0.6374 - val_acc: 0.7426\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6092 - acc: 0.7327 - val_loss: 0.6343 - val_acc: 0.7426\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6091 - acc: 0.7327 - val_loss: 0.6501 - val_acc: 0.7426\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6070 - acc: 0.7327 - val_loss: 0.6316 - val_acc: 0.7426\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6065 - acc: 0.7327 - val_loss: 0.6389 - val_acc: 0.7426\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6000 - acc: 0.7525 - val_loss: 0.6379 - val_acc: 0.7426\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5973 - acc: 0.7351 - val_loss: 0.6150 - val_acc: 0.7426\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5948 - acc: 0.7450 - val_loss: 0.6152 - val_acc: 0.7426\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5932 - acc: 0.7624 - val_loss: 0.6322 - val_acc: 0.7525\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5889 - acc: 0.7500 - val_loss: 0.6087 - val_acc: 0.7525\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5829 - acc: 0.7277 - val_loss: 0.5905 - val_acc: 0.7525\n",
      "Epoch 45/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5818 - acc: 0.7599 - val_loss: 0.6376 - val_acc: 0.8515\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5747 - acc: 0.7228 - val_loss: 0.5814 - val_acc: 0.7723\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5576 - acc: 0.7153 - val_loss: 0.5677 - val_acc: 0.8020\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5473 - acc: 0.7624 - val_loss: 0.5466 - val_acc: 0.8020\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5538 - acc: 0.6931 - val_loss: 0.5129 - val_acc: 0.7624\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5356 - acc: 0.7649 - val_loss: 0.6408 - val_acc: 0.5248\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5369 - acc: 0.6584 - val_loss: 0.4843 - val_acc: 0.7525\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5365 - acc: 0.7624 - val_loss: 0.5936 - val_acc: 0.6535\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5351 - acc: 0.6559 - val_loss: 0.5302 - val_acc: 0.8416\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5232 - acc: 0.7772 - val_loss: 0.6421 - val_acc: 0.5149\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5419 - acc: 0.6931 - val_loss: 0.5668 - val_acc: 0.7030\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5304 - acc: 0.6955 - val_loss: 0.4908 - val_acc: 0.8317\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4931 - acc: 0.7252 - val_loss: 0.4632 - val_acc: 0.8119\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4799 - acc: 0.7772 - val_loss: 0.4708 - val_acc: 0.8317\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5062 - acc: 0.7376 - val_loss: 0.4993 - val_acc: 0.8614\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4629 - acc: 0.7921 - val_loss: 0.4664 - val_acc: 0.8218\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4829 - acc: 0.7698 - val_loss: 0.4384 - val_acc: 0.8317\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4693 - acc: 0.7426 - val_loss: 0.4651 - val_acc: 0.8614\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4716 - acc: 0.7748 - val_loss: 0.5694 - val_acc: 0.6238\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4604 - acc: 0.8069 - val_loss: 0.4905 - val_acc: 0.8614\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4821 - acc: 0.7426 - val_loss: 0.4129 - val_acc: 0.8218\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4607 - acc: 0.7525 - val_loss: 0.4178 - val_acc: 0.8317\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4654 - acc: 0.7178 - val_loss: 0.4246 - val_acc: 0.8218\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4967 - acc: 0.7228 - val_loss: 0.6168 - val_acc: 0.5743\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4616 - acc: 0.7525 - val_loss: 0.4521 - val_acc: 0.8614\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4339 - acc: 0.7475 - val_loss: 0.4337 - val_acc: 0.8515\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4423 - acc: 0.7624 - val_loss: 0.4690 - val_acc: 0.8713\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4243 - acc: 0.7995 - val_loss: 0.4662 - val_acc: 0.8614\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4219 - acc: 0.7698 - val_loss: 0.4813 - val_acc: 0.8416\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4141 - acc: 0.8069 - val_loss: 0.4917 - val_acc: 0.6931\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4312 - acc: 0.7822 - val_loss: 0.4143 - val_acc: 0.8515\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4135 - acc: 0.7847 - val_loss: 0.3898 - val_acc: 0.8614\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4084 - acc: 0.7822 - val_loss: 0.3775 - val_acc: 0.8317\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4245 - acc: 0.8045 - val_loss: 0.4076 - val_acc: 0.8515\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4544 - acc: 0.7871 - val_loss: 0.3727 - val_acc: 0.8119\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4173 - acc: 0.7896 - val_loss: 0.4146 - val_acc: 0.8515\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4066 - acc: 0.8069 - val_loss: 0.6384 - val_acc: 0.5842\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4129 - acc: 0.7772 - val_loss: 0.3722 - val_acc: 0.8020\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3984 - acc: 0.8069 - val_loss: 0.3733 - val_acc: 0.8614\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4274 - acc: 0.8020 - val_loss: 0.3847 - val_acc: 0.8416\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4065 - acc: 0.7896 - val_loss: 0.3937 - val_acc: 0.8515\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3802 - acc: 0.8490 - val_loss: 0.5645 - val_acc: 0.6238\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4646 - acc: 0.7401 - val_loss: 0.3757 - val_acc: 0.8515\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4584 - acc: 0.6856 - val_loss: 0.3886 - val_acc: 0.8020\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4303 - acc: 0.7525 - val_loss: 0.3848 - val_acc: 0.8713\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4103 - acc: 0.8391 - val_loss: 0.5326 - val_acc: 0.6337\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4151 - acc: 0.7327 - val_loss: 0.3706 - val_acc: 0.8119\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3838 - acc: 0.8119 - val_loss: 0.4356 - val_acc: 0.8515\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4110 - acc: 0.7995 - val_loss: 0.4051 - val_acc: 0.8713\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3786 - acc: 0.8020 - val_loss: 0.3638 - val_acc: 0.8713\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3921 - acc: 0.7921 - val_loss: 0.3730 - val_acc: 0.8515\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3969 - acc: 0.7698 - val_loss: 0.4064 - val_acc: 0.8614\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3897 - acc: 0.8267 - val_loss: 0.5312 - val_acc: 0.6337\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4184 - acc: 0.7500 - val_loss: 0.3536 - val_acc: 0.8614\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3856 - acc: 0.7921 - val_loss: 0.3627 - val_acc: 0.8515\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4043 - acc: 0.8094 - val_loss: 0.4889 - val_acc: 0.6931\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3966 - acc: 0.7871 - val_loss: 0.3677 - val_acc: 0.8515\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3976 - acc: 0.7772 - val_loss: 0.3488 - val_acc: 0.8317\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3950 - acc: 0.7970 - val_loss: 0.4503 - val_acc: 0.7228\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3407 - acc: 0.8416 - val_loss: 0.3689 - val_acc: 0.8614\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3758 - acc: 0.8193 - val_loss: 0.3461 - val_acc: 0.8614\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3581 - acc: 0.8168 - val_loss: 0.3504 - val_acc: 0.8515\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3846 - acc: 0.7995 - val_loss: 0.3396 - val_acc: 0.8416\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3832 - acc: 0.8218 - val_loss: 0.3515 - val_acc: 0.8614\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3655 - acc: 0.8441 - val_loss: 0.3897 - val_acc: 0.8713\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3664 - acc: 0.8342 - val_loss: 0.3743 - val_acc: 0.8713\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3539 - acc: 0.7946 - val_loss: 0.3510 - val_acc: 0.8218\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3665 - acc: 0.7871 - val_loss: 0.3727 - val_acc: 0.8713\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3606 - acc: 0.8193 - val_loss: 0.3545 - val_acc: 0.8515\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3694 - acc: 0.8416 - val_loss: 0.4505 - val_acc: 0.7327\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3558 - acc: 0.8168 - val_loss: 0.3714 - val_acc: 0.8614\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3279 - acc: 0.8119 - val_loss: 0.3376 - val_acc: 0.8218\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3960 - acc: 0.7822 - val_loss: 0.3392 - val_acc: 0.8317\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4005 - acc: 0.7921 - val_loss: 0.4207 - val_acc: 0.8218\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3749 - acc: 0.8144 - val_loss: 0.3581 - val_acc: 0.8614\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3483 - acc: 0.8193 - val_loss: 0.3977 - val_acc: 0.8515\n",
      "[[65 10]\n",
      " [ 5 21]]\n",
      "[[65 10]\n",
      " [ 5 21]]\n",
      "results :  pre = 0.677,acc = 0.851,rec = 0.808,f1 = 0.737,auc = 0.928,aupr = 0.826,auprc = 0.822\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_217 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_218 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_219 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_221 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_222 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 5s 13ms/step - loss: 0.6188 - acc: 0.4059 - val_loss: 0.6862 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6149 - acc: 0.7351 - val_loss: 0.6711 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6131 - acc: 0.7351 - val_loss: 0.6589 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6513 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6436 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6467 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6445 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6445 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6409 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6420 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6378 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6432 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6422 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6134 - acc: 0.7351 - val_loss: 0.6409 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6406 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6454 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6106 - acc: 0.7351 - val_loss: 0.6446 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6470 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6104 - acc: 0.7351 - val_loss: 0.6420 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6377 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6424 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6464 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6464 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6447 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6431 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6406 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6429 - val_acc: 0.7327\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6429 - val_acc: 0.7327\n",
      "Epoch 29/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6096 - acc: 0.7351 - val_loss: 0.6436 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6434 - val_acc: 0.7327\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6399 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6441 - val_acc: 0.7327\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6102 - acc: 0.7351 - val_loss: 0.6405 - val_acc: 0.7327\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6464 - val_acc: 0.7327\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6082 - acc: 0.7351 - val_loss: 0.6420 - val_acc: 0.7327\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6441 - val_acc: 0.7327\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6084 - acc: 0.7351 - val_loss: 0.6388 - val_acc: 0.7327\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6084 - acc: 0.7351 - val_loss: 0.6411 - val_acc: 0.7327\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6075 - acc: 0.7351 - val_loss: 0.6439 - val_acc: 0.7327\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6058 - acc: 0.7351 - val_loss: 0.6392 - val_acc: 0.7327\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6061 - acc: 0.7351 - val_loss: 0.6354 - val_acc: 0.7327\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6052 - acc: 0.7351 - val_loss: 0.6299 - val_acc: 0.7327\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6038 - acc: 0.7401 - val_loss: 0.6452 - val_acc: 0.7327\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5984 - acc: 0.7351 - val_loss: 0.6233 - val_acc: 0.7327\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5993 - acc: 0.7351 - val_loss: 0.6225 - val_acc: 0.7327\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5972 - acc: 0.7277 - val_loss: 0.6428 - val_acc: 0.7327\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5950 - acc: 0.7054 - val_loss: 0.6321 - val_acc: 0.7327\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5993 - acc: 0.7351 - val_loss: 0.5982 - val_acc: 0.7327\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5911 - acc: 0.7277 - val_loss: 0.6353 - val_acc: 0.7426\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5928 - acc: 0.6980 - val_loss: 0.6118 - val_acc: 0.7327\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5877 - acc: 0.7153 - val_loss: 0.6056 - val_acc: 0.7327\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5756 - acc: 0.7624 - val_loss: 0.6037 - val_acc: 0.7327\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5725 - acc: 0.7624 - val_loss: 0.5955 - val_acc: 0.7525\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5623 - acc: 0.7624 - val_loss: 0.5870 - val_acc: 0.7723\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5535 - acc: 0.7525 - val_loss: 0.5832 - val_acc: 0.7921\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5585 - acc: 0.6980 - val_loss: 0.5402 - val_acc: 0.7327\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5409 - acc: 0.7401 - val_loss: 0.5446 - val_acc: 0.7624\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5343 - acc: 0.7327 - val_loss: 0.5408 - val_acc: 0.8020\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5270 - acc: 0.7970 - val_loss: 0.5497 - val_acc: 0.7723\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5183 - acc: 0.7401 - val_loss: 0.5030 - val_acc: 0.7921\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5067 - acc: 0.7153 - val_loss: 0.5030 - val_acc: 0.8119\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4928 - acc: 0.7896 - val_loss: 0.4773 - val_acc: 0.7723\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4867 - acc: 0.7723 - val_loss: 0.5577 - val_acc: 0.6832\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5016 - acc: 0.7649 - val_loss: 0.5130 - val_acc: 0.7921\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5002 - acc: 0.7129 - val_loss: 0.4705 - val_acc: 0.8218\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4787 - acc: 0.7129 - val_loss: 0.4544 - val_acc: 0.7921\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4737 - acc: 0.7748 - val_loss: 0.4941 - val_acc: 0.7723\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4666 - acc: 0.7450 - val_loss: 0.4441 - val_acc: 0.8119\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4508 - acc: 0.7847 - val_loss: 0.4425 - val_acc: 0.8317\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4751 - acc: 0.7847 - val_loss: 0.4930 - val_acc: 0.7129\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4583 - acc: 0.7450 - val_loss: 0.4292 - val_acc: 0.8119\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4570 - acc: 0.7748 - val_loss: 0.4262 - val_acc: 0.8020\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4476 - acc: 0.7995 - val_loss: 0.4279 - val_acc: 0.8416\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4573 - acc: 0.7550 - val_loss: 0.4206 - val_acc: 0.8317\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4562 - acc: 0.7847 - val_loss: 0.4323 - val_acc: 0.8020\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4931 - acc: 0.6881 - val_loss: 0.4438 - val_acc: 0.7921\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4630 - acc: 0.7426 - val_loss: 0.4289 - val_acc: 0.8119\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4274 - acc: 0.7748 - val_loss: 0.4302 - val_acc: 0.7921\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4264 - acc: 0.7946 - val_loss: 0.4625 - val_acc: 0.8119\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4251 - acc: 0.7896 - val_loss: 0.4116 - val_acc: 0.8515\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4456 - acc: 0.7748 - val_loss: 0.4104 - val_acc: 0.8317\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4389 - acc: 0.7649 - val_loss: 0.4102 - val_acc: 0.8020\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4291 - acc: 0.7896 - val_loss: 0.4170 - val_acc: 0.8119\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3932 - acc: 0.8119 - val_loss: 0.4251 - val_acc: 0.7921\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4265 - acc: 0.7995 - val_loss: 0.4098 - val_acc: 0.8020\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4109 - acc: 0.7946 - val_loss: 0.4130 - val_acc: 0.8020\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3865 - acc: 0.7970 - val_loss: 0.3993 - val_acc: 0.8416\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4359 - acc: 0.7970 - val_loss: 0.4078 - val_acc: 0.8020\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.4221 - acc: 0.752 - 1s 2ms/step - loss: 0.4279 - acc: 0.7500 - val_loss: 0.4034 - val_acc: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3929 - acc: 0.8465 - val_loss: 0.4815 - val_acc: 0.7129\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4559 - acc: 0.7178 - val_loss: 0.4080 - val_acc: 0.8020\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4295 - acc: 0.7277 - val_loss: 0.3980 - val_acc: 0.8218\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4234 - acc: 0.8193 - val_loss: 0.5319 - val_acc: 0.6337\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3976 - acc: 0.7871 - val_loss: 0.4000 - val_acc: 0.8020\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3974 - acc: 0.7970 - val_loss: 0.4081 - val_acc: 0.8020\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3960 - acc: 0.8144 - val_loss: 0.3922 - val_acc: 0.8416\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4172 - acc: 0.7946 - val_loss: 0.3995 - val_acc: 0.8020\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3894 - acc: 0.8020 - val_loss: 0.3894 - val_acc: 0.8416\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4039 - acc: 0.7822 - val_loss: 0.3861 - val_acc: 0.8218\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3775 - acc: 0.8342 - val_loss: 0.3893 - val_acc: 0.8020\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3882 - acc: 0.8144 - val_loss: 0.4141 - val_acc: 0.8317\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4446 - acc: 0.7351 - val_loss: 0.4168 - val_acc: 0.8317\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3933 - acc: 0.8193 - val_loss: 0.3945 - val_acc: 0.8119\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3810 - acc: 0.8020 - val_loss: 0.3866 - val_acc: 0.8317\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4099 - acc: 0.7797 - val_loss: 0.4087 - val_acc: 0.8020\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 0s 997us/step - loss: 0.4008 - acc: 0.7995 - val_loss: 0.3945 - val_acc: 0.8119\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3745 - acc: 0.8441 - val_loss: 0.4044 - val_acc: 0.8119\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3710 - acc: 0.8193 - val_loss: 0.4020 - val_acc: 0.8119\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3769 - acc: 0.7896 - val_loss: 0.3862 - val_acc: 0.8119\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3751 - acc: 0.7946 - val_loss: 0.4242 - val_acc: 0.7921\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3777 - acc: 0.8366 - val_loss: 0.3926 - val_acc: 0.8119\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3871 - acc: 0.7995 - val_loss: 0.3807 - val_acc: 0.8119\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3967 - acc: 0.7599 - val_loss: 0.3919 - val_acc: 0.8020\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3601 - acc: 0.8094 - val_loss: 0.3731 - val_acc: 0.8416\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3771 - acc: 0.8267 - val_loss: 0.3751 - val_acc: 0.8119\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3818 - acc: 0.7871 - val_loss: 0.3774 - val_acc: 0.8119\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3601 - acc: 0.8342 - val_loss: 0.4027 - val_acc: 0.8515\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3757 - acc: 0.8218 - val_loss: 0.3839 - val_acc: 0.8218\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3735 - acc: 0.8119 - val_loss: 0.3711 - val_acc: 0.8119\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3492 - acc: 0.8366 - val_loss: 0.3834 - val_acc: 0.8119\n",
      "[[73  1]\n",
      " [18  9]]\n",
      "[[73  1]\n",
      " [18  9]]\n",
      "results :  pre = 0.9,acc = 0.812,rec = 0.333,f1 = 0.486,auc = 0.896,aupr = 0.791,auprc = 0.787\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_223 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_224 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_226 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_227 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_228 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 6s 15ms/step - loss: 0.6152 - acc: 0.7079 - val_loss: 0.6652 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6459 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6410 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6126 - acc: 0.7351 - val_loss: 0.6421 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6128 - acc: 0.7351 - val_loss: 0.6426 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6126 - acc: 0.7351 - val_loss: 0.6510 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6512 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6425 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6414 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6405 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6370 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6139 - acc: 0.7351 - val_loss: 0.6553 - val_acc: 0.7327\n",
      "Epoch 13/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6515 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6489 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6397 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6102 - acc: 0.7351 - val_loss: 0.6373 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6390 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6506 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6094 - acc: 0.7351 - val_loss: 0.6425 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6103 - acc: 0.7351 - val_loss: 0.6427 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6403 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6098 - acc: 0.7351 - val_loss: 0.6453 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6094 - acc: 0.7351 - val_loss: 0.6456 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6084 - acc: 0.7351 - val_loss: 0.6392 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6063 - acc: 0.7351 - val_loss: 0.6525 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6067 - acc: 0.7351 - val_loss: 0.6521 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6059 - acc: 0.7351 - val_loss: 0.6395 - val_acc: 0.7327\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6041 - acc: 0.7376 - val_loss: 0.6436 - val_acc: 0.7327\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6078 - acc: 0.7351 - val_loss: 0.6415 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6050 - acc: 0.7351 - val_loss: 0.6269 - val_acc: 0.7327\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6041 - acc: 0.7351 - val_loss: 0.6322 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6001 - acc: 0.7252 - val_loss: 0.6603 - val_acc: 0.7228\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5992 - acc: 0.7426 - val_loss: 0.6239 - val_acc: 0.7327\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5936 - acc: 0.7401 - val_loss: 0.6436 - val_acc: 0.7327\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5922 - acc: 0.7450 - val_loss: 0.6513 - val_acc: 0.7327\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5884 - acc: 0.7426 - val_loss: 0.6165 - val_acc: 0.7327\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5927 - acc: 0.6807 - val_loss: 0.6688 - val_acc: 0.7723\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5855 - acc: 0.7252 - val_loss: 0.6167 - val_acc: 0.7327\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5842 - acc: 0.7475 - val_loss: 0.6373 - val_acc: 0.7525\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5778 - acc: 0.7698 - val_loss: 0.6178 - val_acc: 0.7327\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5648 - acc: 0.7847 - val_loss: 0.6116 - val_acc: 0.7426\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5667 - acc: 0.7327 - val_loss: 0.6003 - val_acc: 0.7327\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5574 - acc: 0.7351 - val_loss: 0.6104 - val_acc: 0.7624\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5698 - acc: 0.7550 - val_loss: 0.6131 - val_acc: 0.7624\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5492 - acc: 0.7500 - val_loss: 0.5764 - val_acc: 0.7426\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5516 - acc: 0.7376 - val_loss: 0.6278 - val_acc: 0.7723\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5436 - acc: 0.6881 - val_loss: 0.5894 - val_acc: 0.7822\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5392 - acc: 0.7574 - val_loss: 0.6055 - val_acc: 0.7525\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5140 - acc: 0.7277 - val_loss: 0.5340 - val_acc: 0.7426\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5389 - acc: 0.7005 - val_loss: 0.6579 - val_acc: 0.4950\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5355 - acc: 0.7228 - val_loss: 0.5530 - val_acc: 0.7921\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4935 - acc: 0.7351 - val_loss: 0.5176 - val_acc: 0.7624\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5294 - acc: 0.7599 - val_loss: 0.6653 - val_acc: 0.4950\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5236 - acc: 0.6931 - val_loss: 0.5394 - val_acc: 0.7723\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4880 - acc: 0.7475 - val_loss: 0.5072 - val_acc: 0.7525\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4802 - acc: 0.8020 - val_loss: 0.5068 - val_acc: 0.7426\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4920 - acc: 0.7525 - val_loss: 0.4899 - val_acc: 0.7624\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5096 - acc: 0.7426 - val_loss: 0.5048 - val_acc: 0.7921\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5066 - acc: 0.6807 - val_loss: 0.4732 - val_acc: 0.7624\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4786 - acc: 0.7228 - val_loss: 0.5024 - val_acc: 0.7921\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4911 - acc: 0.7178 - val_loss: 0.5262 - val_acc: 0.7822\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4722 - acc: 0.7376 - val_loss: 0.5842 - val_acc: 0.6139\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4579 - acc: 0.7772 - val_loss: 0.5091 - val_acc: 0.7822\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4643 - acc: 0.7228 - val_loss: 0.4599 - val_acc: 0.8020\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4738 - acc: 0.7624 - val_loss: 0.4805 - val_acc: 0.8020\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4533 - acc: 0.7525 - val_loss: 0.4546 - val_acc: 0.8020\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4465 - acc: 0.7896 - val_loss: 0.4736 - val_acc: 0.8020\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4257 - acc: 0.8045 - val_loss: 0.4514 - val_acc: 0.8119\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4696 - acc: 0.7624 - val_loss: 0.5089 - val_acc: 0.7921\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4411 - acc: 0.7871 - val_loss: 0.4335 - val_acc: 0.8020\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4291 - acc: 0.7822 - val_loss: 0.4309 - val_acc: 0.7723\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4721 - acc: 0.7426 - val_loss: 0.5489 - val_acc: 0.6733\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4556 - acc: 0.7649 - val_loss: 0.4663 - val_acc: 0.7921\n",
      "Epoch 74/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4230 - acc: 0.7995 - val_loss: 0.4412 - val_acc: 0.8119\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4146 - acc: 0.7896 - val_loss: 0.4809 - val_acc: 0.8020\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4284 - acc: 0.8020 - val_loss: 0.4593 - val_acc: 0.8119\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4235 - acc: 0.7995 - val_loss: 0.4090 - val_acc: 0.7921\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4202 - acc: 0.7351 - val_loss: 0.4097 - val_acc: 0.8119\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3991 - acc: 0.8119 - val_loss: 0.4389 - val_acc: 0.8218\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4252 - acc: 0.7871 - val_loss: 0.5161 - val_acc: 0.6931\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4204 - acc: 0.7748 - val_loss: 0.4214 - val_acc: 0.8218\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4153 - acc: 0.8020 - val_loss: 0.4273 - val_acc: 0.8218\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4231 - acc: 0.7649 - val_loss: 0.4237 - val_acc: 0.8119\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3692 - acc: 0.8267 - val_loss: 0.3930 - val_acc: 0.8020\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4117 - acc: 0.7748 - val_loss: 0.4116 - val_acc: 0.7822\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4506 - acc: 0.7277 - val_loss: 0.3936 - val_acc: 0.8119\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4426 - acc: 0.7797 - val_loss: 0.4975 - val_acc: 0.7030\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3832 - acc: 0.8243 - val_loss: 0.4319 - val_acc: 0.8020\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3937 - acc: 0.8069 - val_loss: 0.3938 - val_acc: 0.8119\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4049 - acc: 0.7970 - val_loss: 0.4087 - val_acc: 0.8218\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3980 - acc: 0.8317 - val_loss: 0.5654 - val_acc: 0.6535\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4314 - acc: 0.7624 - val_loss: 0.3976 - val_acc: 0.8317\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4002 - acc: 0.7797 - val_loss: 0.3867 - val_acc: 0.7921\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4272 - acc: 0.7698 - val_loss: 0.3833 - val_acc: 0.7921\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3939 - acc: 0.8292 - val_loss: 0.4493 - val_acc: 0.8119\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4032 - acc: 0.7921 - val_loss: 0.4004 - val_acc: 0.8119\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3657 - acc: 0.8317 - val_loss: 0.3815 - val_acc: 0.8020\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3907 - acc: 0.7970 - val_loss: 0.3831 - val_acc: 0.8020\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3418 - acc: 0.8614 - val_loss: 0.4999 - val_acc: 0.6931\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3943 - acc: 0.8069 - val_loss: 0.4513 - val_acc: 0.8218\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3868 - acc: 0.8144 - val_loss: 0.4149 - val_acc: 0.8317\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3772 - acc: 0.7871 - val_loss: 0.3969 - val_acc: 0.8119\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3515 - acc: 0.8639 - val_loss: 0.4996 - val_acc: 0.6931\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3704 - acc: 0.8218 - val_loss: 0.4098 - val_acc: 0.8416\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3777 - acc: 0.8168 - val_loss: 0.3748 - val_acc: 0.8020\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3773 - acc: 0.8119 - val_loss: 0.4536 - val_acc: 0.8119\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3830 - acc: 0.7970 - val_loss: 0.3806 - val_acc: 0.8218\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4127 - acc: 0.7847 - val_loss: 0.3829 - val_acc: 0.8218\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4075 - acc: 0.7946 - val_loss: 0.3850 - val_acc: 0.7921\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3804 - acc: 0.7847 - val_loss: 0.3679 - val_acc: 0.7921\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4014 - acc: 0.8020 - val_loss: 0.3734 - val_acc: 0.8020\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3895 - acc: 0.7723 - val_loss: 0.3694 - val_acc: 0.8218\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3769 - acc: 0.7921 - val_loss: 0.4157 - val_acc: 0.8218\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3754 - acc: 0.8342 - val_loss: 0.3858 - val_acc: 0.8317\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3707 - acc: 0.7995 - val_loss: 0.3645 - val_acc: 0.8119\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3591 - acc: 0.8465 - val_loss: 0.3841 - val_acc: 0.8317\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3402 - acc: 0.8391 - val_loss: 0.3617 - val_acc: 0.7921\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3554 - acc: 0.8243 - val_loss: 0.3631 - val_acc: 0.8020\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3740 - acc: 0.8168 - val_loss: 0.3691 - val_acc: 0.8218\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3700 - acc: 0.8144 - val_loss: 0.3803 - val_acc: 0.8317\n",
      "[[65  9]\n",
      " [ 8 19]]\n",
      "[[65  9]\n",
      " [ 8 19]]\n",
      "results :  pre = 0.679,acc = 0.832,rec = 0.704,f1 = 0.691,auc = 0.896,aupr = 0.746,auprc = 0.747\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_229 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_230 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_231 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_232 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_233 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_234 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 6s 16ms/step - loss: 0.6159 - acc: 0.7228 - val_loss: 0.6606 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6503 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6384 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6116 - acc: 0.7351 - val_loss: 0.6415 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6407 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6136 - acc: 0.7351 - val_loss: 0.6455 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6475 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6125 - acc: 0.7351 - val_loss: 0.6452 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6131 - acc: 0.7351 - val_loss: 0.6409 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6483 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6470 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6446 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6441 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6407 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6418 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6444 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6445 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6470 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6478 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6464 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6483 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6411 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6506 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6130 - acc: 0.7351 - val_loss: 0.6408 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6480 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6516 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6092 - acc: 0.7351 - val_loss: 0.6393 - val_acc: 0.7327\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6105 - acc: 0.7351 - val_loss: 0.6373 - val_acc: 0.7327\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6096 - acc: 0.7351 - val_loss: 0.6422 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6085 - acc: 0.7351 - val_loss: 0.6405 - val_acc: 0.7327\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6079 - acc: 0.7351 - val_loss: 0.6457 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6385 - val_acc: 0.7327\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6074 - acc: 0.7351 - val_loss: 0.6424 - val_acc: 0.7327\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6058 - acc: 0.7351 - val_loss: 0.6269 - val_acc: 0.7327\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6025 - acc: 0.7351 - val_loss: 0.6438 - val_acc: 0.7327\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6045 - acc: 0.7401 - val_loss: 0.6420 - val_acc: 0.7327\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6024 - acc: 0.7351 - val_loss: 0.6281 - val_acc: 0.7327\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6008 - acc: 0.7351 - val_loss: 0.6253 - val_acc: 0.7327\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5972 - acc: 0.7525 - val_loss: 0.6440 - val_acc: 0.7426\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5957 - acc: 0.7550 - val_loss: 0.6379 - val_acc: 0.7426\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5886 - acc: 0.7550 - val_loss: 0.6165 - val_acc: 0.7327\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5809 - acc: 0.7450 - val_loss: 0.6179 - val_acc: 0.7426\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5768 - acc: 0.7624 - val_loss: 0.6093 - val_acc: 0.7426\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5689 - acc: 0.7673 - val_loss: 0.5908 - val_acc: 0.7426\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5691 - acc: 0.6683 - val_loss: 0.6072 - val_acc: 0.7525\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5738 - acc: 0.7475 - val_loss: 0.6279 - val_acc: 0.7327\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5673 - acc: 0.6114 - val_loss: 0.5751 - val_acc: 0.7525\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5510 - acc: 0.7599 - val_loss: 0.5816 - val_acc: 0.7525\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5545 - acc: 0.7401 - val_loss: 0.6099 - val_acc: 0.7129\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5485 - acc: 0.7649 - val_loss: 0.6041 - val_acc: 0.7129\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5385 - acc: 0.6955 - val_loss: 0.5717 - val_acc: 0.7327\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5214 - acc: 0.7698 - val_loss: 0.6396 - val_acc: 0.6040\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5162 - acc: 0.7153 - val_loss: 0.5398 - val_acc: 0.7822\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5176 - acc: 0.7376 - val_loss: 0.5528 - val_acc: 0.7327\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5168 - acc: 0.7822 - val_loss: 0.5620 - val_acc: 0.7228\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4967 - acc: 0.7450 - val_loss: 0.5074 - val_acc: 0.7624\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5297 - acc: 0.7599 - val_loss: 0.5435 - val_acc: 0.7228\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5011 - acc: 0.7327 - val_loss: 0.5046 - val_acc: 0.7921\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4966 - acc: 0.7698 - val_loss: 0.5523 - val_acc: 0.7327\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4870 - acc: 0.7574 - val_loss: 0.5392 - val_acc: 0.7228\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4908 - acc: 0.7426 - val_loss: 0.4939 - val_acc: 0.7921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4890 - acc: 0.7525 - val_loss: 0.5340 - val_acc: 0.7228\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4804 - acc: 0.7847 - val_loss: 0.6005 - val_acc: 0.6139\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4825 - acc: 0.7475 - val_loss: 0.5123 - val_acc: 0.7624\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4449 - acc: 0.7946 - val_loss: 0.5097 - val_acc: 0.7525\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4584 - acc: 0.7624 - val_loss: 0.5184 - val_acc: 0.7129\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4446 - acc: 0.7822 - val_loss: 0.4823 - val_acc: 0.7723\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4530 - acc: 0.7946 - val_loss: 0.5078 - val_acc: 0.7327\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4438 - acc: 0.7574 - val_loss: 0.4909 - val_acc: 0.7822\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4322 - acc: 0.7797 - val_loss: 0.4758 - val_acc: 0.7921\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4634 - acc: 0.7649 - val_loss: 0.5004 - val_acc: 0.7327\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4521 - acc: 0.7748 - val_loss: 0.4789 - val_acc: 0.7723\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4517 - acc: 0.7673 - val_loss: 0.4694 - val_acc: 0.7822\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4358 - acc: 0.7599 - val_loss: 0.4626 - val_acc: 0.8020\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4514 - acc: 0.7871 - val_loss: 0.4610 - val_acc: 0.7921\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4818 - acc: 0.7302 - val_loss: 0.4611 - val_acc: 0.8020\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4240 - acc: 0.7921 - val_loss: 0.5301 - val_acc: 0.7822\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4497 - acc: 0.7896 - val_loss: 0.5130 - val_acc: 0.7723\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4275 - acc: 0.7723 - val_loss: 0.4750 - val_acc: 0.7723\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4145 - acc: 0.7871 - val_loss: 0.4525 - val_acc: 0.8020\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4917 - acc: 0.7054 - val_loss: 0.4679 - val_acc: 0.7921\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4516 - acc: 0.7649 - val_loss: 0.5693 - val_acc: 0.6436\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4137 - acc: 0.8144 - val_loss: 0.5117 - val_acc: 0.7921\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4341 - acc: 0.7698 - val_loss: 0.4945 - val_acc: 0.7624\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4076 - acc: 0.8020 - val_loss: 0.4498 - val_acc: 0.7921\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.4073 - acc: 0.795 - 1s 2ms/step - loss: 0.4043 - acc: 0.7995 - val_loss: 0.4677 - val_acc: 0.7624\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3878 - acc: 0.8515 - val_loss: 0.4991 - val_acc: 0.7921\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3873 - acc: 0.8119 - val_loss: 0.4431 - val_acc: 0.7921\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3913 - acc: 0.8119 - val_loss: 0.4752 - val_acc: 0.7822\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4172 - acc: 0.7822 - val_loss: 0.4353 - val_acc: 0.7822\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4240 - acc: 0.7475 - val_loss: 0.4633 - val_acc: 0.8020\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4321 - acc: 0.7723 - val_loss: 0.5883 - val_acc: 0.5842\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3962 - acc: 0.8168 - val_loss: 0.4503 - val_acc: 0.7723\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3709 - acc: 0.8391 - val_loss: 0.4337 - val_acc: 0.7921\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4072 - acc: 0.8144 - val_loss: 0.4386 - val_acc: 0.7921\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3991 - acc: 0.8045 - val_loss: 0.4917 - val_acc: 0.7921\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4043 - acc: 0.8020 - val_loss: 0.4572 - val_acc: 0.7822\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3801 - acc: 0.8168 - val_loss: 0.4764 - val_acc: 0.8119\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4174 - acc: 0.7970 - val_loss: 0.4194 - val_acc: 0.7921\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3847 - acc: 0.7847 - val_loss: 0.4366 - val_acc: 0.8119\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3772 - acc: 0.7921 - val_loss: 0.4169 - val_acc: 0.8020\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3942 - acc: 0.8045 - val_loss: 0.4354 - val_acc: 0.8317\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3842 - acc: 0.8168 - val_loss: 0.4231 - val_acc: 0.8218\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.3560 - acc: 0.8099- ETA: 0s - loss: 0.3612 - acc: 0. - ETA: 0s - loss: 0.3593 - acc: 0.80 - 1s 1ms/step - loss: 0.3564 - acc: 0.8144 - val_loss: 0.4159 - val_acc: 0.8317\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3753 - acc: 0.8267 - val_loss: 0.4138 - val_acc: 0.8317\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3632 - acc: 0.8267 - val_loss: 0.4511 - val_acc: 0.8218\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3815 - acc: 0.7995 - val_loss: 0.4066 - val_acc: 0.8119\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3546 - acc: 0.8317 - val_loss: 0.4421 - val_acc: 0.8416\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3996 - acc: 0.7871 - val_loss: 0.4127 - val_acc: 0.8218\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3965 - acc: 0.7797 - val_loss: 0.4019 - val_acc: 0.8119\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4136 - acc: 0.7797 - val_loss: 0.4039 - val_acc: 0.8416\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3705 - acc: 0.8168 - val_loss: 0.4094 - val_acc: 0.8317\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3639 - acc: 0.8094 - val_loss: 0.4021 - val_acc: 0.8317\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3556 - acc: 0.8193 - val_loss: 0.3957 - val_acc: 0.8317\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3636 - acc: 0.8342 - val_loss: 0.3954 - val_acc: 0.8218\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3812 - acc: 0.7946 - val_loss: 0.3921 - val_acc: 0.8218\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4039 - acc: 0.7847 - val_loss: 0.4124 - val_acc: 0.8317\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3686 - acc: 0.8045 - val_loss: 0.3955 - val_acc: 0.8515\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3432 - acc: 0.8441 - val_loss: 0.3978 - val_acc: 0.8416\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3577 - acc: 0.8490 - val_loss: 0.4168 - val_acc: 0.8614\n",
      "[[66  8]\n",
      " [ 6 21]]\n",
      "[[66  8]\n",
      " [ 6 21]]\n",
      "results :  pre = 0.724,acc = 0.861,rec = 0.778,f1 = 0.75,auc = 0.875,aupr = 0.775,auprc = 0.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_235 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_236 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_237 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_238 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_239 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_240 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 6s 15ms/step - loss: 0.6167 - acc: 0.7153 - val_loss: 0.6729 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6508 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6445 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6378 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6135 - acc: 0.7351 - val_loss: 0.6422 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6103 - acc: 0.7351 - val_loss: 0.6412 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6449 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6125 - acc: 0.7351 - val_loss: 0.6458 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6085 - acc: 0.7351 - val_loss: 0.6377 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6351 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6411 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6132 - acc: 0.7351 - val_loss: 0.6473 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6106 - acc: 0.7351 - val_loss: 0.6476 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6440 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6417 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6467 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6125 - acc: 0.7351 - val_loss: 0.6461 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6444 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6103 - acc: 0.7351 - val_loss: 0.6410 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6126 - acc: 0.7351 - val_loss: 0.6421 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6452 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6451 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6409 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6497 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6427 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6484 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6103 - acc: 0.7351 - val_loss: 0.6457 - val_acc: 0.7327\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6095 - acc: 0.7351 - val_loss: 0.6408 - val_acc: 0.7327\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6096 - acc: 0.7351 - val_loss: 0.6444 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6080 - acc: 0.7351 - val_loss: 0.6375 - val_acc: 0.7327\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6080 - acc: 0.7351 - val_loss: 0.6394 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6074 - acc: 0.7351 - val_loss: 0.6380 - val_acc: 0.7327\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6070 - acc: 0.7351 - val_loss: 0.6393 - val_acc: 0.7327\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6076 - acc: 0.7376 - val_loss: 0.6503 - val_acc: 0.7327\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6042 - acc: 0.7351 - val_loss: 0.6167 - val_acc: 0.7327\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6043 - acc: 0.7401 - val_loss: 0.6399 - val_acc: 0.7327\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6011 - acc: 0.7426 - val_loss: 0.6403 - val_acc: 0.7327\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5967 - acc: 0.7401 - val_loss: 0.6315 - val_acc: 0.7327\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5947 - acc: 0.7450 - val_loss: 0.6398 - val_acc: 0.7426\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5886 - acc: 0.7525 - val_loss: 0.6169 - val_acc: 0.7426\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5885 - acc: 0.7475 - val_loss: 0.6172 - val_acc: 0.7426\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5940 - acc: 0.6609 - val_loss: 0.6211 - val_acc: 0.7525\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5735 - acc: 0.7772 - val_loss: 0.6050 - val_acc: 0.7426\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5734 - acc: 0.7723 - val_loss: 0.6195 - val_acc: 0.7525\n",
      "Epoch 45/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5771 - acc: 0.6287 - val_loss: 0.5917 - val_acc: 0.7624\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5607 - acc: 0.7649 - val_loss: 0.6229 - val_acc: 0.7327\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5783 - acc: 0.5644 - val_loss: 0.5664 - val_acc: 0.7525\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5706 - acc: 0.7649 - val_loss: 0.6267 - val_acc: 0.7228\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5515 - acc: 0.6485 - val_loss: 0.5789 - val_acc: 0.7624\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5490 - acc: 0.7450 - val_loss: 0.5848 - val_acc: 0.7426\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5406 - acc: 0.7450 - val_loss: 0.5964 - val_acc: 0.7624\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5333 - acc: 0.7475 - val_loss: 0.5661 - val_acc: 0.7426\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5178 - acc: 0.7797 - val_loss: 0.5802 - val_acc: 0.7624\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5109 - acc: 0.7772 - val_loss: 0.5658 - val_acc: 0.7624\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4948 - acc: 0.7599 - val_loss: 0.5290 - val_acc: 0.7723\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.5090 - acc: 0.6980 - val_loss: 0.4994 - val_acc: 0.7624\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5005 - acc: 0.7748 - val_loss: 0.6234 - val_acc: 0.6337\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4899 - acc: 0.7723 - val_loss: 0.5752 - val_acc: 0.7426\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4765 - acc: 0.7574 - val_loss: 0.4925 - val_acc: 0.7723\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4885 - acc: 0.7426 - val_loss: 0.4882 - val_acc: 0.7624\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4989 - acc: 0.7426 - val_loss: 0.5066 - val_acc: 0.7723\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4739 - acc: 0.7450 - val_loss: 0.5249 - val_acc: 0.7822\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4710 - acc: 0.7871 - val_loss: 0.4994 - val_acc: 0.7822\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4824 - acc: 0.7748 - val_loss: 0.5608 - val_acc: 0.7129\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4780 - acc: 0.7327 - val_loss: 0.4634 - val_acc: 0.7624\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4813 - acc: 0.7129 - val_loss: 0.4615 - val_acc: 0.7624\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4897 - acc: 0.7550 - val_loss: 0.4856 - val_acc: 0.7921\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4353 - acc: 0.7723 - val_loss: 0.4699 - val_acc: 0.8119\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4531 - acc: 0.8094 - val_loss: 0.4783 - val_acc: 0.8119\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4630 - acc: 0.7673 - val_loss: 0.5007 - val_acc: 0.7921\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4597 - acc: 0.7574 - val_loss: 0.5007 - val_acc: 0.8119\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4275 - acc: 0.7970 - val_loss: 0.4462 - val_acc: 0.8119\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4109 - acc: 0.7847 - val_loss: 0.4400 - val_acc: 0.7822\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4563 - acc: 0.7450 - val_loss: 0.4312 - val_acc: 0.8020\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4758 - acc: 0.7401 - val_loss: 0.4474 - val_acc: 0.8218\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4381 - acc: 0.8218 - val_loss: 0.5979 - val_acc: 0.5941\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4387 - acc: 0.7698 - val_loss: 0.4312 - val_acc: 0.8218\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4092 - acc: 0.7946 - val_loss: 0.4525 - val_acc: 0.8317\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4345 - acc: 0.7896 - val_loss: 0.4488 - val_acc: 0.8317\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4419 - acc: 0.7574 - val_loss: 0.4212 - val_acc: 0.8020\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4251 - acc: 0.7995 - val_loss: 0.4594 - val_acc: 0.8416\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4206 - acc: 0.8317 - val_loss: 0.5488 - val_acc: 0.6832\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4503 - acc: 0.7649 - val_loss: 0.4637 - val_acc: 0.8119\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4244 - acc: 0.7772 - val_loss: 0.4735 - val_acc: 0.7921\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4104 - acc: 0.8045 - val_loss: 0.4709 - val_acc: 0.7822\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4254 - acc: 0.7624 - val_loss: 0.4134 - val_acc: 0.8218\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3856 - acc: 0.8069 - val_loss: 0.4215 - val_acc: 0.7822\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4117 - acc: 0.8045 - val_loss: 0.4367 - val_acc: 0.8515\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3840 - acc: 0.8193 - val_loss: 0.4370 - val_acc: 0.8515\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3867 - acc: 0.8218 - val_loss: 0.4143 - val_acc: 0.7723\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3968 - acc: 0.7946 - val_loss: 0.4968 - val_acc: 0.7129\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3911 - acc: 0.8144 - val_loss: 0.4312 - val_acc: 0.8515\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3543 - acc: 0.8020 - val_loss: 0.4105 - val_acc: 0.7822\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4239 - acc: 0.7797 - val_loss: 0.4050 - val_acc: 0.8020\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3904 - acc: 0.7847 - val_loss: 0.4055 - val_acc: 0.8020\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3804 - acc: 0.8243 - val_loss: 0.4043 - val_acc: 0.8119\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3730 - acc: 0.8045 - val_loss: 0.4020 - val_acc: 0.7921\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3611 - acc: 0.8441 - val_loss: 0.4384 - val_acc: 0.8020\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4099 - acc: 0.7995 - val_loss: 0.4138 - val_acc: 0.8515\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3702 - acc: 0.8515 - val_loss: 0.4069 - val_acc: 0.8416\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3951 - acc: 0.8243 - val_loss: 0.4328 - val_acc: 0.8119\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3857 - acc: 0.7921 - val_loss: 0.3923 - val_acc: 0.8218\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3858 - acc: 0.8069 - val_loss: 0.3918 - val_acc: 0.8119\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3850 - acc: 0.7970 - val_loss: 0.3944 - val_acc: 0.8317\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.4347 - acc: 0.7550 - val_loss: 0.3886 - val_acc: 0.8218\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3918 - acc: 0.8094 - val_loss: 0.4081 - val_acc: 0.8515\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3687 - acc: 0.8416 - val_loss: 0.4622 - val_acc: 0.7426\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3936 - acc: 0.8094 - val_loss: 0.4110 - val_acc: 0.8119\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3501 - acc: 0.8243 - val_loss: 0.3864 - val_acc: 0.8119\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3739 - acc: 0.7896 - val_loss: 0.4201 - val_acc: 0.8119\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3768 - acc: 0.8193 - val_loss: 0.4816 - val_acc: 0.7327\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3847 - acc: 0.7896 - val_loss: 0.4126 - val_acc: 0.8119\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3676 - acc: 0.8119 - val_loss: 0.3954 - val_acc: 0.7921\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3769 - acc: 0.8243 - val_loss: 0.3842 - val_acc: 0.8317TA: 0s - loss: 0.3537 - acc: 0.829\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3514 - acc: 0.8243 - val_loss: 0.4004 - val_acc: 0.8218\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3644 - acc: 0.8391 - val_loss: 0.3958 - val_acc: 0.8317\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3205 - acc: 0.8342 - val_loss: 0.3964 - val_acc: 0.7921\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3630 - acc: 0.8193 - val_loss: 0.4140 - val_acc: 0.8119\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3485 - acc: 0.8366 - val_loss: 0.3901 - val_acc: 0.7921\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.3467 - acc: 0.8243 - val_loss: 0.3899 - val_acc: 0.8416\n",
      "[[70  4]\n",
      " [12 15]]\n",
      "[[70  4]\n",
      " [12 15]]\n",
      "results :  pre = 0.789,acc = 0.842,rec = 0.556,f1 = 0.652,auc = 0.896,aupr = 0.766,auprc = 0.764\n",
      "average value :  pre = 0.754,acc = 0.84,rec = 0.636,f1 = 0.663,auc = 0.898,aupr = 0.781,auprc = 0.779\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590)\n",
    "\n",
    "# random.seed(5)\n",
    "# total_score = []\n",
    "# for i in range(0,5):\n",
    "kfscore = []\n",
    "for train_index, test_index in skf.split(single_x, single_y):\n",
    "    X_train, X_test = single_x[train_index], single_x[test_index]\n",
    "    y_train, y_test = single_y[train_index], single_y[test_index]\n",
    "\n",
    "    single_model = create_model(single_x)\n",
    "\n",
    "    single_model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=120,class_weight={0:0.68,1:1.48},batch_size = 32)  #epochs=50,class_weight={0:0.5,1:1.35},batch_size = 64\n",
    "    y_pred = single_model.predict(X_test)\n",
    "    kfscore.append(evaluates(y_test, y_pred))\n",
    "    results = evaluates(y_test, y_pred)\n",
    "    print(\"results :  pre = {},acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(results[0],3),round(results[1],3),round(results[2],3),round(results[3],3),round(results[4],3),round(results[5],3),round(results[6],3)))\n",
    "\n",
    "\n",
    "#平均值\n",
    "kfscores = np.array(kfscore).sum(axis= 0)/5.0\n",
    "print(\"average value :  pre = {},acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(kfscores[0],3),round(kfscores[1],3),round(kfscores[2],3),round(kfscores[3],3),round(kfscores[4],3),round(kfscores[5],3),round(kfscores[6],3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两种组学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# express_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_amp = Omics_data.swaplevel(i=0, j=1, axis=1)[['snv_data','cnv_amp']].swaplevel(i=0, j=1, axis=1)\n",
    "snv_amp_order = snv_amp.columns.levels[0]\n",
    "snv_amp = snv_amp.reindex(columns=snv_amp_order, level=0)\n",
    "multi_x  = snv_amp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590) \n",
    "kfscore = []\n",
    "for train_index, test_index in skf.split(multi_x, y):\n",
    "\n",
    "    X_train, X_test = multi_x[train_index], multi_x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = create_model(multi_x)\n",
    "\n",
    "    model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=120,class_weight={0:0.68,1:1.48},batch_size = 32)  #epochs=50,class_weight={0:0.5,1:1.35},batch_size = 64\n",
    "    y_pred = model.predict(X_test)\n",
    "    kfscore.append(evaluates(y_test, y_pred))\n",
    "    results = evaluates(y_test, y_pred)\n",
    "    print(\"results :  pre = {},acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(results[0],3),round(results[1],3),round(results[2],3),round(results[3],3),round(results[4],3),round(results[5],3),round(results[6],3)))\n",
    "\n",
    "    \n",
    "kfscores = np.array(kfscore).sum(axis= 0)/5.0\n",
    "print(\"average value :  pre = {},acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(kfscores[0],3),round(kfscores[1],3),round(kfscores[2],3),round(kfscores[3],3),round(kfscores[4],3),round(kfscores[5],3),round(kfscores[6],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_del = Omics_data.swaplevel(i=0, j=1, axis=1)[['snv_data','cnv_del']].swaplevel(i=0, j=1, axis=1)\n",
    "snv_del_order = snv_del.columns.levels[0]\n",
    "snv_del = snv_del.reindex(columns=snv_del_order, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_del_x  = snv_del.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590) #,shuffle=True\n",
    "\n",
    "\n",
    "total_score  = []\n",
    "for i in range(0,5):\n",
    "    kfscore = []\n",
    "    for train_index, test_index in skf.split(snv_del_x, y):\n",
    "\n",
    "        X_train, X_test = snv_del_x[train_index], snv_del_x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = create__multi_model(snv_del_x)\n",
    "\n",
    "\n",
    "\n",
    "        model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=120,class_weight={0:0.68,1:1.48},batch_size = 32)  #epochs=50,class_weight={0:0.5,1:1.35},batch_size = 64\n",
    "        y_pred = model.predict(X_test)\n",
    "        kfscore.append(evaluates(y_test, y_pred))\n",
    "        print(evaluates(y_test, y_pred))\n",
    "\n",
    "        temp_pd =pd.DataFrame()\n",
    "        temp_pd['sample'] = sample_pro.loc[test_index]['sample'].values\n",
    "\n",
    "        temp_pd['values'] = y_pred\n",
    "\n",
    "        total_pd = pd.concat([total_pd,temp_pd],axis=0)\n",
    "\n",
    "    kfscore = np.array(kfscore).sum(axis= 0)/5.0\n",
    "    total_score.append(kfscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0:x_0,1:x_1}\n",
    "compare_models = [\n",
    "    {\n",
    "        'type': 'sgd',\n",
    "        'id': 'L2 Logistic Regression',\n",
    "        'params': {'loss': 'log', 'penalty': 'l2', 'alpha': 0.01, 'class_weight': class_weight}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'svc',\n",
    "        'id': 'RBF Support Vector Machine ',\n",
    "        'params': {'kernel': 'rbf', 'gamma': 0.001, 'probability': True, 'class_weight': class_weight}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'svc', 'id':\n",
    "        'Linear Support Vector Machine ',\n",
    "        'params': { 'kernel': 'linear','C': 0.1, 'probability': True, 'class_weight': class_weight}  \n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'random_forest',\n",
    "        'id': 'Random Forest',\n",
    "        'params': {'max_depth': None, 'n_estimators': 50, 'bootstrap': False, 'class_weight': class_weight}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'adaboost',\n",
    "        'id': 'Adaptive Boosting',\n",
    "        'params': {'learning_rate': 0.1, 'n_estimators': 50}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'decision_tree',\n",
    "        'id': 'Decision Tree',\n",
    "        'params': {'min_samples_split': 10, 'max_depth': 10}\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指标\n",
    "def get_metrics(true_score,pre_score,pre_probe):\n",
    "    \n",
    "  \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_score, pre_probe, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    aupr = average_precision_score(true_score, pre_probe)\n",
    "    \n",
    "    precision1, recall1, thresholds = precision_recall_curve(true_score, pre_probe)    \n",
    "    auprc  = metrics.auc(recall1, precision1)\n",
    "    \n",
    "    accuracy = accuracy_score(true_score,pre_score)\n",
    "    \n",
    "    f1 = metrics.f1_score(true_score, pre_score)\n",
    "    \n",
    "    precision = metrics.precision_score(true_score,pre_score)\n",
    "    \n",
    "    recall = metrics.recall_score(true_score,pre_score)\n",
    "    \n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============随机梯度下降法分类===============\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def Creat_SGD(whole_data_x,whole_data_y,train_index,test_index):\n",
    "    \n",
    "    model = SGDClassifier(**compare_models[0]['params'] )  #参数\n",
    "    \n",
    "    model.fit(whole_data_x[train_index],whole_data_y[train_index] )  # 训练模型\n",
    "    \n",
    "    true_score = whole_data_y[test_index] #真实标签\n",
    "    \n",
    "    pre_score = model.predict(whole_data_x[test_index]) #预测\n",
    "    \n",
    "    pre_probe = model.predict_proba(whole_data_x[test_index])[:, 1] #预测的概率\n",
    "    \n",
    "\n",
    "    precision,accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) #验证模型，获得指标\n",
    "    \n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============随机森林分类===============\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def Creat_RDF(whole_data_x,whole_data_y,train_index,test_index):\n",
    "     \n",
    "    model = RandomForestClassifier(**compare_models[3]['params'])  #定义模型\n",
    "\n",
    "    model.fit(whole_data_x[train_index],whole_data_y[train_index] )  # 训练模型\n",
    "    \n",
    "    true_score = whole_data_y[test_index] #真实标签\n",
    "    \n",
    "    pre_score = model.predict(whole_data_x[test_index]) #预测\n",
    "    \n",
    "    pre_probe = model.predict_proba(whole_data_x[test_index])[:, 1] #预测的概率\n",
    "    \n",
    "\n",
    "    precision,accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) #验证模型，获得指标\n",
    "    \n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============逻辑回归分类===============\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def Creat_LR(whole_data_x,whole_data_y,train_index,test_index):\n",
    "    \n",
    "    model =  LogisticRegression() \n",
    "\n",
    "    model.fit(whole_data_x[train_index],whole_data_y[train_index] )  # 训练模型\n",
    "    \n",
    "    true_score = whole_data_y[test_index] #真实标签\n",
    "    \n",
    "    pre_score = model.predict(whole_data_x[test_index]) #预测\n",
    "    \n",
    "    pre_probe = model.predict_proba(whole_data_x[test_index])[:, 1] #预测的概率\n",
    "    \n",
    "\n",
    "    precision,accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) #验证模型，获得指标\n",
    "    \n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============决策树分类===============\n",
    "from sklearn import tree\n",
    " \n",
    "def Creat_DTC(whole_data_x,whole_data_y,train_index,test_index):\n",
    "    \n",
    "    DTC_model = tree.DecisionTreeClassifier() #实例化 #max_depth = 10\n",
    "    \n",
    "    DTC_model.fit(whole_data_x[train_index],whole_data_y[train_index] )  # 训练模型\n",
    "    \n",
    "    true_score = whole_data_y[test_index] #真实标签\n",
    "    \n",
    "    pre_score = DTC_model.predict(whole_data_x[test_index]) #预测\n",
    "    \n",
    "    pre_probe = DTC_model.predict_proba(whole_data_x[test_index])[:, 1] #预测的概率\n",
    "    \n",
    "\n",
    "    precision,accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) #验证模型，获得指标\n",
    "    \n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============SVM分类===============\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "\n",
    "def Creat_RBFSVM(whole_data_x,whole_data_y,train_index,test_index):\n",
    "\n",
    "    RBFSVM = NuSVC(**compare_models[1]['params'])\n",
    "\n",
    "    RBFSVM.fit(whole_data_x[train_index],whole_data_y[train_index] )  # 训练模型\n",
    "    \n",
    "    true_score = whole_data_y[test_index] #真实标签\n",
    "    \n",
    "    pre_score = RBFSVM.predict(whole_data_x[test_index]) #预测\n",
    "    \n",
    "    pre_probe = RBFSVM.predict_proba(whole_data_x[test_index])[:, 1] #预测的概率\n",
    "    \n",
    "\n",
    "    precision,accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) #验证模型，获得指标\n",
    "    \n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "\n",
    "def Creat_LinearSVC(whole_data_x,whole_data_y,train_index,test_index):\n",
    "\n",
    "    LSVC = SVC(**compare_models[2]['params'])\n",
    "\n",
    "    LSVC.fit(whole_data_x[train_index],whole_data_y[train_index] )  # 训练模型\n",
    "    \n",
    "    true_score = whole_data_y[test_index] #真实标签\n",
    "    \n",
    "    pre_score = LSVC.predict(whole_data_x[test_index]) #预测\n",
    "    \n",
    "    pre_probe = LSVC.predict_proba(whole_data_x[test_index])[:, 1] #预测的概率\n",
    "    \n",
    "\n",
    "    precision,accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) #验证模型，获得指标\n",
    "    \n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34375, 0.6435643564356436, 0.4230769230769231, 0.3793103448275862, 0.5592307692307692, 0.29721160646284406, 0.4459100614731803]\n",
      "[0.3939393939393939, 0.6633663366336634, 0.48148148148148145, 0.43333333333333324, 0.6141141141141142, 0.3409720056973018, 0.5031261296064247]\n",
      "[0.5555555555555556, 0.7524752475247525, 0.37037037037037035, 0.4444444444444445, 0.6476476476476477, 0.3856196535832921, 0.5598230388340978]\n",
      "[0.21212121212121213, 0.5445544554455446, 0.25925925925925924, 0.23333333333333334, 0.5007507507507507, 0.2567876628932735, 0.3597149794344514]\n",
      "[0.375, 0.6732673267326733, 0.3333333333333333, 0.35294117647058826, 0.5985985985985987, 0.3219389921448285, 0.45105234207631295]\n",
      "average value :  pre = 0.376,acc = 0.655,rec = 0.374,f1 = 0.369,auc = 0.584,aupr = 0.321,auprc = 0.464\n"
     ]
    }
   ],
   "source": [
    "#Comparison algorithm five-fold cross-validation\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590) #,random_state=10590\n",
    "\n",
    "kfscore = []\n",
    "\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "         \n",
    "    score = list(Creat_DTC(x,y,train_index,test_index))\n",
    "    print(score)                        \n",
    "    kfscore.append(score)\n",
    "                                             \n",
    "\n",
    "kfscores = np.array(kfscore).sum(axis= 0)/5.0     \n",
    "print(\"average value :  pre = {},acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(kfscores[0],3),round(kfscores[1],3),round(kfscores[2],3),round(kfscores[3],3),round(kfscores[4],3),round(kfscores[5],3),round(kfscores[6],3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnet",
   "language": "python",
   "name": "pnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
