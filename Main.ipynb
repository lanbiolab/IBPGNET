{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "random.seed(555)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pathways process and network generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the pathway feature generated by GCN\n",
    "pathway_feature = pd.read_csv('./data/Pathways_Feature.csv',index_col =0)\n",
    "\n",
    "#pathway data loading\n",
    "data = pd.read_csv('./data/ReactomePathwaysRelation_new_download.txt',sep = '\\t',header=None)\n",
    "\n",
    "data.columns = ['child','parent']\n",
    "human_hierarchy = data[data['child'].str.contains('HSA')]  \n",
    "\n",
    "# construct pathway graph\n",
    "net = nx.from_pandas_edgelist(human_hierarchy, 'child', 'parent', create_using=nx.DiGraph()) \n",
    "net.name = 'reactome'\n",
    "\n",
    "roots = [n for n, d in net.in_degree() if d == 0]  \n",
    "root_node = 'root'\n",
    "edges = [(root_node, n) for n in roots] \n",
    "net.add_edges_from(edges)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the node of the current layer\n",
    "def get_nodes_at_level(net, distance):\n",
    "    nodes = set(nx.ego_graph(net, 'root', radius=distance))\n",
    "    if distance >= 1.:\n",
    "        nodes -= set(nx.ego_graph(net, 'root', radius=distance - 1))\n",
    "    return list(nodes)\n",
    "\n",
    "def get_nodes(net,num):\n",
    "    net_nodes = [] \n",
    "    \n",
    "    for i in range(1,num+1):\n",
    "        net_nodes.append(get_nodes_at_level(net,i))\n",
    "        \n",
    "    return net_nodes\n",
    "\n",
    "#  define network size. for example,this network is five layer\n",
    "net_num = 5\n",
    "net_nodes = get_nodes(net,net_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read the connection of a single node to the next layer\n",
    "def add_node(net,net_nodes):\n",
    "        \n",
    "    for i in range(len(net_nodes)-2,-1,-1):\n",
    "        \n",
    "        data_temp = copy.deepcopy(net_nodes[i])\n",
    "        \n",
    "        for n in net_nodes[i]:\n",
    "            nexts = net.successors(n)         \n",
    "            temp = [ nex  for nex in nexts ] \n",
    "            if len(temp)==0:\n",
    "                data_temp.remove(n)  # If the node of the current layer has no successor node, remove the node\n",
    "            elif len(set(temp).intersection(set(net_nodes[i+1])))==0:   #if the subsequent node of the node of the current layer is not on the next layer, delete the node\n",
    "                data_temp.remove(n)\n",
    "            else:\n",
    "                continue\n",
    "        net_nodes[i] = data_temp\n",
    "    return net_nodes\n",
    "\n",
    "net_nodes  =  add_node(net,net_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_note_relation(net_nodes):\n",
    "    node_mat = []\n",
    "   \n",
    "    for i in range(len(net_nodes)-1):\n",
    "        dicts = {}\n",
    "        for n in net_nodes[i]:\n",
    "            nexts = net.successors(n)  \n",
    "            x = [ nex   for nex in nexts if nex in net_nodes[i+1] ]\n",
    "            dicts[n] = x\n",
    "\n",
    "        mat = np.zeros((len(net_nodes[i]), len(net_nodes[i+1]))) \n",
    "        for p, gs in dicts.items():     \n",
    "            g_inds = [net_nodes[i+1].index(g) for g in gs]\n",
    "            p_ind = net_nodes[i].index(p)\n",
    "            mat[p_ind, g_inds] = 1\n",
    "\n",
    "        df = pd.DataFrame(mat, index=net_nodes[i], columns=net_nodes[i+1])\n",
    "        node_mat.append(df.T)\n",
    "    return node_mat\n",
    "\n",
    "Get_Node_relation = get_note_relation(net_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link prediction only for adjacent pathways\n",
    "for k in range(0,4):\n",
    "    for col in Get_Node_relation[k].columns:\n",
    "        if col in list(pathway_feature.index):\n",
    "            for row in Get_Node_relation[k].index:\n",
    "                if row in list(pathway_feature.index):\n",
    "                    pos_c = pathway_feature.loc[col].values\n",
    "                    pos_r = pathway_feature.loc[row].values\n",
    "                    score = sigmoid(pos_c.dot(pos_r))\n",
    "\n",
    "                    if score >0.9:  #The similarity is greater than 0.9\n",
    "                        Get_Node_relation[k][col][row] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1745)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Get_Node_relation[3].values.nonzero()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read gene-pathway annotation relationships\n",
    "import re\n",
    "def load_data_dict(filename):\n",
    "\n",
    "    data_dict_list = []\n",
    "    dict = {}\n",
    "    with open( filename) as gmt:\n",
    "        data_list = gmt.readlines()\n",
    "\n",
    "        # print data_list[0]\n",
    "        for row in data_list:\n",
    "            genes = row.split('\\t')\n",
    "            \n",
    "            genes = [ i.replace('\\n','') for i in genes]\n",
    "            dict[genes[1]] = genes[3:]\n",
    "\n",
    "    return dict\n",
    "\n",
    "gene_data = load_data_dict('./data/ReactomePathways.gmt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data preprocessing and multi omics data intergration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading snv data\n",
    "snv_data = pd.read_csv(\"./data/TCGA-LUAD.varscan2_snv.csv\",index_col = 0)\n",
    "\n",
    "\n",
    "#loading cnv data\n",
    "cnv_data = pd.read_csv(\"./data/TCGA-LUAD_cnv.csv\",index_col = 0)\n",
    "\n",
    "\n",
    "#loading label\n",
    "response  = pd.read_csv('./data/response_paper.csv',index_col=0)\n",
    "\n",
    "#Disrupted data set\n",
    "response = response.sample(frac=1)\n",
    "\n",
    "snv_data = snv_data.sample(frac=1)\n",
    "\n",
    "cnv_data = cnv_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split copy number variation data\n",
    "import copy\n",
    "cnv_amp = copy.deepcopy(cnv_data)\n",
    "\n",
    "#cnv_amp\n",
    "cnv_amp[cnv_amp <= 0] = 0.\n",
    "cnv_amp[cnv_amp > 0 ] = 1.\n",
    "\n",
    "#cnv_del\n",
    "cnv_data[cnv_data >= 0] = 0.\n",
    "cnv_data[cnv_data < 0 ] = 1.\n",
    "cnv_del = cnv_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 453943)\n",
      "(2, 317421)\n",
      "(2, 162637)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(cnv_amp.values.nonzero()).shape)\n",
    "print(np.array(cnv_data.values.nonzero()).shape)\n",
    "print(np.array(snv_data.values.nonzero()).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#snv\n",
    "tol_snv = snv_data.join(response,how='inner')\n",
    "model = SelectKBest(chi2, k=3000)\n",
    "x_data1 = model.fit_transform(tol_snv.values[:,0:-1],tol_snv.values[:,-1])\n",
    "fea = model.get_support()\n",
    "snv_data = snv_data.loc[:,fea]\n",
    "\n",
    "#cnv_amp\n",
    "tol_amp = cnv_amp.join(response,how='inner')\n",
    "model = SelectKBest(chi2, k=3000)\n",
    "x_data1 = model.fit_transform(tol_amp.values[:,0:-1],tol_amp.values[:,-1])\n",
    "fea = model.get_support()\n",
    "cnv_amp = cnv_amp.loc[:,fea]\n",
    "\n",
    "#cnv_del\n",
    "tol_del = cnv_del.join(response,how='inner')\n",
    "model = SelectKBest(chi2, k=3000)\n",
    "x_data1 = model.fit_transform(tol_del.values[:,0:-1],tol_del.values[:,-1])\n",
    "fea = model.get_support()\n",
    "cnv_del = cnv_del.loc[:,fea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 3000)\n",
      "(514, 3000)\n",
      "(514, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(snv_data.shape)\n",
    "print(cnv_amp.shape)\n",
    "print(cnv_del.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading Load pre-training data\n",
    "response = pd.read_csv('./data/response.csv',index_col = 0)\n",
    "snv_data = snv_data.loc[response.index]\n",
    "cnv_amp = cnv_amp.loc[response.index]\n",
    "cnv_del = cnv_del.loc[response.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "rows_list = []\n",
    "cols_list = []\n",
    "\n",
    "data_type_list =['snv_data','cnv_amp','cnv_del']\n",
    "\n",
    "for ind in [snv_data,cnv_amp,cnv_del]: \n",
    "    get_data = ind.join(response,how='inner')\n",
    "    del get_data['response']\n",
    "    \n",
    "    row = get_data.index      \n",
    "    col = get_data.columns     \n",
    "    resp = response.loc[row]   \n",
    "    \n",
    "    x_list.append(ind)\n",
    "    y_list.append(resp)\n",
    "    rows_list.append(row)\n",
    "    cols_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data set\n",
    "def combine(x_list, y_list, rows_list, cols_list, data_type_list, combine_type, use_coding_genes_only=True):\n",
    "    \n",
    "    cols_list_set = [set(list(c)) for c in cols_list]  \n",
    "    \n",
    "    print('cols_list_set',len(cols_list_set))\n",
    "\n",
    "    if combine_type == 'intersection':    \n",
    "        cols = set.intersection(*cols_list_set)\n",
    "    else:\n",
    "        cols = set.union(*cols_list_set) \n",
    "    \n",
    "    print('intersection_cols',len(cols))\n",
    "\n",
    "    if use_coding_genes_only: #true\n",
    "        coding_genes_df = pd.read_csv('./data/protein-coding_gene_with_coordinate_minimal.txt', sep='\\t', header=None)\n",
    "        coding_genes_df.columns = ['chr', 'start', 'end', 'name']\n",
    "        coding_genes = set(coding_genes_df['name'].unique())     \n",
    "        cols = cols.intersection(coding_genes)  \n",
    "        print('protein-coding_genes',len(coding_genes))\n",
    "   \n",
    "    print('finally_cols',len(cols))\n",
    "   \n",
    "    all_cols = list(cols)\n",
    "\n",
    "    all_cols_df = pd.DataFrame(index=all_cols) \n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for x, y, r, c in zip(x_list, y_list, rows_list, cols_list):\n",
    "        df = pd.DataFrame(x, columns=c, index=r)\n",
    "        df = df.T.join(all_cols_df, how='right')  \n",
    "        df = df.T\n",
    "        df = df.fillna(0)\n",
    "        df_list.append(df)\n",
    "\n",
    "    all_data = pd.concat(df_list, keys=data_type_list, join='inner', axis=1, )  \n",
    "\n",
    "   \n",
    "    all_data = all_data.swaplevel(i=0, j=1, axis=1)\n",
    "\n",
    "\n",
    "    order = all_data.columns.levels[0] \n",
    "\n",
    "    all_data = all_data.reindex(columns=order, level=0)  \n",
    "\n",
    "    x = all_data\n",
    "\n",
    "    reordering_df = pd.DataFrame(index=all_data.index)  \n",
    "    y = reordering_df.join(y, how='left')   \n",
    "\n",
    "    y = y.values   \n",
    "    cols = all_data.columns   \n",
    "    rows = all_data.index      \n",
    "    print(\n",
    "        'After combining, loaded data %d samples, %d variables, %d responses ' % (x.shape[0], x.shape[1], y.shape[0]))\n",
    "\n",
    "    return x, y, rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_list_set 3\n",
      "intersection_cols 7722\n",
      "protein-coding_genes 19045\n",
      "finally_cols 7034\n",
      "After combining, loaded data 505 samples, 21102 variables, 505 responses \n"
     ]
    }
   ],
   "source": [
    "x, y, rows, cols = combine(x_list, y_list, rows_list, cols_list, data_type_list, combine_type = 'union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TCGA-55-8206', 'TCGA-05-4382', 'TCGA-69-7761', 'TCGA-50-5944',\n",
       "       'TCGA-44-A479', 'TCGA-55-8620', 'TCGA-91-A4BC', 'TCGA-78-7536',\n",
       "       'TCGA-55-8087', 'TCGA-55-7907',\n",
       "       ...\n",
       "       'TCGA-71-6725', 'TCGA-44-8117', 'TCGA-91-8499', 'TCGA-73-4659',\n",
       "       'TCGA-75-6212', 'TCGA-97-8176', 'TCGA-86-8280', 'TCGA-55-6543',\n",
       "       'TCGA-50-6594', 'TCGA-38-4632'],\n",
       "      dtype='object', length=505)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotated relationships between genes and pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7034"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathways  = list(gene_data.keys())  \n",
    "pathway_union = list(set(Get_Node_relation[3].index).intersection(set(pathways)))\n",
    "\n",
    "print(len(pathway_union))\n",
    "Get_Node_relation[3] = Get_Node_relation[3].loc[pathway_union]\n",
    "\n",
    "union_gene = list(cols.levels[0])\n",
    "len(union_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_gene = np.zeros((len(pathway_union), len(union_gene))) \n",
    "\n",
    "for p  in pathway_union:\n",
    "    gs = gene_data[p]      \n",
    "    g_inds = [union_gene.index(g) for g in gs if g in union_gene]  \n",
    "    p_ind = pathway_union.index(p)\n",
    "    pathways_gene[p_ind, g_inds] = 1\n",
    "gene_pathway_df = pd.DataFrame(pathways_gene, index=pathway_union, columns=union_gene)\n",
    "\n",
    "\n",
    "#Drop genes that are not in the pathway\n",
    "gene_pathway_df = gene_pathway_df.loc[:, (gene_pathway_df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 1542)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAMTS1</th>\n",
       "      <th>YWHAQ</th>\n",
       "      <th>CTNND1</th>\n",
       "      <th>RCC2</th>\n",
       "      <th>BDKRB2</th>\n",
       "      <th>PANK3</th>\n",
       "      <th>SPP1</th>\n",
       "      <th>CRMP1</th>\n",
       "      <th>PHC3</th>\n",
       "      <th>PIP4K2A</th>\n",
       "      <th>...</th>\n",
       "      <th>GLP1R</th>\n",
       "      <th>CKAP5</th>\n",
       "      <th>PSENEN</th>\n",
       "      <th>NPFFR2</th>\n",
       "      <th>SLC22A6</th>\n",
       "      <th>OSM</th>\n",
       "      <th>LRTOMT</th>\n",
       "      <th>ACAD9</th>\n",
       "      <th>TATDN2</th>\n",
       "      <th>MAP1LC3B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-HSA-72689</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-HSA-3560783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-HSA-1482922</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-HSA-111461</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-HSA-3304356</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1542 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADAMTS1  YWHAQ  CTNND1  RCC2  BDKRB2  PANK3  SPP1  CRMP1  PHC3  \\\n",
       "R-HSA-72689        0.0    0.0     0.0   0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "R-HSA-3560783      0.0    0.0     0.0   0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "R-HSA-1482922      0.0    0.0     0.0   0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "R-HSA-111461       0.0    0.0     0.0   0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "R-HSA-3304356      0.0    0.0     0.0   0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "\n",
       "               PIP4K2A  ...  GLP1R  CKAP5  PSENEN  NPFFR2  SLC22A6  OSM  \\\n",
       "R-HSA-72689        0.0  ...    0.0    0.0     0.0     0.0      0.0  0.0   \n",
       "R-HSA-3560783      0.0  ...    0.0    0.0     0.0     0.0      0.0  0.0   \n",
       "R-HSA-1482922      0.0  ...    0.0    0.0     0.0     0.0      0.0  0.0   \n",
       "R-HSA-111461       0.0  ...    0.0    0.0     0.0     0.0      0.0  0.0   \n",
       "R-HSA-3304356      0.0  ...    0.0    0.0     0.0     0.0      0.0  0.0   \n",
       "\n",
       "               LRTOMT  ACAD9  TATDN2  MAP1LC3B  \n",
       "R-HSA-72689       0.0    0.0     0.0       0.0  \n",
       "R-HSA-3560783     0.0    0.0     0.0       0.0  \n",
       "R-HSA-1482922     0.0    0.0     0.0       0.0  \n",
       "R-HSA-111461      0.0    0.0     0.0       0.0  \n",
       "R-HSA-3304356     0.0    0.0     0.0       0.0  \n",
       "\n",
       "[5 rows x 1542 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gene_pathway_df.shape)\n",
    "gene_pathway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505, 4626)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Omics_data = x[list(gene_pathway_df.columns)] \n",
    "Omics_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = gene_pathway_df.columns  \n",
    "mapp = gene_pathway_df.values          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, multiply\n",
    "from keras.regularizers import l2\n",
    "from keras import Input\n",
    "from keras.engine import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.engine import Layer\n",
    "# from keras import initializations\n",
    "from keras.initializers import glorot_uniform, Initializer\n",
    "from keras.layers import activations, initializers, constraints\n",
    "# our layer will take input shape (nb_samples, 1)\n",
    "from keras.regularizers import Regularizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M_Nets(Layer):   \n",
    "    def __init__(self, units, activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 W_regularizer=None,\n",
    "                 b_regularizer=None,\n",
    "                 **kwargs):\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.activation_fn = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.bias_regularize = regularizers.get(b_regularizer)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(W_regularizer)\n",
    "        \n",
    "        super(M_Nets, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):  \n",
    "\n",
    "        input_dimension = input_shape[1]\n",
    "        self.kernel_shape = (input_dimension, self.units)  \n",
    "        self.n_inputs_per_node = input_dimension / self.units\n",
    "\n",
    "        rows = np.arange(input_dimension) \n",
    "        cols = np.arange(self.units)    \n",
    "        cols = np.repeat(cols, self.n_inputs_per_node) \n",
    "        self.nonzero_ind = np.column_stack((rows, cols)) \n",
    "\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_dimension,),  \n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      trainable=True)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        trainable=True\n",
    "                                        \n",
    "                                       )\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        super(M_Nets, self).build(input_shape)  \n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        \n",
    "        n_features = x.shape[1]\n",
    "\n",
    "\n",
    "        kernel = K.reshape(self.kernel, (1, n_features))\n",
    "        mult = x * kernel\n",
    "        mult = K.reshape(mult, (-1, int(self.n_inputs_per_node)))\n",
    "        mult = K.sum(mult, axis=1)\n",
    "        output = K.reshape(mult, (-1, self.units))\n",
    "\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "        if self.activation_fn is not None:\n",
    "            output = self.activation_fn(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': self.activation,\n",
    "            'kernel_initializer' : self.kernel_initializer,\n",
    "            'bias_initializer' : self.bias_initializer,\n",
    "            'use_bias': self.use_bias\n",
    "        }\n",
    "        base_config = super(M_Nets, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nets(Layer):\n",
    "    def __init__(self, units, mapp=None, nonzero_ind=None, kernel_initializer='glorot_uniform', W_regularizer=None,\n",
    "                 activation='tanh', use_bias=True,bias_initializer='zeros', bias_regularizer=None,\n",
    "                 bias_constraint=None,**kwargs):\n",
    "        \n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.mapp = mapp\n",
    "        self.nonzero_ind = nonzero_ind\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(W_regularizer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activation_fn = activations.get(activation)\n",
    "        super(Nets, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        input_dim = input_shape[1]\n",
    "   \n",
    "\n",
    "        if not self.mapp is None:\n",
    "            self.mapp = self.mapp.astype(np.float32)\n",
    "\n",
    "   \n",
    "        if self.nonzero_ind is None:\n",
    "            nonzero_ind = np.array(np.nonzero(self.mapp)).T\n",
    "            self.nonzero_ind = nonzero_ind\n",
    "\n",
    "        self.kernel_shape = (input_dim, self.units)\n",
    "        \n",
    "\n",
    "        nonzero_count = self.nonzero_ind.shape[0]  \n",
    "\n",
    "\n",
    "        self.kernel_vector = self.add_weight(name='kernel_vector',\n",
    "                                             shape=(nonzero_count,),\n",
    "                                             initializer=self.kernel_initializer,\n",
    "                                             regularizer=self.kernel_regularizer,\n",
    "                                             trainable=True)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer\n",
    "                                        )\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        super(Nets, self).build(input_shape)  \n",
    "      \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        \n",
    "        temp_t = tf.scatter_nd(tf.constant(self.nonzero_ind, tf.int32), self.kernel_vector,\n",
    "                           tf.constant(list(self.kernel_shape)))\n",
    "    \n",
    "        output = K.dot(inputs, temp_t)\n",
    "        \n",
    "    \n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "            \n",
    "        if self.activation_fn is not None:\n",
    "            output = self.activation_fn(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': self.activation,\n",
    "            'use_bias': self.use_bias,\n",
    "            'nonzero_ind': np.array(self.nonzero_ind),\n",
    "          \n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'W_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "\n",
    "        }\n",
    "        base_config = super(Nets, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "      \n",
    "        return (input_shape[0], self.units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(Omics_data):\n",
    "    \n",
    "    S_inputs = Input(shape=(Omics_data.shape[1],), dtype='float32',name= 'inputs')\n",
    "\n",
    "    h_0 = M_Nets(cols.shape[0], activation='tanh',name='h_0')(S_inputs)\n",
    "    drop_layer1 =keras.layers.Dropout(0.5)(h_0)\n",
    "\n",
    "    h0 = Nets(gene_pathway_df.shape[0],mapp =gene_pathway_df.values.T, name = 'h0')(drop_layer1)\n",
    "    drop0 = keras.layers.Dropout(0.1)(h0)\n",
    "\n",
    "    h1 = Nets(Get_Node_relation[3].shape[1],mapp =Get_Node_relation[3].values ,name = 'h1')(drop0)\n",
    "    drop_h1 = keras.layers.Dropout(0.1)(h1)\n",
    "\n",
    "\n",
    "    h2 = Nets(Get_Node_relation[2].shape[1],mapp =Get_Node_relation[2].values, name = 'h2')(drop_h1)\n",
    "    drop2 = keras.layers.Dropout(0.1)(h2)\n",
    "\n",
    "\n",
    "    h3 = Nets(Get_Node_relation[1].shape[1],mapp =Get_Node_relation[1].values, name = 'h3')(drop2)\n",
    "    drop3 = keras.layers.Dropout(0.1)(h3)\n",
    "\n",
    "    \n",
    "    h4 = Nets(Get_Node_relation[0].shape[1],mapp =Get_Node_relation[0].values, name = 'h4')(drop3)\n",
    "    drop4 = keras.layers.Dropout(0.1)(h4)\n",
    "\n",
    "    Output = keras.layers.Dense(1,activation='sigmoid')(drop4)\n",
    "\n",
    "    model = Model(inputs=S_inputs, outputs=Output)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr = 0.001) #,decay=-0.0001 ,decay=0.001\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "   \n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "def evaluates(y_test, y_pred):\n",
    "    \n",
    "    auc = metrics.roc_auc_score(y_test,y_pred)\n",
    "    \n",
    "    aupr = average_precision_score(y_test, y_pred)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)    \n",
    "    auprc  = metrics.auc(recall, precision)\n",
    "    \n",
    "    pp = [1 if index>=0.5  else 0 for index in  y_pred ]\n",
    "    \n",
    "    pre = metrics.precision_score(y_test,pp)\n",
    "    \n",
    "    f1 = metrics.f1_score(y_test,pp)\n",
    "    \n",
    "    rec = metrics.recall_score(y_test,pp)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test,pp)\n",
    "    \n",
    "    print(confusion_matrix(y_test,pp))\n",
    "    \n",
    "    return pre,acc,rec,f1,auc,aupr,auprc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deepexplain.model_utils import get_layers, get_coef_importance\n",
    "\n",
    "def get_coef_importances(model, X_train, y_train, target=-1, feature_importance='deepexplain_grad*input'):\n",
    "\n",
    "    coef_ = get_coef_importance(model, X_train, y_train, target, feature_importance, detailed=False)\n",
    "    return coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "def myScheduler(epoch):\n",
    "\n",
    "    if epoch % 150 == 0 and epoch != 0:\n",
    "\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "\n",
    "        K.set_value(model.optimizer.lr, lr * 0.5)\n",
    "    return K.get_value(model.optimizer.lr)\n",
    " \n",
    "myReduce_lr = LearningRateScheduler(myScheduler)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omics_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.6177 - acc: 0.7054 - val_loss: 0.6678 - val_acc: 0.7426\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6152 - acc: 0.7327 - val_loss: 0.6548 - val_acc: 0.7426\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6144 - acc: 0.7327 - val_loss: 0.6437 - val_acc: 0.7426\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6131 - acc: 0.7327 - val_loss: 0.6462 - val_acc: 0.7426\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6157 - acc: 0.7327 - val_loss: 0.6414 - val_acc: 0.7426\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6116 - acc: 0.7327 - val_loss: 0.6460 - val_acc: 0.7426\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6129 - acc: 0.7327 - val_loss: 0.6430 - val_acc: 0.7426\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6140 - acc: 0.7327 - val_loss: 0.6418 - val_acc: 0.7426\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6131 - acc: 0.7327 - val_loss: 0.6417 - val_acc: 0.7426\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6128 - acc: 0.7327 - val_loss: 0.6402 - val_acc: 0.7426\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6139 - acc: 0.7327 - val_loss: 0.6405 - val_acc: 0.7426\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6130 - acc: 0.7327 - val_loss: 0.6482 - val_acc: 0.7426\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6138 - acc: 0.7327 - val_loss: 0.6428 - val_acc: 0.7426\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6124 - acc: 0.7327 - val_loss: 0.6433 - val_acc: 0.7426\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6118 - acc: 0.7327 - val_loss: 0.6399 - val_acc: 0.7426\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6114 - acc: 0.7327 - val_loss: 0.6399 - val_acc: 0.7426\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6110 - acc: 0.7327 - val_loss: 0.6415 - val_acc: 0.7426\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6104 - acc: 0.7327 - val_loss: 0.6398 - val_acc: 0.7426\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6085 - acc: 0.7327 - val_loss: 0.6320 - val_acc: 0.7426\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6091 - acc: 0.7376 - val_loss: 0.6498 - val_acc: 0.7426\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6036 - acc: 0.7351 - val_loss: 0.6349 - val_acc: 0.7426\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5990 - acc: 0.7426 - val_loss: 0.6267 - val_acc: 0.7525\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.5909 - acc: 0.750 - 1s 2ms/step - loss: 0.5930 - acc: 0.7475 - val_loss: 0.6185 - val_acc: 0.7525\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5870 - acc: 0.7376 - val_loss: 0.5992 - val_acc: 0.7525\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5774 - acc: 0.7550 - val_loss: 0.6118 - val_acc: 0.7525\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.5713 - acc: 0.7649 - val_loss: 0.5894 - val_acc: 0.7525\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.5481 - acc: 0.7673 - val_loss: 0.5975 - val_acc: 0.8119\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.5257 - acc: 0.7748 - val_loss: 0.5499 - val_acc: 0.7426\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.5236 - acc: 0.7500 - val_loss: 0.5220 - val_acc: 0.7624\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5212 - acc: 0.7450 - val_loss: 0.5675 - val_acc: 0.6337\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5039 - acc: 0.7351 - val_loss: 0.5388 - val_acc: 0.6931\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5062 - acc: 0.7574 - val_loss: 0.5883 - val_acc: 0.6436\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4696 - acc: 0.7401 - val_loss: 0.4677 - val_acc: 0.7822\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4865 - acc: 0.7327 - val_loss: 0.5083 - val_acc: 0.7030\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4395 - acc: 0.8119 - val_loss: 0.4661 - val_acc: 0.8119\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4522 - acc: 0.7896 - val_loss: 0.5026 - val_acc: 0.6832\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4590 - acc: 0.7946 - val_loss: 0.4954 - val_acc: 0.6931\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4408 - acc: 0.7525 - val_loss: 0.4606 - val_acc: 0.7921\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4311 - acc: 0.7822 - val_loss: 0.4263 - val_acc: 0.7921\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4370 - acc: 0.7574 - val_loss: 0.4252 - val_acc: 0.7921\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4422 - acc: 0.7525 - val_loss: 0.4545 - val_acc: 0.7723\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4316 - acc: 0.8267 - val_loss: 0.5118 - val_acc: 0.7129\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3906 - acc: 0.7772 - val_loss: 0.4298 - val_acc: 0.8515\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3961 - acc: 0.7871 - val_loss: 0.4321 - val_acc: 0.8119\n",
      "Epoch 45/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3966 - acc: 0.7995 - val_loss: 0.4150 - val_acc: 0.8515\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.3876 - acc: 0.8144 - val_loss: 0.4042 - val_acc: 0.8317\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3759 - acc: 0.8020 - val_loss: 0.4067 - val_acc: 0.8416\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.3638 - acc: 0.8144 - val_loss: 0.4060 - val_acc: 0.8416\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3657 - acc: 0.8465 - val_loss: 0.4199 - val_acc: 0.8119\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.4014 - acc: 0.7797 - val_loss: 0.4176 - val_acc: 0.7921\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.3666 - acc: 0.8045 - val_loss: 0.4454 - val_acc: 0.7426\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3535 - acc: 0.8144 - val_loss: 0.3895 - val_acc: 0.8515\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.3606 - acc: 0.8267 - val_loss: 0.4084 - val_acc: 0.8119\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3867 - acc: 0.7871 - val_loss: 0.4236 - val_acc: 0.7723\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.3589 - acc: 0.8515 - val_loss: 0.5291 - val_acc: 0.7129\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3617 - acc: 0.8069 - val_loss: 0.3821 - val_acc: 0.8317\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3536 - acc: 0.8193 - val_loss: 0.3887 - val_acc: 0.8416\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3553 - acc: 0.8020 - val_loss: 0.3771 - val_acc: 0.8317\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3216 - acc: 0.8614 - val_loss: 0.4616 - val_acc: 0.7525\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3078 - acc: 0.8490 - val_loss: 0.4136 - val_acc: 0.8020\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3194 - acc: 0.8366 - val_loss: 0.3803 - val_acc: 0.8614\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3443 - acc: 0.7995 - val_loss: 0.4303 - val_acc: 0.7525\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3558 - acc: 0.8243 - val_loss: 0.4453 - val_acc: 0.7525\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3257 - acc: 0.8292 - val_loss: 0.3679 - val_acc: 0.8713\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3006 - acc: 0.8540 - val_loss: 0.3883 - val_acc: 0.8020\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2888 - acc: 0.8515 - val_loss: 0.4007 - val_acc: 0.8020\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3320 - acc: 0.8614 - val_loss: 0.4248 - val_acc: 0.7525\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3042 - acc: 0.8441 - val_loss: 0.3804 - val_acc: 0.8416\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3186 - acc: 0.8094 - val_loss: 0.3640 - val_acc: 0.8713- loss: 0.3266 - acc: 0.79\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3041 - acc: 0.8639 - val_loss: 0.4474 - val_acc: 0.7624\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3188 - acc: 0.8342 - val_loss: 0.4898 - val_acc: 0.7426\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2676 - acc: 0.8787 - val_loss: 0.3698 - val_acc: 0.8119\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2736 - acc: 0.8861 - val_loss: 0.3601 - val_acc: 0.8713\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2847 - acc: 0.8490 - val_loss: 0.3688 - val_acc: 0.8218\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2807 - acc: 0.8762 - val_loss: 0.3648 - val_acc: 0.8614\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2676 - acc: 0.8936 - val_loss: 0.3566 - val_acc: 0.8515\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2494 - acc: 0.8936 - val_loss: 0.4403 - val_acc: 0.7624\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2920 - acc: 0.8589 - val_loss: 0.3725 - val_acc: 0.8317\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2661 - acc: 0.8540 - val_loss: 0.3583 - val_acc: 0.8614\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2659 - acc: 0.8713 - val_loss: 0.3620 - val_acc: 0.8713\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2922 - acc: 0.8540 - val_loss: 0.3605 - val_acc: 0.8713\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2579 - acc: 0.8738 - val_loss: 0.3780 - val_acc: 0.8515\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2734 - acc: 0.8540 - val_loss: 0.3572 - val_acc: 0.8713\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2660 - acc: 0.8787 - val_loss: 0.3759 - val_acc: 0.8119\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2840 - acc: 0.8738 - val_loss: 0.3621 - val_acc: 0.8515\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2863 - acc: 0.8663 - val_loss: 0.4618 - val_acc: 0.7624\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2928 - acc: 0.8441 - val_loss: 0.3819 - val_acc: 0.8218\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2429 - acc: 0.8713 - val_loss: 0.3473 - val_acc: 0.8812\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2448 - acc: 0.9010 - val_loss: 0.3495 - val_acc: 0.8614\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2269 - acc: 0.9084 - val_loss: 0.4030 - val_acc: 0.7723\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2808 - acc: 0.8441 - val_loss: 0.3696 - val_acc: 0.8317\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2546 - acc: 0.8762 - val_loss: 0.3603 - val_acc: 0.8416\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3009 - acc: 0.8515 - val_loss: 0.4381 - val_acc: 0.7525\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2496 - acc: 0.8911 - val_loss: 0.3584 - val_acc: 0.8416\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2611 - acc: 0.8589 - val_loss: 0.3476 - val_acc: 0.8713\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2425 - acc: 0.9084 - val_loss: 0.3822 - val_acc: 0.8020\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2611 - acc: 0.8589 - val_loss: 0.3442 - val_acc: 0.8911\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2227 - acc: 0.9257 - val_loss: 0.4002 - val_acc: 0.7525\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2412 - acc: 0.9059 - val_loss: 0.3541 - val_acc: 0.8812\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2368 - acc: 0.8960 - val_loss: 0.3547 - val_acc: 0.8614\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2760 - acc: 0.8465 - val_loss: 0.3732 - val_acc: 0.8416\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2389 - acc: 0.8688 - val_loss: 0.3472 - val_acc: 0.8812\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2479 - acc: 0.8837 - val_loss: 0.3472 - val_acc: 0.8812\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2329 - acc: 0.8837 - val_loss: 0.3813 - val_acc: 0.8020\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2166 - acc: 0.8911 - val_loss: 0.3645 - val_acc: 0.8416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2335 - acc: 0.8911 - val_loss: 0.3502 - val_acc: 0.8812\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2445 - acc: 0.9010 - val_loss: 0.3468 - val_acc: 0.8911\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2259 - acc: 0.8663 - val_loss: 0.3405 - val_acc: 0.8911\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2176 - acc: 0.8936 - val_loss: 0.3365 - val_acc: 0.8812\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2069 - acc: 0.9059 - val_loss: 0.3470 - val_acc: 0.8713\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2508 - acc: 0.8614 - val_loss: 0.3381 - val_acc: 0.8911\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2322 - acc: 0.8837 - val_loss: 0.3543 - val_acc: 0.8317\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2182 - acc: 0.8787 - val_loss: 0.3345 - val_acc: 0.8911\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2087 - acc: 0.9208 - val_loss: 0.3514 - val_acc: 0.8317\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2226 - acc: 0.8861 - val_loss: 0.3750 - val_acc: 0.8119\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2312 - acc: 0.8886 - val_loss: 0.3501 - val_acc: 0.8416\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2542 - acc: 0.8465 - val_loss: 0.3323 - val_acc: 0.9010\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1868 - acc: 0.9208 - val_loss: 0.3366 - val_acc: 0.8812\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2371 - acc: 0.8911 - val_loss: 0.4653 - val_acc: 0.7624\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2422 - acc: 0.8762 - val_loss: 0.3369 - val_acc: 0.9109\n",
      "[[75  0]\n",
      " [ 9 17]]\n",
      "[[75  0]\n",
      " [ 9 17]]\n",
      "results : pre = 1.0, acc = 0.911,rec = 0.654,f1 = 0.791,auc = 0.902,aupr = 0.851,auprc = 0.849\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 14s 35ms/step - loss: 0.6161 - acc: 0.7228 - val_loss: 0.6713 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6140 - acc: 0.7351 - val_loss: 0.6592 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6125 - acc: 0.7351 - val_loss: 0.6495 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6498 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6506 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6449 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6453 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6449 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6472 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6468 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6451 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6106 - acc: 0.7351 - val_loss: 0.6442 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6424 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6106 - acc: 0.7351 - val_loss: 0.6364 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6103 - acc: 0.7351 - val_loss: 0.6393 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6443 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6392 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6451 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6087 - acc: 0.7351 - val_loss: 0.6372 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6095 - acc: 0.7351 - val_loss: 0.6427 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6073 - acc: 0.7351 - val_loss: 0.6466 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6064 - acc: 0.7351 - val_loss: 0.6422 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6072 - acc: 0.7351 - val_loss: 0.6349 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6038 - acc: 0.7351 - val_loss: 0.6368 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6004 - acc: 0.7351 - val_loss: 0.6333 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5974 - acc: 0.7351 - val_loss: 0.6392 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5943 - acc: 0.7351 - val_loss: 0.6427 - val_acc: 0.7624\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5864 - acc: 0.7376 - val_loss: 0.6152 - val_acc: 0.7525\n",
      "Epoch 29/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5775 - acc: 0.7599 - val_loss: 0.6330 - val_acc: 0.7426\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5624 - acc: 0.7624 - val_loss: 0.6059 - val_acc: 0.7426\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.5517 - acc: 0.752 - 1s 3ms/step - loss: 0.5521 - acc: 0.7500 - val_loss: 0.6379 - val_acc: 0.7921\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.5350 - acc: 0.7673 - val_loss: 0.6022 - val_acc: 0.7921\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5197 - acc: 0.7970 - val_loss: 0.6428 - val_acc: 0.6238\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5250 - acc: 0.6287 - val_loss: 0.5174 - val_acc: 0.7624\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5222 - acc: 0.7673 - val_loss: 0.7549 - val_acc: 0.4158\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5316 - acc: 0.6312 - val_loss: 0.5300 - val_acc: 0.7822\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4811 - acc: 0.7475 - val_loss: 0.6358 - val_acc: 0.6238\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4818 - acc: 0.7574 - val_loss: 0.5662 - val_acc: 0.8119\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4693 - acc: 0.7574 - val_loss: 0.5694 - val_acc: 0.8020\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4266 - acc: 0.7995 - val_loss: 0.5539 - val_acc: 0.8119\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4370 - acc: 0.8144 - val_loss: 0.5362 - val_acc: 0.8020\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4219 - acc: 0.7649 - val_loss: 0.5143 - val_acc: 0.7921\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4200 - acc: 0.7748 - val_loss: 0.4990 - val_acc: 0.7921\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 2s 6ms/step - loss: 0.4486 - acc: 0.7550 - val_loss: 0.6534 - val_acc: 0.6337\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4171 - acc: 0.8020 - val_loss: 0.5903 - val_acc: 0.6733\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3933 - acc: 0.7946 - val_loss: 0.4953 - val_acc: 0.8119\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3939 - acc: 0.7921 - val_loss: 0.4686 - val_acc: 0.7921\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 0.3723 - acc: 0.8218 - val_loss: 0.5493 - val_acc: 0.7525\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3723 - acc: 0.8144 - val_loss: 0.4637 - val_acc: 0.8119\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3808 - acc: 0.7946 - val_loss: 0.4562 - val_acc: 0.8119\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3621 - acc: 0.8094 - val_loss: 0.4884 - val_acc: 0.8119\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3493 - acc: 0.8465 - val_loss: 0.4983 - val_acc: 0.8020\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3437 - acc: 0.8243 - val_loss: 0.4607 - val_acc: 0.8020\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3273 - acc: 0.8317 - val_loss: 0.5756 - val_acc: 0.6832\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3526 - acc: 0.8168 - val_loss: 0.4640 - val_acc: 0.8119\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3412 - acc: 0.8218 - val_loss: 0.5226 - val_acc: 0.7228\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3233 - acc: 0.8391 - val_loss: 0.5087 - val_acc: 0.7525\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3083 - acc: 0.8614 - val_loss: 0.4542 - val_acc: 0.8317\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3315 - acc: 0.8391 - val_loss: 0.4406 - val_acc: 0.8218\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3239 - acc: 0.8243 - val_loss: 0.4322 - val_acc: 0.8515\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3013 - acc: 0.8391 - val_loss: 0.5204 - val_acc: 0.7426\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3389 - acc: 0.7921 - val_loss: 0.4913 - val_acc: 0.8218\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3228 - acc: 0.8416 - val_loss: 0.4928 - val_acc: 0.7723\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3109 - acc: 0.8490 - val_loss: 0.5085 - val_acc: 0.7624\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2846 - acc: 0.8564 - val_loss: 0.4382 - val_acc: 0.8317\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3106 - acc: 0.8243 - val_loss: 0.4622 - val_acc: 0.8218\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3246 - acc: 0.8391 - val_loss: 0.4967 - val_acc: 0.7624\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3005 - acc: 0.8490 - val_loss: 0.5498 - val_acc: 0.7129\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2967 - acc: 0.8465 - val_loss: 0.4492 - val_acc: 0.8218\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2757 - acc: 0.8663 - val_loss: 0.4713 - val_acc: 0.8317\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2771 - acc: 0.8614 - val_loss: 0.4296 - val_acc: 0.8416\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2765 - acc: 0.8342 - val_loss: 0.4950 - val_acc: 0.7723\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2548 - acc: 0.8886 - val_loss: 0.4897 - val_acc: 0.7723\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2671 - acc: 0.8663 - val_loss: 0.5098 - val_acc: 0.7624\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2647 - acc: 0.8465 - val_loss: 0.4292 - val_acc: 0.8416\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 0.2763 - acc: 0.8663 - val_loss: 0.5528 - val_acc: 0.7327\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.2903 - acc: 0.8490 - val_loss: 0.4661 - val_acc: 0.8020\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2505 - acc: 0.8886 - val_loss: 0.4836 - val_acc: 0.8119\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2544 - acc: 0.8614 - val_loss: 0.4734 - val_acc: 0.8119\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2565 - acc: 0.8663 - val_loss: 0.5162 - val_acc: 0.7525\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2586 - acc: 0.8713 - val_loss: 0.4648 - val_acc: 0.8020\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2781 - acc: 0.8490 - val_loss: 0.4693 - val_acc: 0.8020\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2676 - acc: 0.8639 - val_loss: 0.4470 - val_acc: 0.8218\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2533 - acc: 0.8688 - val_loss: 0.4390 - val_acc: 0.8515\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2543 - acc: 0.8861 - val_loss: 0.4513 - val_acc: 0.8317\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2723 - acc: 0.8589 - val_loss: 0.4375 - val_acc: 0.8317\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2476 - acc: 0.8837 - val_loss: 0.4442 - val_acc: 0.8416\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2644 - acc: 0.8589 - val_loss: 0.5301 - val_acc: 0.7525\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2265 - acc: 0.9010 - val_loss: 0.4502 - val_acc: 0.8218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2151 - acc: 0.8960 - val_loss: 0.4446 - val_acc: 0.8416\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2309 - acc: 0.8713 - val_loss: 0.4464 - val_acc: 0.8416\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2918 - acc: 0.8515 - val_loss: 0.4561 - val_acc: 0.8416\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2719 - acc: 0.8441 - val_loss: 0.4506 - val_acc: 0.8416\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3015 - acc: 0.8441 - val_loss: 0.5962 - val_acc: 0.7228\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2436 - acc: 0.8787 - val_loss: 0.4806 - val_acc: 0.8119\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2188 - acc: 0.8861 - val_loss: 0.4751 - val_acc: 0.8119\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2209 - acc: 0.9035 - val_loss: 0.5485 - val_acc: 0.7426\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2299 - acc: 0.8762 - val_loss: 0.4544 - val_acc: 0.8317\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2259 - acc: 0.8812 - val_loss: 0.4740 - val_acc: 0.8119\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2230 - acc: 0.8861 - val_loss: 0.6072 - val_acc: 0.7030\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2491 - acc: 0.8787 - val_loss: 0.5048 - val_acc: 0.7327\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2320 - acc: 0.8886 - val_loss: 0.4677 - val_acc: 0.8119\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1893 - acc: 0.9084 - val_loss: 0.4929 - val_acc: 0.8020\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2202 - acc: 0.8861 - val_loss: 0.5048 - val_acc: 0.7426\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2149 - acc: 0.8960 - val_loss: 0.4942 - val_acc: 0.8119\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2325 - acc: 0.8837 - val_loss: 0.4758 - val_acc: 0.8218\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2220 - acc: 0.8936 - val_loss: 0.4869 - val_acc: 0.8218\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2345 - acc: 0.8812 - val_loss: 0.4972 - val_acc: 0.8020\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2238 - acc: 0.8787 - val_loss: 0.6876 - val_acc: 0.7129\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2274 - acc: 0.8787 - val_loss: 0.5221 - val_acc: 0.7327\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2021 - acc: 0.8985 - val_loss: 0.5868 - val_acc: 0.7228\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2149 - acc: 0.8787 - val_loss: 0.4917 - val_acc: 0.8218\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2182 - acc: 0.9059 - val_loss: 0.5043 - val_acc: 0.8020\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2369 - acc: 0.8738 - val_loss: 0.4676 - val_acc: 0.8515\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2290 - acc: 0.8738 - val_loss: 0.4676 - val_acc: 0.8416\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2004 - acc: 0.8985 - val_loss: 0.5169 - val_acc: 0.7327\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1988 - acc: 0.9257 - val_loss: 0.5798 - val_acc: 0.7228\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1821 - acc: 0.8886 - val_loss: 0.4731 - val_acc: 0.8416\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2100 - acc: 0.8861 - val_loss: 0.4753 - val_acc: 0.8416\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2025 - acc: 0.9282 - val_loss: 0.5801 - val_acc: 0.7327\n",
      "[[54 20]\n",
      " [ 7 20]]\n",
      "[[54 20]\n",
      " [ 7 20]]\n",
      "results : pre = 0.5, acc = 0.733,rec = 0.741,f1 = 0.597,auc = 0.839,aupr = 0.765,auprc = 0.762\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.6157 - acc: 0.7203 - val_loss: 0.6672 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6521 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6126 - acc: 0.7351 - val_loss: 0.6441 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6120 - acc: 0.7351 - val_loss: 0.6396 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6453 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6133 - acc: 0.7351 - val_loss: 0.6455 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6456 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6370 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6425 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6367 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6420 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6419 - val_acc: 0.7327\n",
      "Epoch 13/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6389 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6133 - acc: 0.7351 - val_loss: 0.6499 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6105 - acc: 0.7351 - val_loss: 0.6493 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6100 - acc: 0.7351 - val_loss: 0.6487 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6088 - acc: 0.7351 - val_loss: 0.6388 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6070 - acc: 0.7351 - val_loss: 0.6356 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6069 - acc: 0.7351 - val_loss: 0.6354 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6052 - acc: 0.7351 - val_loss: 0.6409 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6030 - acc: 0.7351 - val_loss: 0.6407 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6030 - acc: 0.7351 - val_loss: 0.6406 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5983 - acc: 0.7376 - val_loss: 0.6380 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5917 - acc: 0.7376 - val_loss: 0.6332 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5878 - acc: 0.7500 - val_loss: 0.6272 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5799 - acc: 0.7426 - val_loss: 0.6147 - val_acc: 0.7129\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5647 - acc: 0.7723 - val_loss: 0.6360 - val_acc: 0.6931\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5578 - acc: 0.6832 - val_loss: 0.6011 - val_acc: 0.6931\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5396 - acc: 0.7599 - val_loss: 0.6391 - val_acc: 0.6238\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5268 - acc: 0.7550 - val_loss: 0.6043 - val_acc: 0.7624\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5038 - acc: 0.7698 - val_loss: 0.6394 - val_acc: 0.5842\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4964 - acc: 0.7525 - val_loss: 0.6154 - val_acc: 0.6931\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4721 - acc: 0.7995 - val_loss: 0.6093 - val_acc: 0.6931\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4615 - acc: 0.7649 - val_loss: 0.5620 - val_acc: 0.7822\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4491 - acc: 0.7921 - val_loss: 0.5719 - val_acc: 0.7624\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4375 - acc: 0.7847 - val_loss: 0.5401 - val_acc: 0.7723\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4336 - acc: 0.7871 - val_loss: 0.5646 - val_acc: 0.7822\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4312 - acc: 0.7847 - val_loss: 0.6181 - val_acc: 0.6139\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4116 - acc: 0.8045 - val_loss: 0.7211 - val_acc: 0.5347\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4073 - acc: 0.7896 - val_loss: 0.5375 - val_acc: 0.7723\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3852 - acc: 0.8193 - val_loss: 0.5404 - val_acc: 0.7723\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4136 - acc: 0.7970 - val_loss: 0.7402 - val_acc: 0.5347\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3964 - acc: 0.7723 - val_loss: 0.5383 - val_acc: 0.7525\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3846 - acc: 0.8168 - val_loss: 0.5558 - val_acc: 0.7228\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3885 - acc: 0.8069 - val_loss: 0.5039 - val_acc: 0.7822\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3801 - acc: 0.8193 - val_loss: 0.6255 - val_acc: 0.5842\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3588 - acc: 0.8119 - val_loss: 0.5222 - val_acc: 0.7723\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3469 - acc: 0.8465 - val_loss: 0.6164 - val_acc: 0.6040\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3547 - acc: 0.8144 - val_loss: 0.4854 - val_acc: 0.7822\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3463 - acc: 0.8515 - val_loss: 0.4957 - val_acc: 0.7822\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3640 - acc: 0.8267 - val_loss: 0.4843 - val_acc: 0.7822\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3601 - acc: 0.8045 - val_loss: 0.4643 - val_acc: 0.8218\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3665 - acc: 0.8144 - val_loss: 0.5293 - val_acc: 0.7327\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3203 - acc: 0.8738 - val_loss: 0.5436 - val_acc: 0.7228\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3469 - acc: 0.8465 - val_loss: 0.5588 - val_acc: 0.6832\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3340 - acc: 0.8366 - val_loss: 0.5178 - val_acc: 0.7327\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3165 - acc: 0.8366 - val_loss: 0.4954 - val_acc: 0.7525\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3205 - acc: 0.8292 - val_loss: 0.5023 - val_acc: 0.7525\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3443 - acc: 0.8366 - val_loss: 0.4787 - val_acc: 0.7624\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3617 - acc: 0.8045 - val_loss: 0.4449 - val_acc: 0.8416\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2933 - acc: 0.8589 - val_loss: 0.4608 - val_acc: 0.7822\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3236 - acc: 0.8490 - val_loss: 0.5126 - val_acc: 0.7426\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3334 - acc: 0.8069 - val_loss: 0.5035 - val_acc: 0.7129\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3218 - acc: 0.8366 - val_loss: 0.4539 - val_acc: 0.7921\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3012 - acc: 0.8465 - val_loss: 0.4429 - val_acc: 0.8416\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3203 - acc: 0.8515 - val_loss: 0.5518 - val_acc: 0.6832\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3010 - acc: 0.8465 - val_loss: 0.4775 - val_acc: 0.7624\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2864 - acc: 0.8614 - val_loss: 0.4599 - val_acc: 0.7723\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2993 - acc: 0.8589 - val_loss: 0.4557 - val_acc: 0.7921\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2867 - acc: 0.8465 - val_loss: 0.4460 - val_acc: 0.7921\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3216 - acc: 0.8441 - val_loss: 0.5810 - val_acc: 0.6634\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3050 - acc: 0.8391 - val_loss: 0.4480 - val_acc: 0.8020\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2622 - acc: 0.8936 - val_loss: 0.5161 - val_acc: 0.7426\n",
      "Epoch 74/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2656 - acc: 0.8837 - val_loss: 0.4509 - val_acc: 0.7822\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2865 - acc: 0.8639 - val_loss: 0.4909 - val_acc: 0.7426\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2459 - acc: 0.8762 - val_loss: 0.4290 - val_acc: 0.8119\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2786 - acc: 0.8589 - val_loss: 0.4262 - val_acc: 0.8317\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3020 - acc: 0.8614 - val_loss: 0.4488 - val_acc: 0.7822\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2781 - acc: 0.8713 - val_loss: 0.5802 - val_acc: 0.6634\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2666 - acc: 0.8490 - val_loss: 0.4868 - val_acc: 0.7426\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2640 - acc: 0.8713 - val_loss: 0.4290 - val_acc: 0.8515\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2630 - acc: 0.8688 - val_loss: 0.4339 - val_acc: 0.8416\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2714 - acc: 0.8688 - val_loss: 0.4386 - val_acc: 0.8218\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2441 - acc: 0.8861 - val_loss: 0.4436 - val_acc: 0.8119\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2170 - acc: 0.9158 - val_loss: 0.4361 - val_acc: 0.8416\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2507 - acc: 0.8861 - val_loss: 0.4359 - val_acc: 0.8515\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2751 - acc: 0.8564 - val_loss: 0.5894 - val_acc: 0.6733\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2314 - acc: 0.9059 - val_loss: 0.4673 - val_acc: 0.7822\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2463 - acc: 0.8688 - val_loss: 0.4390 - val_acc: 0.8515\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2638 - acc: 0.8614 - val_loss: 0.4854 - val_acc: 0.7327\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2522 - acc: 0.8936 - val_loss: 0.4567 - val_acc: 0.7822\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2020 - acc: 0.8911 - val_loss: 0.4384 - val_acc: 0.8614\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2296 - acc: 0.8861 - val_loss: 0.4560 - val_acc: 0.7822\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2481 - acc: 0.8837 - val_loss: 0.4614 - val_acc: 0.7723\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2221 - acc: 0.8960 - val_loss: 0.4776 - val_acc: 0.7822\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2676 - acc: 0.8713 - val_loss: 0.4476 - val_acc: 0.8515\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2110 - acc: 0.8911 - val_loss: 0.4575 - val_acc: 0.8020\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2237 - acc: 0.9109 - val_loss: 0.5049 - val_acc: 0.7327\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2525 - acc: 0.8911 - val_loss: 0.5537 - val_acc: 0.7129\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2478 - acc: 0.8713 - val_loss: 0.5377 - val_acc: 0.7129\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2302 - acc: 0.8837 - val_loss: 0.4996 - val_acc: 0.7228\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2646 - acc: 0.8738 - val_loss: 0.4465 - val_acc: 0.8218\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2572 - acc: 0.8614 - val_loss: 0.4457 - val_acc: 0.8218\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2625 - acc: 0.8787 - val_loss: 0.4590 - val_acc: 0.7822\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2500 - acc: 0.8837 - val_loss: 0.4410 - val_acc: 0.8614\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2343 - acc: 0.8762 - val_loss: 0.4293 - val_acc: 0.8317\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2305 - acc: 0.8886 - val_loss: 0.4309 - val_acc: 0.8515\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2330 - acc: 0.8911 - val_loss: 0.4356 - val_acc: 0.8317\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2283 - acc: 0.8911 - val_loss: 0.4374 - val_acc: 0.8218\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2019 - acc: 0.9109 - val_loss: 0.5619 - val_acc: 0.7129\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2831 - acc: 0.8614 - val_loss: 0.5454 - val_acc: 0.7327\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2550 - acc: 0.8614 - val_loss: 0.4510 - val_acc: 0.8119\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2285 - acc: 0.8837 - val_loss: 0.4701 - val_acc: 0.7327\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2458 - acc: 0.8812 - val_loss: 0.4195 - val_acc: 0.8416\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2465 - acc: 0.8589 - val_loss: 0.4204 - val_acc: 0.8317\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2157 - acc: 0.9084 - val_loss: 0.5068 - val_acc: 0.7129\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2287 - acc: 0.8960 - val_loss: 0.5372 - val_acc: 0.7228\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2036 - acc: 0.9134 - val_loss: 0.4250 - val_acc: 0.8317\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2160 - acc: 0.8886 - val_loss: 0.4345 - val_acc: 0.8614\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2235 - acc: 0.8911 - val_loss: 0.4427 - val_acc: 0.8317\n",
      "[[66  8]\n",
      " [ 9 18]]\n",
      "[[66  8]\n",
      " [ 9 18]]\n",
      "results : pre = 0.692, acc = 0.832,rec = 0.667,f1 = 0.679,auc = 0.851,aupr = 0.762,auprc = 0.759\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.6167 - acc: 0.5743 - val_loss: 0.6754 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6520 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6134 - acc: 0.7351 - val_loss: 0.6371 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6441 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6125 - acc: 0.7351 - val_loss: 0.6432 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6128 - acc: 0.7351 - val_loss: 0.6456 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6530 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6456 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6455 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6105 - acc: 0.7351 - val_loss: 0.6453 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6419 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6352 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6097 - acc: 0.7351 - val_loss: 0.6437 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6100 - acc: 0.7351 - val_loss: 0.6447 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6103 - acc: 0.7351 - val_loss: 0.6410 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6444 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6095 - acc: 0.7351 - val_loss: 0.6354 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6369 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6077 - acc: 0.7351 - val_loss: 0.6470 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6082 - acc: 0.7351 - val_loss: 0.6341 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6048 - acc: 0.7351 - val_loss: 0.6357 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6037 - acc: 0.7327 - val_loss: 0.6371 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6001 - acc: 0.7475 - val_loss: 0.6339 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5946 - acc: 0.7450 - val_loss: 0.6192 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5909 - acc: 0.7475 - val_loss: 0.6130 - val_acc: 0.7426\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5843 - acc: 0.7599 - val_loss: 0.6105 - val_acc: 0.7426\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5763 - acc: 0.7673 - val_loss: 0.6099 - val_acc: 0.7525\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5659 - acc: 0.7624 - val_loss: 0.5731 - val_acc: 0.7525\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5516 - acc: 0.7797 - val_loss: 0.5689 - val_acc: 0.7822\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5385 - acc: 0.7797 - val_loss: 0.5744 - val_acc: 0.7624\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5230 - acc: 0.7550 - val_loss: 0.5048 - val_acc: 0.7525\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5165 - acc: 0.7847 - val_loss: 0.5389 - val_acc: 0.7921\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5007 - acc: 0.7822 - val_loss: 0.4870 - val_acc: 0.7921\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4969 - acc: 0.7748 - val_loss: 0.5522 - val_acc: 0.6634\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 4ms/step - loss: 0.5085 - acc: 0.7574 - val_loss: 0.5496 - val_acc: 0.6634\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4798 - acc: 0.7104 - val_loss: 0.4512 - val_acc: 0.7723\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4695 - acc: 0.7946 - val_loss: 0.4611 - val_acc: 0.7822\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 4ms/step - loss: 0.4463 - acc: 0.8020 - val_loss: 0.4268 - val_acc: 0.7921\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4523 - acc: 0.7871 - val_loss: 0.4195 - val_acc: 0.7822 0s - loss: 0.4686 - acc:\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4527 - acc: 0.7673 - val_loss: 0.4111 - val_acc: 0.8119\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4402 - acc: 0.8020 - val_loss: 0.5051 - val_acc: 0.7129\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 2s 6ms/step - loss: 0.4138 - acc: 0.7797 - val_loss: 0.4006 - val_acc: 0.8020\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4403 - acc: 0.7797 - val_loss: 0.3903 - val_acc: 0.8119 0s - loss: 0.4445 - acc: 0.776\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4177 - acc: 0.8069 - val_loss: 0.4062 - val_acc: 0.8317\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.4236 - acc: 0.7698 - val_loss: 0.3846 - val_acc: 0.8020\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3979 - acc: 0.8193 - val_loss: 0.3725 - val_acc: 0.8218\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3588 - acc: 0.8465 - val_loss: 0.3655 - val_acc: 0.8218\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3762 - acc: 0.8416 - val_loss: 0.3952 - val_acc: 0.8119\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3950 - acc: 0.8094 - val_loss: 0.3539 - val_acc: 0.8218\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3560 - acc: 0.8243 - val_loss: 0.3528 - val_acc: 0.8218\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3510 - acc: 0.8267 - val_loss: 0.3554 - val_acc: 0.8218\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3682 - acc: 0.8465 - val_loss: 0.3378 - val_acc: 0.8218\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3553 - acc: 0.8193 - val_loss: 0.3403 - val_acc: 0.8218\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3460 - acc: 0.8366 - val_loss: 0.3368 - val_acc: 0.8218\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3702 - acc: 0.8094 - val_loss: 0.3752 - val_acc: 0.7921\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3540 - acc: 0.8045 - val_loss: 0.3604 - val_acc: 0.8020\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3276 - acc: 0.8762 - val_loss: 0.3207 - val_acc: 0.8614\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 0.3160 - acc: 0.8738 - val_loss: 0.3169 - val_acc: 0.8416\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3162 - acc: 0.8515 - val_loss: 0.3140 - val_acc: 0.8416\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3187 - acc: 0.8416 - val_loss: 0.3415 - val_acc: 0.8119\n",
      "Epoch 61/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3264 - acc: 0.8094 - val_loss: 0.3830 - val_acc: 0.8020\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3372 - acc: 0.8416 - val_loss: 0.3592 - val_acc: 0.8020\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3277 - acc: 0.8292 - val_loss: 0.3115 - val_acc: 0.8713\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3502 - acc: 0.8193 - val_loss: 0.3195 - val_acc: 0.8515\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3313 - acc: 0.8465 - val_loss: 0.3130 - val_acc: 0.8713\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3402 - acc: 0.8441 - val_loss: 0.3051 - val_acc: 0.9109\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3014 - acc: 0.8589 - val_loss: 0.3009 - val_acc: 0.8416\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3197 - acc: 0.8391 - val_loss: 0.3054 - val_acc: 0.8317\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3212 - acc: 0.8342 - val_loss: 0.3934 - val_acc: 0.8020\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2854 - acc: 0.8663 - val_loss: 0.2976 - val_acc: 0.8614\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2985 - acc: 0.8614 - val_loss: 0.2954 - val_acc: 0.8614\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2688 - acc: 0.8861 - val_loss: 0.3051 - val_acc: 0.8317\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3143 - acc: 0.8342 - val_loss: 0.2950 - val_acc: 0.8812\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2940 - acc: 0.8540 - val_loss: 0.3016 - val_acc: 0.8812\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2678 - acc: 0.8861 - val_loss: 0.2951 - val_acc: 0.8911\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2700 - acc: 0.8812 - val_loss: 0.2913 - val_acc: 0.8713\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2776 - acc: 0.8837 - val_loss: 0.2984 - val_acc: 0.8515\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3109 - acc: 0.8342 - val_loss: 0.3740 - val_acc: 0.8119\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2963 - acc: 0.8639 - val_loss: 0.3376 - val_acc: 0.8218\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2482 - acc: 0.8911 - val_loss: 0.3444 - val_acc: 0.8218\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2444 - acc: 0.8911 - val_loss: 0.3019 - val_acc: 0.8218\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2570 - acc: 0.8911 - val_loss: 0.2835 - val_acc: 0.8614\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2762 - acc: 0.8540 - val_loss: 0.2979 - val_acc: 0.8416\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2670 - acc: 0.8762 - val_loss: 0.3069 - val_acc: 0.8317\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2435 - acc: 0.8837 - val_loss: 0.2811 - val_acc: 0.8911\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2357 - acc: 0.8960 - val_loss: 0.2913 - val_acc: 0.8614\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2562 - acc: 0.8762 - val_loss: 0.3011 - val_acc: 0.8416\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2413 - acc: 0.8936 - val_loss: 0.3050 - val_acc: 0.8317\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2513 - acc: 0.8837 - val_loss: 0.2863 - val_acc: 0.8614\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2865 - acc: 0.8589 - val_loss: 0.2794 - val_acc: 0.8713\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2698 - acc: 0.8837 - val_loss: 0.2782 - val_acc: 0.8911\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2610 - acc: 0.8812 - val_loss: 0.2776 - val_acc: 0.8911\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2352 - acc: 0.8936 - val_loss: 0.3009 - val_acc: 0.8416\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2222 - acc: 0.9134 - val_loss: 0.3680 - val_acc: 0.8218\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2555 - acc: 0.8713 - val_loss: 0.3987 - val_acc: 0.8020\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2621 - acc: 0.8762 - val_loss: 0.2937 - val_acc: 0.8515\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2408 - acc: 0.8886 - val_loss: 0.2965 - val_acc: 0.8416\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2309 - acc: 0.9059 - val_loss: 0.2918 - val_acc: 0.8614\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2582 - acc: 0.8540 - val_loss: 0.3795 - val_acc: 0.8218\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2316 - acc: 0.8861 - val_loss: 0.3184 - val_acc: 0.8317\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2486 - acc: 0.8787 - val_loss: 0.2761 - val_acc: 0.9010\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2510 - acc: 0.8960 - val_loss: 0.2973 - val_acc: 0.8713\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2395 - acc: 0.8787 - val_loss: 0.2892 - val_acc: 0.8614\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2021 - acc: 0.9109 - val_loss: 0.2808 - val_acc: 0.8812\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2142 - acc: 0.9084 - val_loss: 0.3548 - val_acc: 0.8218\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2313 - acc: 0.8911 - val_loss: 0.3617 - val_acc: 0.8218\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2316 - acc: 0.8837 - val_loss: 0.3597 - val_acc: 0.8218\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2391 - acc: 0.8985 - val_loss: 0.2726 - val_acc: 0.8812\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2210 - acc: 0.9134 - val_loss: 0.2766 - val_acc: 0.8713\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2371 - acc: 0.8911 - val_loss: 0.2724 - val_acc: 0.8812\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1929 - acc: 0.9233 - val_loss: 0.2797 - val_acc: 0.8614\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1822 - acc: 0.9134 - val_loss: 0.3585 - val_acc: 0.8317\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2053 - acc: 0.9233 - val_loss: 0.2829 - val_acc: 0.8812\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2812 - acc: 0.8837 - val_loss: 0.2654 - val_acc: 0.8812\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2051 - acc: 0.9208 - val_loss: 0.2896 - val_acc: 0.8614\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2730 - acc: 0.8515 - val_loss: 0.3180 - val_acc: 0.8317\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2410 - acc: 0.8861 - val_loss: 0.2990 - val_acc: 0.8614\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2098 - acc: 0.8837 - val_loss: 0.3668 - val_acc: 0.8119\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2156 - acc: 0.9059 - val_loss: 0.2721 - val_acc: 0.8911\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1871 - acc: 0.9183 - val_loss: 0.2720 - val_acc: 0.8911\n",
      "[[72  2]\n",
      " [ 9 18]]\n",
      "[[72  2]\n",
      " [ 9 18]]\n",
      "results : pre = 0.9, acc = 0.891,rec = 0.667,f1 = 0.766,auc = 0.945,aupr = 0.859,auprc = 0.855\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 4626)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              6168      \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 13,886\n",
      "Trainable params: 13,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.6159 - acc: 0.7228 - val_loss: 0.6629 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6479 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6472 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6116 - acc: 0.7351 - val_loss: 0.6417 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6411 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6430 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6104 - acc: 0.7351 - val_loss: 0.6421 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6413 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6443 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6438 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6103 - acc: 0.7351 - val_loss: 0.6469 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6095 - acc: 0.7351 - val_loss: 0.6469 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6097 - acc: 0.7351 - val_loss: 0.6371 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6092 - acc: 0.7351 - val_loss: 0.6379 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6071 - acc: 0.7351 - val_loss: 0.6377 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6070 - acc: 0.7351 - val_loss: 0.6367 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6049 - acc: 0.7351 - val_loss: 0.6498 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6040 - acc: 0.7376 - val_loss: 0.6463 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6011 - acc: 0.7376 - val_loss: 0.6236 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5973 - acc: 0.7401 - val_loss: 0.6314 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5928 - acc: 0.7649 - val_loss: 0.6538 - val_acc: 0.7426\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5846 - acc: 0.7574 - val_loss: 0.6092 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5825 - acc: 0.7550 - val_loss: 0.6278 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5726 - acc: 0.7624 - val_loss: 0.5956 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5685 - acc: 0.6262 - val_loss: 0.6235 - val_acc: 0.7525\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5537 - acc: 0.7723 - val_loss: 0.5767 - val_acc: 0.7525\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5351 - acc: 0.6881 - val_loss: 0.6096 - val_acc: 0.7228\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5189 - acc: 0.7970 - val_loss: 0.5688 - val_acc: 0.7525\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5038 - acc: 0.8119 - val_loss: 0.5813 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4945 - acc: 0.7401 - val_loss: 0.5424 - val_acc: 0.7624\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4672 - acc: 0.8119 - val_loss: 0.5471 - val_acc: 0.7525\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4518 - acc: 0.7624 - val_loss: 0.5121 - val_acc: 0.7624\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4617 - acc: 0.7871 - val_loss: 0.6234 - val_acc: 0.6238\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4532 - acc: 0.7822 - val_loss: 0.5442 - val_acc: 0.7426\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4304 - acc: 0.7921 - val_loss: 0.4879 - val_acc: 0.7624\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4248 - acc: 0.7896 - val_loss: 0.4783 - val_acc: 0.7723\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4342 - acc: 0.7772 - val_loss: 0.5025 - val_acc: 0.7624\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3882 - acc: 0.8267 - val_loss: 0.4749 - val_acc: 0.7624\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4320 - acc: 0.7772 - val_loss: 0.5123 - val_acc: 0.7525\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4015 - acc: 0.8218 - val_loss: 0.5664 - val_acc: 0.7030\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4073 - acc: 0.8045 - val_loss: 0.5183 - val_acc: 0.7822\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3734 - acc: 0.7847 - val_loss: 0.4587 - val_acc: 0.7822\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3834 - acc: 0.8020 - val_loss: 0.4680 - val_acc: 0.7822\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3764 - acc: 0.8020 - val_loss: 0.4816 - val_acc: 0.7624\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3815 - acc: 0.8292 - val_loss: 0.5507 - val_acc: 0.7525\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3365 - acc: 0.8342 - val_loss: 0.4800 - val_acc: 0.7525\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3746 - acc: 0.8144 - val_loss: 0.5587 - val_acc: 0.7426\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3832 - acc: 0.8045 - val_loss: 0.5698 - val_acc: 0.7228\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3422 - acc: 0.8391 - val_loss: 0.4620 - val_acc: 0.7624\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3548 - acc: 0.8366 - val_loss: 0.4865 - val_acc: 0.8119\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3293 - acc: 0.8589 - val_loss: 0.5613 - val_acc: 0.7327\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3357 - acc: 0.8490 - val_loss: 0.4434 - val_acc: 0.7822\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3489 - acc: 0.8045 - val_loss: 0.4437 - val_acc: 0.7921\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3139 - acc: 0.8490 - val_loss: 0.5330 - val_acc: 0.7723\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3090 - acc: 0.8762 - val_loss: 0.4389 - val_acc: 0.7822\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3488 - acc: 0.8119 - val_loss: 0.4575 - val_acc: 0.8020\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3237 - acc: 0.8564 - val_loss: 0.4918 - val_acc: 0.8317\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2752 - acc: 0.8861 - val_loss: 0.4352 - val_acc: 0.7723\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2700 - acc: 0.8787 - val_loss: 0.4900 - val_acc: 0.8119\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3076 - acc: 0.8416 - val_loss: 0.4430 - val_acc: 0.7822\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2780 - acc: 0.8688 - val_loss: 0.4307 - val_acc: 0.7624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2665 - acc: 0.8861 - val_loss: 0.4437 - val_acc: 0.8119\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2818 - acc: 0.8861 - val_loss: 0.4915 - val_acc: 0.8119\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3165 - acc: 0.8589 - val_loss: 0.4653 - val_acc: 0.8218\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2928 - acc: 0.8515 - val_loss: 0.4568 - val_acc: 0.8218\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3092 - acc: 0.8515 - val_loss: 0.4244 - val_acc: 0.7921\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2696 - acc: 0.8639 - val_loss: 0.4297 - val_acc: 0.7822\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3056 - acc: 0.8663 - val_loss: 0.4950 - val_acc: 0.8218\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2558 - acc: 0.8886 - val_loss: 0.4416 - val_acc: 0.8218\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2683 - acc: 0.8540 - val_loss: 0.4594 - val_acc: 0.7822\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2808 - acc: 0.8738 - val_loss: 0.4647 - val_acc: 0.8317\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2980 - acc: 0.8663 - val_loss: 0.4168 - val_acc: 0.7822\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2550 - acc: 0.8639 - val_loss: 0.4363 - val_acc: 0.8218\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2451 - acc: 0.8985 - val_loss: 0.4223 - val_acc: 0.8020\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2882 - acc: 0.8540 - val_loss: 0.4175 - val_acc: 0.7921\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2774 - acc: 0.8837 - val_loss: 0.4515 - val_acc: 0.8218\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2388 - acc: 0.8837 - val_loss: 0.4127 - val_acc: 0.7921\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2705 - acc: 0.8738 - val_loss: 0.4106 - val_acc: 0.7921\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2307 - acc: 0.9035 - val_loss: 0.4345 - val_acc: 0.8218\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2554 - acc: 0.8688 - val_loss: 0.4135 - val_acc: 0.7921\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2528 - acc: 0.8787 - val_loss: 0.4095 - val_acc: 0.7921\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2747 - acc: 0.8861 - val_loss: 0.4131 - val_acc: 0.7921\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2300 - acc: 0.8663 - val_loss: 0.4193 - val_acc: 0.8020\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2426 - acc: 0.9010 - val_loss: 0.4527 - val_acc: 0.8218\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2150 - acc: 0.8985 - val_loss: 0.4167 - val_acc: 0.7822\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2408 - acc: 0.8738 - val_loss: 0.4161 - val_acc: 0.7921\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2730 - acc: 0.8639 - val_loss: 0.4160 - val_acc: 0.7921\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2535 - acc: 0.8663 - val_loss: 0.4386 - val_acc: 0.8218\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2657 - acc: 0.8762 - val_loss: 0.4623 - val_acc: 0.8218\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2337 - acc: 0.9010 - val_loss: 0.4268 - val_acc: 0.8020\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2363 - acc: 0.8837 - val_loss: 0.4231 - val_acc: 0.7822\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2527 - acc: 0.8762 - val_loss: 0.4592 - val_acc: 0.8317\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2247 - acc: 0.9084 - val_loss: 0.4496 - val_acc: 0.8317\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2523 - acc: 0.9059 - val_loss: 0.4371 - val_acc: 0.8515\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2528 - acc: 0.8861 - val_loss: 0.4611 - val_acc: 0.8416\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2637 - acc: 0.8713 - val_loss: 0.4455 - val_acc: 0.8317\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2035 - acc: 0.9183 - val_loss: 0.4166 - val_acc: 0.7921\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2532 - acc: 0.8886 - val_loss: 0.5065 - val_acc: 0.8218\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2805 - acc: 0.8762 - val_loss: 0.6628 - val_acc: 0.6931\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2824 - acc: 0.8688 - val_loss: 0.4105 - val_acc: 0.7921\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2135 - acc: 0.8960 - val_loss: 0.4193 - val_acc: 0.8020\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2036 - acc: 0.9158 - val_loss: 0.4095 - val_acc: 0.7921\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2472 - acc: 0.8688 - val_loss: 0.4363 - val_acc: 0.7921\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2307 - acc: 0.9109 - val_loss: 0.4554 - val_acc: 0.8218\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2510 - acc: 0.8812 - val_loss: 0.4523 - val_acc: 0.8317\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2228 - acc: 0.9035 - val_loss: 0.4161 - val_acc: 0.7921\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2106 - acc: 0.9010 - val_loss: 0.4213 - val_acc: 0.8119\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1948 - acc: 0.9183 - val_loss: 0.4404 - val_acc: 0.7921\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2243 - acc: 0.9134 - val_loss: 0.4105 - val_acc: 0.7723\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2179 - acc: 0.8861 - val_loss: 0.4095 - val_acc: 0.7822\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1962 - acc: 0.9208 - val_loss: 0.4390 - val_acc: 0.8218\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2028 - acc: 0.9084 - val_loss: 0.4127 - val_acc: 0.7822\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.1750 - acc: 0.9233 - val_loss: 0.4147 - val_acc: 0.8020\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2369 - acc: 0.8861 - val_loss: 0.4324 - val_acc: 0.8218\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2047 - acc: 0.9035 - val_loss: 0.4162 - val_acc: 0.7822\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2237 - acc: 0.9010 - val_loss: 0.4401 - val_acc: 0.7921\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2003 - acc: 0.9084 - val_loss: 0.4220 - val_acc: 0.7822\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2218 - acc: 0.9059 - val_loss: 0.4741 - val_acc: 0.8317\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2539 - acc: 0.8713 - val_loss: 0.4844 - val_acc: 0.8317\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.2263 - acc: 0.8960 - val_loss: 0.4137 - val_acc: 0.8020\n",
      "[[64 10]\n",
      " [10 17]]\n",
      "[[64 10]\n",
      " [10 17]]\n",
      "results : pre = 0.63, acc = 0.802,rec = 0.63,f1 = 0.63,auc = 0.875,aupr = 0.724,auprc = 0.718\n",
      "average value : pre = 0.744, acc = 0.834,rec = 0.672,f1 = 0.693,auc = 0.882,aupr = 0.792,auprc = 0.718\n"
     ]
    }
   ],
   "source": [
    "#Five-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590) \n",
    "\n",
    "\n",
    "kfscore = []\n",
    "\n",
    "p = 0\n",
    "x = Omics_data.values\n",
    "y = y.reshape(-1)\n",
    "x_0 =  0.68\n",
    "x_1 =  1.48\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = create_model(x)\n",
    "\n",
    "    history = model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=120,class_weight={0:x_0,1:x_1},batch_size = 32)  #epochs=50,class_weight={0:0.5,1:1.35},batch_size = 64\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    kfscore.append(evaluates(y_test, y_pred))\n",
    "    results = evaluates(y_test, y_pred)\n",
    "    print(\"results : pre = {}, acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(results[0],3),round(results[1],3),round(results[2],3),round(results[3],3),round(results[4],3),round(results[5],3),round(results[6],3)))\n",
    "\n",
    "    # feature importance\n",
    "    explain_x = X_train[np.where(y_train!=0)]\n",
    "    explain_y = y_train[np.where(y_train!=0)]\n",
    "    coef_ = get_coef_importance(model,explain_x, explain_y, target=-1,feature_importance='deepexplain_deeplift')\n",
    "    cof_values = ['inputs','h_0','h0','h1','h2','h3','h4']\n",
    "    name = [np.array(Omics_data.columns),gene_pathway_df.columns,Get_Node_relation[3].index,Get_Node_relation[2].index,Get_Node_relation[1].index,Get_Node_relation[0].index,Get_Node_relation[0].columns]\n",
    "#     os.mkdir('./data/coef/h{}/'.format(p))\n",
    "    for i in range(0,7):\n",
    "        X = pd.DataFrame()\n",
    "        X['name'] = name[i]\n",
    "        X['values'] = coef_[0][cof_values[i]]\n",
    "        X.to_csv('./data/coef/h{}/{}.csv'.format(p,cof_values[i]),index=False,encoding='UTF-8')\n",
    "    p =p+1\n",
    "#avrrage\n",
    "kfscores = np.array(kfscore).sum(axis= 0)/5.0\n",
    "print(\"average value : pre = {}, acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(kfscores[0],3),round(kfscores[1],3),round(kfscores[2],3),round(kfscores[3],3),round(kfscores[4],3),round(kfscores[5],3),round(results[6],3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  average  five result\n",
    "file_name = ['inputs.csv','h_0.csv','h0.csv','h1.csv','h2.csv','h3.csv','h4.csv']\n",
    "os.mkdir('./data/coef/average')\n",
    "for j in file_name:\n",
    "    result0 =pd.DataFrame()\n",
    "    for i in range(0,5):\n",
    "         result  = pd.read_csv('./data/coef/h{}/{}'.format(i,j))\n",
    "         result0 = result0.append(result)\n",
    "    results = pd.DataFrame(result0.groupby('name')['values'].mean()).reset_index().sort_values('values',ascending=False)\n",
    "    results.to_csv('./data/coef/average/{}'.format(j),index = False)\n",
    "    print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single omics training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_model(omics_data):\n",
    "    S_inputs = Input(shape=(omics_data.shape[1],), dtype='float32',name= 'inputs')\n",
    "    #gene and pathway\n",
    "\n",
    "    h0 = SparseTF(gene_pathway_df.shape[0],mapp =gene_pathway_df.values.T, name = 'h0')(S_inputs)\n",
    "    drop0 = keras.layers.Dropout(0.5)(h0)\n",
    "\n",
    "    h1 = SparseTF(Get_Node_relation[3].shape[1],mapp =Get_Node_relation[3].values ,name = 'h1')(drop0)\n",
    "    drop_h1 = keras.layers.Dropout(0.1)(h1)\n",
    "\n",
    "\n",
    "    h2 = SparseTF(Get_Node_relation[2].shape[1],mapp =Get_Node_relation[2].values, name = 'h2')(drop_h1)\n",
    "    drop2 = keras.layers.Dropout(0.1)(h2)\n",
    "\n",
    "\n",
    "    h3 = SparseTF(Get_Node_relation[1].shape[1],mapp =Get_Node_relation[1].values, name = 'h3')(drop2)\n",
    "    drop3 = keras.layers.Dropout(0.1)(h3)\n",
    "\n",
    "    \n",
    "    h4 = SparseTF(Get_Node_relation[0].shape[1],mapp =Get_Node_relation[0].values, name = 'h4')(drop3)\n",
    "    drop4 = keras.layers.Dropout(0.1)(h4)\n",
    "\n",
    "    Output = keras.layers.Dense(1,activation='sigmoid')(drop4)\n",
    "\n",
    "    model = Model(inputs=S_inputs, outputs=Output)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr = 0.001) #,decay=-0.0001\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single omics\n",
    "#snv_data; cnv_amp; cnv_del\n",
    "single_snv =Omics_data.swaplevel(i=0, j=1, axis=1)['snv_data']\n",
    "single_snv = single_snv.join(response,how='inner')\n",
    "single_snv.shape\n",
    "\n",
    "single_x = single_snv.values[:,0:-1]\n",
    "single_y =  single_snv.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 9s 21ms/step - loss: 0.6181 - acc: 0.7327 - val_loss: 0.6716 - val_acc: 0.7426\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6155 - acc: 0.7327 - val_loss: 0.6591 - val_acc: 0.7426\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6140 - acc: 0.7327 - val_loss: 0.6538 - val_acc: 0.7426\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6139 - acc: 0.7327 - val_loss: 0.6478 - val_acc: 0.7426\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6142 - acc: 0.7327 - val_loss: 0.6445 - val_acc: 0.7426\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6143 - acc: 0.7327 - val_loss: 0.6452 - val_acc: 0.7426\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6147 - acc: 0.7327 - val_loss: 0.6449 - val_acc: 0.7426\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6139 - acc: 0.7327 - val_loss: 0.6493 - val_acc: 0.7426\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6134 - acc: 0.7327 - val_loss: 0.6484 - val_acc: 0.7426\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6142 - acc: 0.7327 - val_loss: 0.6463 - val_acc: 0.7426\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6137 - acc: 0.7327 - val_loss: 0.6473 - val_acc: 0.7426\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6131 - acc: 0.7327 - val_loss: 0.6424 - val_acc: 0.7426\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6134 - acc: 0.7327 - val_loss: 0.6414 - val_acc: 0.7426\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6156 - acc: 0.7327 - val_loss: 0.6402 - val_acc: 0.7426\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6148 - acc: 0.7327 - val_loss: 0.6424 - val_acc: 0.7426\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6135 - acc: 0.7327 - val_loss: 0.6427 - val_acc: 0.7426\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6136 - acc: 0.7327 - val_loss: 0.6444 - val_acc: 0.7426\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6124 - acc: 0.7327 - val_loss: 0.6468 - val_acc: 0.7426\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6129 - acc: 0.7327 - val_loss: 0.6422 - val_acc: 0.7426\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6124 - acc: 0.7327 - val_loss: 0.6406 - val_acc: 0.7426\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6124 - acc: 0.7327 - val_loss: 0.6413 - val_acc: 0.7426\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6130 - acc: 0.7327 - val_loss: 0.6391 - val_acc: 0.7426\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6152 - acc: 0.7327 - val_loss: 0.6404 - val_acc: 0.7426\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6146 - acc: 0.7327 - val_loss: 0.6472 - val_acc: 0.7426\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6137 - acc: 0.7327 - val_loss: 0.6465 - val_acc: 0.7426\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6149 - acc: 0.7327 - val_loss: 0.6504 - val_acc: 0.7426\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6132 - acc: 0.7327 - val_loss: 0.6479 - val_acc: 0.7426\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6114 - acc: 0.7327 - val_loss: 0.6452 - val_acc: 0.7426\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6133 - acc: 0.7327 - val_loss: 0.6406 - val_acc: 0.7426\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6135 - acc: 0.7327 - val_loss: 0.6410 - val_acc: 0.7426\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6143 - acc: 0.7327 - val_loss: 0.6456 - val_acc: 0.7426\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7327 - val_loss: 0.6417 - val_acc: 0.7426\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6121 - acc: 0.7327 - val_loss: 0.6381 - val_acc: 0.7426\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6121 - acc: 0.7327 - val_loss: 0.6425 - val_acc: 0.7426\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6127 - acc: 0.7327 - val_loss: 0.6414 - val_acc: 0.7426\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6128 - acc: 0.7327 - val_loss: 0.6408 - val_acc: 0.7426\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6123 - acc: 0.7327 - val_loss: 0.6414 - val_acc: 0.7426\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6126 - acc: 0.7327 - val_loss: 0.6468 - val_acc: 0.7426\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7327 - val_loss: 0.6398 - val_acc: 0.7426\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 0.6106 - acc: 0.7327 - val_loss: 0.6377 - val_acc: 0.7426\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6102 - acc: 0.7327 - val_loss: 0.6408 - val_acc: 0.7426\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6090 - acc: 0.7327 - val_loss: 0.6430 - val_acc: 0.7426\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6094 - acc: 0.7327 - val_loss: 0.6406 - val_acc: 0.7426\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6092 - acc: 0.7327 - val_loss: 0.6434 - val_acc: 0.7426\n",
      "Epoch 45/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6096 - acc: 0.7327 - val_loss: 0.6349 - val_acc: 0.7426\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6040 - acc: 0.7376 - val_loss: 0.6367 - val_acc: 0.7426\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6046 - acc: 0.7401 - val_loss: 0.6334 - val_acc: 0.7426\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5988 - acc: 0.7401 - val_loss: 0.6219 - val_acc: 0.7426\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5992 - acc: 0.7401 - val_loss: 0.6317 - val_acc: 0.7525\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5987 - acc: 0.7079 - val_loss: 0.6352 - val_acc: 0.7525\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5967 - acc: 0.7327 - val_loss: 0.6136 - val_acc: 0.7525\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5880 - acc: 0.7426 - val_loss: 0.6311 - val_acc: 0.7624\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5861 - acc: 0.7376 - val_loss: 0.6032 - val_acc: 0.7525\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5827 - acc: 0.7351 - val_loss: 0.6187 - val_acc: 0.7624\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5847 - acc: 0.7079 - val_loss: 0.6043 - val_acc: 0.7624\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5723 - acc: 0.6708 - val_loss: 0.5978 - val_acc: 0.7624\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5833 - acc: 0.7376 - val_loss: 0.5949 - val_acc: 0.7822\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5633 - acc: 0.7005 - val_loss: 0.5737 - val_acc: 0.7822\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5510 - acc: 0.7748 - val_loss: 0.6011 - val_acc: 0.7525\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5615 - acc: 0.7054 - val_loss: 0.5866 - val_acc: 0.7723\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5325 - acc: 0.7649 - val_loss: 0.5272 - val_acc: 0.7624\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5407 - acc: 0.7500 - val_loss: 0.5861 - val_acc: 0.7822\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5465 - acc: 0.7203 - val_loss: 0.5672 - val_acc: 0.7624\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5444 - acc: 0.6832 - val_loss: 0.5374 - val_acc: 0.7723\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5347 - acc: 0.6757 - val_loss: 0.5169 - val_acc: 0.7723\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5280 - acc: 0.7475 - val_loss: 0.5560 - val_acc: 0.7921\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5106 - acc: 0.7599 - val_loss: 0.5597 - val_acc: 0.8515\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5171 - acc: 0.7203 - val_loss: 0.4954 - val_acc: 0.7723\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5078 - acc: 0.7203 - val_loss: 0.5043 - val_acc: 0.7822\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4887 - acc: 0.7550 - val_loss: 0.5240 - val_acc: 0.8020\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5120 - acc: 0.7228 - val_loss: 0.6017 - val_acc: 0.5941\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5026 - acc: 0.7351 - val_loss: 0.5618 - val_acc: 0.6733\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4932 - acc: 0.7327 - val_loss: 0.4668 - val_acc: 0.7723\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4826 - acc: 0.7054 - val_loss: 0.5098 - val_acc: 0.8416\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4696 - acc: 0.7574 - val_loss: 0.4579 - val_acc: 0.7822\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4825 - acc: 0.7525 - val_loss: 0.4912 - val_acc: 0.8119\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4588 - acc: 0.7748 - val_loss: 0.4628 - val_acc: 0.8020\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4504 - acc: 0.7772 - val_loss: 0.4617 - val_acc: 0.8020\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4524 - acc: 0.7599 - val_loss: 0.4408 - val_acc: 0.7921\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4736 - acc: 0.7525 - val_loss: 0.5457 - val_acc: 0.6832\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4776 - acc: 0.7550 - val_loss: 0.4437 - val_acc: 0.8020\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4759 - acc: 0.7649 - val_loss: 0.6606 - val_acc: 0.5545\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4909 - acc: 0.7351 - val_loss: 0.4243 - val_acc: 0.8119\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4699 - acc: 0.6955 - val_loss: 0.4252 - val_acc: 0.7822\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4421 - acc: 0.7673 - val_loss: 0.5042 - val_acc: 0.7327\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4426 - acc: 0.7847 - val_loss: 0.4658 - val_acc: 0.8614\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4520 - acc: 0.7351 - val_loss: 0.4271 - val_acc: 0.8119\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4600 - acc: 0.7327 - val_loss: 0.4175 - val_acc: 0.8119\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4136 - acc: 0.7847 - val_loss: 0.4312 - val_acc: 0.8416\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4144 - acc: 0.7698 - val_loss: 0.4289 - val_acc: 0.8614\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4522 - acc: 0.7351 - val_loss: 0.3991 - val_acc: 0.8020\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4344 - acc: 0.7649 - val_loss: 0.4152 - val_acc: 0.8416\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4308 - acc: 0.7921 - val_loss: 0.4483 - val_acc: 0.8812\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4211 - acc: 0.7772 - val_loss: 0.4747 - val_acc: 0.7525\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4230 - acc: 0.7921 - val_loss: 0.5033 - val_acc: 0.7129\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4251 - acc: 0.7847 - val_loss: 0.4699 - val_acc: 0.7525\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4094 - acc: 0.7847 - val_loss: 0.4436 - val_acc: 0.8614\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3879 - acc: 0.7921 - val_loss: 0.3832 - val_acc: 0.8119\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4134 - acc: 0.8218 - val_loss: 0.5023 - val_acc: 0.6931\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4501 - acc: 0.7748 - val_loss: 0.5002 - val_acc: 0.7030\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4341 - acc: 0.7574 - val_loss: 0.3965 - val_acc: 0.8515\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3892 - acc: 0.8267 - val_loss: 0.5105 - val_acc: 0.6832\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4365 - acc: 0.7946 - val_loss: 0.4992 - val_acc: 0.7030\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3966 - acc: 0.7723 - val_loss: 0.3867 - val_acc: 0.8515\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3978 - acc: 0.7822 - val_loss: 0.4044 - val_acc: 0.8812\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3989 - acc: 0.7822 - val_loss: 0.3776 - val_acc: 0.8416\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3835 - acc: 0.7797 - val_loss: 0.3713 - val_acc: 0.8317\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4097 - acc: 0.7847 - val_loss: 0.4364 - val_acc: 0.8614\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3944 - acc: 0.7797 - val_loss: 0.3919 - val_acc: 0.8812\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3887 - acc: 0.8069 - val_loss: 0.4155 - val_acc: 0.8713\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4186 - acc: 0.7921 - val_loss: 0.5708 - val_acc: 0.6337\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4323 - acc: 0.7698 - val_loss: 0.3760 - val_acc: 0.8416\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3878 - acc: 0.7698 - val_loss: 0.3655 - val_acc: 0.8218\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4039 - acc: 0.7624 - val_loss: 0.3775 - val_acc: 0.8020\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3868 - acc: 0.7822 - val_loss: 0.4128 - val_acc: 0.8812\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3919 - acc: 0.8317 - val_loss: 0.4286 - val_acc: 0.8812\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4013 - acc: 0.7574 - val_loss: 0.3688 - val_acc: 0.8317\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3950 - acc: 0.8069 - val_loss: 0.4028 - val_acc: 0.8713\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3850 - acc: 0.8144 - val_loss: 0.4433 - val_acc: 0.8713\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3867 - acc: 0.7822 - val_loss: 0.3665 - val_acc: 0.8020\n",
      "[[72  3]\n",
      " [17  9]]\n",
      "[[72  3]\n",
      " [17  9]]\n",
      "results : acc = 0.75,rec = 0.802,f1 = 0.346,auc = 0.474,aupr = 0.93,auprc = 0.804\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 9s 22ms/step - loss: 0.6163 - acc: 0.7252 - val_loss: 0.6688 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6129 - acc: 0.7351 - val_loss: 0.6590 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.6195 - acc: 0.724 - 1s 1ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6458 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6411 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6390 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6413 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6386 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6133 - acc: 0.7351 - val_loss: 0.6429 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6105 - acc: 0.7351 - val_loss: 0.6451 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6407 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6489 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6472 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6141 - acc: 0.7351 - val_loss: 0.6510 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6132 - acc: 0.7351 - val_loss: 0.6433 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6137 - acc: 0.7351 - val_loss: 0.6472 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6462 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6462 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6122 - acc: 0.7351 - val_loss: 0.6470 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6526 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6438 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6490 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6525 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6423 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6091 - acc: 0.7351 - val_loss: 0.6336 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6098 - acc: 0.7351 - val_loss: 0.6383 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6403 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6091 - acc: 0.7351 - val_loss: 0.6457 - val_acc: 0.7327\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6078 - acc: 0.7351 - val_loss: 0.6459 - val_acc: 0.7327\n",
      "Epoch 29/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6092 - acc: 0.7351 - val_loss: 0.6370 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6062 - acc: 0.7351 - val_loss: 0.6408 - val_acc: 0.7327\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6056 - acc: 0.7376 - val_loss: 0.6421 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6028 - acc: 0.7376 - val_loss: 0.6456 - val_acc: 0.7327\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6018 - acc: 0.7401 - val_loss: 0.6292 - val_acc: 0.7327\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6074 - acc: 0.7376 - val_loss: 0.6186 - val_acc: 0.7327\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5971 - acc: 0.7550 - val_loss: 0.6369 - val_acc: 0.7327\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5978 - acc: 0.7376 - val_loss: 0.6243 - val_acc: 0.7327\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5964 - acc: 0.7475 - val_loss: 0.6309 - val_acc: 0.7327\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5865 - acc: 0.7500 - val_loss: 0.6110 - val_acc: 0.7426\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5810 - acc: 0.6881 - val_loss: 0.6217 - val_acc: 0.7426\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5778 - acc: 0.7500 - val_loss: 0.6048 - val_acc: 0.7426\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5747 - acc: 0.7525 - val_loss: 0.5912 - val_acc: 0.7426\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5735 - acc: 0.7426 - val_loss: 0.5984 - val_acc: 0.7525\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5478 - acc: 0.7401 - val_loss: 0.5558 - val_acc: 0.7327\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5538 - acc: 0.7327 - val_loss: 0.6224 - val_acc: 0.6436\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5470 - acc: 0.6658 - val_loss: 0.5278 - val_acc: 0.7426\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5583 - acc: 0.7426 - val_loss: 0.6099 - val_acc: 0.6634\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5405 - acc: 0.7178 - val_loss: 0.5905 - val_acc: 0.8020\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5397 - acc: 0.6832 - val_loss: 0.5329 - val_acc: 0.7723\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5255 - acc: 0.7351 - val_loss: 0.5332 - val_acc: 0.7723\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5289 - acc: 0.7574 - val_loss: 0.5329 - val_acc: 0.8020\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5076 - acc: 0.7500 - val_loss: 0.4967 - val_acc: 0.7822\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5076 - acc: 0.7376 - val_loss: 0.5376 - val_acc: 0.7921\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4951 - acc: 0.7475 - val_loss: 0.4738 - val_acc: 0.7822\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5043 - acc: 0.7574 - val_loss: 0.5060 - val_acc: 0.7921\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4799 - acc: 0.7426 - val_loss: 0.4544 - val_acc: 0.7822\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4833 - acc: 0.7772 - val_loss: 0.5648 - val_acc: 0.6337\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4924 - acc: 0.7401 - val_loss: 0.5538 - val_acc: 0.6634\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4825 - acc: 0.7574 - val_loss: 0.6203 - val_acc: 0.5644\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5071 - acc: 0.7277 - val_loss: 0.4658 - val_acc: 0.7921\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4650 - acc: 0.7550 - val_loss: 0.4306 - val_acc: 0.7921\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5008 - acc: 0.6832 - val_loss: 0.4362 - val_acc: 0.7822\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4888 - acc: 0.7178 - val_loss: 0.4263 - val_acc: 0.8020\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4848 - acc: 0.7525 - val_loss: 0.5248 - val_acc: 0.6931\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4415 - acc: 0.7946 - val_loss: 0.4203 - val_acc: 0.8317\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4413 - acc: 0.7772 - val_loss: 0.4126 - val_acc: 0.8218\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4333 - acc: 0.7921 - val_loss: 0.4559 - val_acc: 0.8020\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4352 - acc: 0.7896 - val_loss: 0.4586 - val_acc: 0.8020\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4628 - acc: 0.7599 - val_loss: 0.3980 - val_acc: 0.8317\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4200 - acc: 0.7772 - val_loss: 0.3940 - val_acc: 0.8020\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4572 - acc: 0.7376 - val_loss: 0.3925 - val_acc: 0.8416\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3889 - acc: 0.8490 - val_loss: 0.4945 - val_acc: 0.6931\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4481 - acc: 0.7376 - val_loss: 0.3901 - val_acc: 0.8218\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4411 - acc: 0.7525 - val_loss: 0.3917 - val_acc: 0.8119\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4130 - acc: 0.7723 - val_loss: 0.3870 - val_acc: 0.8218\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4024 - acc: 0.8094 - val_loss: 0.3839 - val_acc: 0.8218\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4289 - acc: 0.8119 - val_loss: 0.4209 - val_acc: 0.8218\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4523 - acc: 0.7030 - val_loss: 0.3955 - val_acc: 0.8020\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4557 - acc: 0.7153 - val_loss: 0.3806 - val_acc: 0.8416\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4170 - acc: 0.8045 - val_loss: 0.4070 - val_acc: 0.8020\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3968 - acc: 0.8267 - val_loss: 0.3781 - val_acc: 0.8416\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4226 - acc: 0.7797 - val_loss: 0.3752 - val_acc: 0.8317\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4385 - acc: 0.7624 - val_loss: 0.4140 - val_acc: 0.8218\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4015 - acc: 0.7896 - val_loss: 0.4022 - val_acc: 0.8020\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4006 - acc: 0.8144 - val_loss: 0.3774 - val_acc: 0.8317\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4097 - acc: 0.7822 - val_loss: 0.3712 - val_acc: 0.8317\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4003 - acc: 0.7921 - val_loss: 0.3747 - val_acc: 0.8416\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3739 - acc: 0.8366 - val_loss: 0.4009 - val_acc: 0.8218\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4017 - acc: 0.7995 - val_loss: 0.3967 - val_acc: 0.8218\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3761 - acc: 0.8094 - val_loss: 0.3765 - val_acc: 0.8317\n",
      "Epoch 90/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3870 - acc: 0.7896 - val_loss: 0.3644 - val_acc: 0.8416\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3802 - acc: 0.7921 - val_loss: 0.3872 - val_acc: 0.8020\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4072 - acc: 0.8069 - val_loss: 0.3910 - val_acc: 0.8317\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3678 - acc: 0.8391 - val_loss: 0.3709 - val_acc: 0.8218\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4195 - acc: 0.8094 - val_loss: 0.4392 - val_acc: 0.7129\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3857 - acc: 0.8441 - val_loss: 0.3935 - val_acc: 0.8416\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3898 - acc: 0.7673 - val_loss: 0.3798 - val_acc: 0.8119\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4066 - acc: 0.7871 - val_loss: 0.3593 - val_acc: 0.8317\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3816 - acc: 0.8292 - val_loss: 0.3678 - val_acc: 0.8119\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3784 - acc: 0.8144 - val_loss: 0.3816 - val_acc: 0.8218\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3653 - acc: 0.8465 - val_loss: 0.3956 - val_acc: 0.8614\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3546 - acc: 0.8441 - val_loss: 0.3622 - val_acc: 0.8317\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4026 - acc: 0.7723 - val_loss: 0.3572 - val_acc: 0.8416\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3945 - acc: 0.7995 - val_loss: 0.3741 - val_acc: 0.8317\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3793 - acc: 0.8069 - val_loss: 0.4158 - val_acc: 0.7426\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3879 - acc: 0.7921 - val_loss: 0.3580 - val_acc: 0.8317\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3590 - acc: 0.8441 - val_loss: 0.3606 - val_acc: 0.8119\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3612 - acc: 0.8366 - val_loss: 0.3930 - val_acc: 0.8614\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3567 - acc: 0.8391 - val_loss: 0.4578 - val_acc: 0.7228\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4086 - acc: 0.7673 - val_loss: 0.3554 - val_acc: 0.8317\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3627 - acc: 0.7871 - val_loss: 0.3614 - val_acc: 0.8317\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3390 - acc: 0.8639 - val_loss: 0.3562 - val_acc: 0.8416\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3859 - acc: 0.7698 - val_loss: 0.3679 - val_acc: 0.8218\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3790 - acc: 0.7871 - val_loss: 0.3525 - val_acc: 0.8317\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3497 - acc: 0.8515 - val_loss: 0.3592 - val_acc: 0.8317\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3649 - acc: 0.8119 - val_loss: 0.3563 - val_acc: 0.8218\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3563 - acc: 0.8267 - val_loss: 0.3520 - val_acc: 0.8416\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3404 - acc: 0.8614 - val_loss: 0.3747 - val_acc: 0.8614\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3306 - acc: 0.8515 - val_loss: 0.3526 - val_acc: 0.8218\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3549 - acc: 0.8317 - val_loss: 0.3505 - val_acc: 0.8416\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3531 - acc: 0.8267 - val_loss: 0.3558 - val_acc: 0.8317\n",
      "[[72  2]\n",
      " [15 12]]\n",
      "[[72  2]\n",
      " [15 12]]\n",
      "results : acc = 0.857,rec = 0.832,f1 = 0.444,auc = 0.585,aupr = 0.901,auprc = 0.809\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 9s 22ms/step - loss: 0.6165 - acc: 0.7153 - val_loss: 0.6698 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6130 - acc: 0.7351 - val_loss: 0.6553 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6487 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6433 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6133 - acc: 0.7351 - val_loss: 0.6393 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6128 - acc: 0.7351 - val_loss: 0.6397 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6139 - acc: 0.7351 - val_loss: 0.6502 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6130 - acc: 0.7351 - val_loss: 0.6569 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6463 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6128 - acc: 0.7351 - val_loss: 0.6468 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6129 - acc: 0.7351 - val_loss: 0.6471 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6448 - val_acc: 0.7327\n",
      "Epoch 13/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6448 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6461 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6128 - acc: 0.7351 - val_loss: 0.6401 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6401 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6116 - acc: 0.7351 - val_loss: 0.6443 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6410 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6474 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6494 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6126 - acc: 0.7351 - val_loss: 0.6452 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6415 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6420 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6428 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6116 - acc: 0.7351 - val_loss: 0.6454 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6105 - acc: 0.7351 - val_loss: 0.6476 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6101 - acc: 0.7351 - val_loss: 0.6394 - val_acc: 0.7327\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6408 - val_acc: 0.7327\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6096 - acc: 0.7351 - val_loss: 0.6393 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6104 - acc: 0.7351 - val_loss: 0.6438 - val_acc: 0.7327\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6092 - acc: 0.7351 - val_loss: 0.6350 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6088 - acc: 0.7351 - val_loss: 0.6382 - val_acc: 0.7327\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6092 - acc: 0.7351 - val_loss: 0.6389 - val_acc: 0.7327\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6069 - acc: 0.7351 - val_loss: 0.6464 - val_acc: 0.7327\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6049 - acc: 0.7351 - val_loss: 0.6281 - val_acc: 0.7327\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6070 - acc: 0.7351 - val_loss: 0.6348 - val_acc: 0.7327\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6044 - acc: 0.7351 - val_loss: 0.6457 - val_acc: 0.7327\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5984 - acc: 0.7401 - val_loss: 0.6472 - val_acc: 0.7327\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6011 - acc: 0.7426 - val_loss: 0.6267 - val_acc: 0.7327\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5927 - acc: 0.7401 - val_loss: 0.6347 - val_acc: 0.7327\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5925 - acc: 0.7426 - val_loss: 0.6142 - val_acc: 0.7327\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5893 - acc: 0.7277 - val_loss: 0.6389 - val_acc: 0.7624\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5829 - acc: 0.7327 - val_loss: 0.6384 - val_acc: 0.7723\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5855 - acc: 0.7054 - val_loss: 0.6027 - val_acc: 0.7525\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5941 - acc: 0.5693 - val_loss: 0.6003 - val_acc: 0.7525\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5718 - acc: 0.7698 - val_loss: 0.5881 - val_acc: 0.7525\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5752 - acc: 0.6931 - val_loss: 0.5909 - val_acc: 0.7624\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5544 - acc: 0.7673 - val_loss: 0.5882 - val_acc: 0.7723\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5468 - acc: 0.7351 - val_loss: 0.5699 - val_acc: 0.7723\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5612 - acc: 0.6609 - val_loss: 0.5580 - val_acc: 0.7723\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5390 - acc: 0.7673 - val_loss: 0.6344 - val_acc: 0.5743\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5405 - acc: 0.7203 - val_loss: 0.5215 - val_acc: 0.7723\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5190 - acc: 0.7376 - val_loss: 0.5976 - val_acc: 0.6238\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5228 - acc: 0.7327 - val_loss: 0.5242 - val_acc: 0.7624\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5356 - acc: 0.6188 - val_loss: 0.5056 - val_acc: 0.7723\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5263 - acc: 0.7475 - val_loss: 0.5400 - val_acc: 0.8020\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5052 - acc: 0.7450 - val_loss: 0.5316 - val_acc: 0.8119\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5265 - acc: 0.7649 - val_loss: 0.6511 - val_acc: 0.5644\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5172 - acc: 0.6856 - val_loss: 0.4831 - val_acc: 0.7822\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4883 - acc: 0.7129 - val_loss: 0.4975 - val_acc: 0.8020\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5066 - acc: 0.7153 - val_loss: 0.5697 - val_acc: 0.6238\n",
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4786 - acc: 0.7252 - val_loss: 0.4694 - val_acc: 0.8020\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4881 - acc: 0.7525 - val_loss: 0.5034 - val_acc: 0.8119\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4738 - acc: 0.7723 - val_loss: 0.5409 - val_acc: 0.6634\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4737 - acc: 0.7475 - val_loss: 0.4678 - val_acc: 0.8119\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4577 - acc: 0.7995 - val_loss: 0.4829 - val_acc: 0.8119\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4763 - acc: 0.7153 - val_loss: 0.4377 - val_acc: 0.8020\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4864 - acc: 0.7649 - val_loss: 0.4574 - val_acc: 0.8317\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4502 - acc: 0.7426 - val_loss: 0.4329 - val_acc: 0.8020\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4504 - acc: 0.7723 - val_loss: 0.4844 - val_acc: 0.8218\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4488 - acc: 0.7970 - val_loss: 0.4968 - val_acc: 0.7822\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4353 - acc: 0.7946 - val_loss: 0.4972 - val_acc: 0.7129\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4415 - acc: 0.7475 - val_loss: 0.4197 - val_acc: 0.7921\n",
      "Epoch 74/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4252 - acc: 0.7797 - val_loss: 0.4485 - val_acc: 0.8020\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4374 - acc: 0.7970 - val_loss: 0.4644 - val_acc: 0.8119\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4273 - acc: 0.8020 - val_loss: 0.5688 - val_acc: 0.6139\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4802 - acc: 0.7550 - val_loss: 0.4626 - val_acc: 0.8020\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.4289 - acc: 0.7772 - val_loss: 0.4071 - val_acc: 0.8119\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4262 - acc: 0.7376 - val_loss: 0.4036 - val_acc: 0.8119\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3986 - acc: 0.8193 - val_loss: 0.4262 - val_acc: 0.8020\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4016 - acc: 0.8168 - val_loss: 0.4388 - val_acc: 0.8119\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4251 - acc: 0.7970 - val_loss: 0.5477 - val_acc: 0.6436\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4536 - acc: 0.7673 - val_loss: 0.4316 - val_acc: 0.8020\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4214 - acc: 0.7896 - val_loss: 0.4305 - val_acc: 0.8020\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4109 - acc: 0.7847 - val_loss: 0.4809 - val_acc: 0.7129\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4111 - acc: 0.8094 - val_loss: 0.4164 - val_acc: 0.8119\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3943 - acc: 0.7970 - val_loss: 0.4324 - val_acc: 0.8218\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4156 - acc: 0.7896 - val_loss: 0.4061 - val_acc: 0.8020\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4197 - acc: 0.7748 - val_loss: 0.3895 - val_acc: 0.8218\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4073 - acc: 0.8292 - val_loss: 0.5014 - val_acc: 0.6931\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3977 - acc: 0.7946 - val_loss: 0.3902 - val_acc: 0.8218\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3549 - acc: 0.8589 - val_loss: 0.4856 - val_acc: 0.6931\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4216 - acc: 0.7673 - val_loss: 0.4417 - val_acc: 0.8317\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3694 - acc: 0.8218 - val_loss: 0.3863 - val_acc: 0.8218\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3750 - acc: 0.8193 - val_loss: 0.3802 - val_acc: 0.8119\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3897 - acc: 0.8069 - val_loss: 0.3807 - val_acc: 0.8119\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3724 - acc: 0.8218 - val_loss: 0.3828 - val_acc: 0.8218\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4154 - acc: 0.7847 - val_loss: 0.4049 - val_acc: 0.8020\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.4362 - acc: 0.755 - 1s 1ms/step - loss: 0.4281 - acc: 0.7698 - val_loss: 0.3776 - val_acc: 0.8119\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3919 - acc: 0.8193 - val_loss: 0.4065 - val_acc: 0.8218\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3990 - acc: 0.7871 - val_loss: 0.3927 - val_acc: 0.8020\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3852 - acc: 0.8069 - val_loss: 0.3751 - val_acc: 0.8119\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3789 - acc: 0.8144 - val_loss: 0.3715 - val_acc: 0.8218\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3803 - acc: 0.8045 - val_loss: 0.4324 - val_acc: 0.8119\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3988 - acc: 0.7797 - val_loss: 0.4563 - val_acc: 0.7228\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3988 - acc: 0.8144 - val_loss: 0.3788 - val_acc: 0.8218\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3877 - acc: 0.7921 - val_loss: 0.3737 - val_acc: 0.8020\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3658 - acc: 0.8366 - val_loss: 0.4884 - val_acc: 0.6931\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4170 - acc: 0.7698 - val_loss: 0.3701 - val_acc: 0.8317\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3901 - acc: 0.7871 - val_loss: 0.3847 - val_acc: 0.7921\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3737 - acc: 0.8144 - val_loss: 0.3843 - val_acc: 0.8119\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3460 - acc: 0.8441 - val_loss: 0.4070 - val_acc: 0.8317\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3779 - acc: 0.8144 - val_loss: 0.3754 - val_acc: 0.8218\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3518 - acc: 0.8218 - val_loss: 0.3641 - val_acc: 0.8218\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3718 - acc: 0.8045 - val_loss: 0.3623 - val_acc: 0.8119\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3644 - acc: 0.8243 - val_loss: 0.4215 - val_acc: 0.8218\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3702 - acc: 0.8193 - val_loss: 0.3703 - val_acc: 0.8218\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3761 - acc: 0.8094 - val_loss: 0.3875 - val_acc: 0.8218\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3424 - acc: 0.8193 - val_loss: 0.3717 - val_acc: 0.8020\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4085 - acc: 0.7723 - val_loss: 0.3844 - val_acc: 0.8218\n",
      "[[65  9]\n",
      " [ 9 18]]\n",
      "[[65  9]\n",
      " [ 9 18]]\n",
      "results : acc = 0.667,rec = 0.822,f1 = 0.667,auc = 0.667,aupr = 0.899,auprc = 0.762\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 9s 23ms/step - loss: 0.6173 - acc: 0.7104 - val_loss: 0.6826 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6146 - acc: 0.7351 - val_loss: 0.6658 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6131 - acc: 0.7351 - val_loss: 0.6500 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6138 - acc: 0.7351 - val_loss: 0.6506 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6127 - acc: 0.7351 - val_loss: 0.6471 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6456 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6124 - acc: 0.7351 - val_loss: 0.6472 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6429 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6433 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6443 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6419 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6425 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6441 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6401 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6407 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6443 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6435 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6433 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6437 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6454 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6425 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6418 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6416 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6442 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6106 - acc: 0.7351 - val_loss: 0.6429 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6109 - acc: 0.7351 - val_loss: 0.6433 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6092 - acc: 0.7351 - val_loss: 0.6384 - val_acc: 0.7327\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6110 - acc: 0.7351 - val_loss: 0.6368 - val_acc: 0.7327\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6384 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6106 - acc: 0.7351 - val_loss: 0.6453 - val_acc: 0.7327\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6095 - acc: 0.7351 - val_loss: 0.6426 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6120 - acc: 0.7351 - val_loss: 0.6418 - val_acc: 0.7327\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6105 - acc: 0.7351 - val_loss: 0.6420 - val_acc: 0.7327\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6098 - acc: 0.7351 - val_loss: 0.6439 - val_acc: 0.7327\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6096 - acc: 0.7351 - val_loss: 0.6396 - val_acc: 0.7327\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6077 - acc: 0.7351 - val_loss: 0.6462 - val_acc: 0.7327\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6086 - acc: 0.7351 - val_loss: 0.6462 - val_acc: 0.7327\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6086 - acc: 0.7351 - val_loss: 0.6457 - val_acc: 0.7327\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6077 - acc: 0.7351 - val_loss: 0.6453 - val_acc: 0.7327\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6039 - acc: 0.7351 - val_loss: 0.6409 - val_acc: 0.7327\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6041 - acc: 0.7351 - val_loss: 0.6320 - val_acc: 0.7327\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6033 - acc: 0.7376 - val_loss: 0.6517 - val_acc: 0.7327\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6019 - acc: 0.7376 - val_loss: 0.6318 - val_acc: 0.7327\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5975 - acc: 0.7475 - val_loss: 0.6472 - val_acc: 0.7426\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.5958 - acc: 0.7401 - val_loss: 0.6145 - val_acc: 0.7327\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5887 - acc: 0.7426 - val_loss: 0.6229 - val_acc: 0.7426\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5854 - acc: 0.7599 - val_loss: 0.6271 - val_acc: 0.7525\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5808 - acc: 0.7624 - val_loss: 0.6265 - val_acc: 0.7525\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5776 - acc: 0.7624 - val_loss: 0.6237 - val_acc: 0.7525\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5734 - acc: 0.7475 - val_loss: 0.6356 - val_acc: 0.7129\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5691 - acc: 0.7426 - val_loss: 0.6075 - val_acc: 0.7624\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5537 - acc: 0.7104 - val_loss: 0.5680 - val_acc: 0.7525\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5551 - acc: 0.7500 - val_loss: 0.6136 - val_acc: 0.7228\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5392 - acc: 0.7327 - val_loss: 0.5983 - val_acc: 0.7426\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5165 - acc: 0.7550 - val_loss: 0.5465 - val_acc: 0.7525\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5222 - acc: 0.7475 - val_loss: 0.5502 - val_acc: 0.7624\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5078 - acc: 0.7995 - val_loss: 0.7268 - val_acc: 0.4356\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5672 - acc: 0.5990 - val_loss: 0.5241 - val_acc: 0.7624\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5086 - acc: 0.7847 - val_loss: 0.5797 - val_acc: 0.6931\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5073 - acc: 0.7376 - val_loss: 0.5750 - val_acc: 0.7129\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4996 - acc: 0.7129 - val_loss: 0.5238 - val_acc: 0.7624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5068 - acc: 0.7351 - val_loss: 0.5807 - val_acc: 0.6931\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4888 - acc: 0.7772 - val_loss: 0.6106 - val_acc: 0.5941\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5011 - acc: 0.7673 - val_loss: 0.5866 - val_acc: 0.6931\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4923 - acc: 0.7252 - val_loss: 0.5064 - val_acc: 0.7822\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.4610 - acc: 0.826 - 1s 1ms/step - loss: 0.4662 - acc: 0.8243 - val_loss: 0.5840 - val_acc: 0.7030\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4986 - acc: 0.6955 - val_loss: 0.5318 - val_acc: 0.7525\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4767 - acc: 0.7624 - val_loss: 0.4999 - val_acc: 0.7822\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4700 - acc: 0.7203 - val_loss: 0.4957 - val_acc: 0.7624\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4876 - acc: 0.7649 - val_loss: 0.7055 - val_acc: 0.5248\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5074 - acc: 0.7450 - val_loss: 0.4932 - val_acc: 0.7822\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4751 - acc: 0.7129 - val_loss: 0.4937 - val_acc: 0.7723\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4704 - acc: 0.7946 - val_loss: 0.5798 - val_acc: 0.7129\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4507 - acc: 0.7302 - val_loss: 0.4953 - val_acc: 0.7822\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4733 - acc: 0.7921 - val_loss: 0.5334 - val_acc: 0.7327\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4502 - acc: 0.8168 - val_loss: 0.5393 - val_acc: 0.7129\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4632 - acc: 0.7822 - val_loss: 0.5414 - val_acc: 0.7228\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4263 - acc: 0.7921 - val_loss: 0.4926 - val_acc: 0.7921\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4319 - acc: 0.8193 - val_loss: 0.4923 - val_acc: 0.7921\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4303 - acc: 0.7970 - val_loss: 0.4730 - val_acc: 0.7723\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4393 - acc: 0.7748 - val_loss: 0.4968 - val_acc: 0.7723\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4226 - acc: 0.7921 - val_loss: 0.5084 - val_acc: 0.7525\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4156 - acc: 0.8243 - val_loss: 0.4712 - val_acc: 0.7921\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4175 - acc: 0.7871 - val_loss: 0.5067 - val_acc: 0.7624\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4326 - acc: 0.8069 - val_loss: 0.5683 - val_acc: 0.6535\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4120 - acc: 0.7772 - val_loss: 0.4941 - val_acc: 0.7525\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4145 - acc: 0.8045 - val_loss: 0.4862 - val_acc: 0.7723\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3993 - acc: 0.8218 - val_loss: 0.4913 - val_acc: 0.7921\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4081 - acc: 0.7995 - val_loss: 0.5535 - val_acc: 0.6733\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4242 - acc: 0.7673 - val_loss: 0.4770 - val_acc: 0.8020\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4346 - acc: 0.7847 - val_loss: 0.4645 - val_acc: 0.8020\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4090 - acc: 0.8119 - val_loss: 0.4893 - val_acc: 0.7921\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4207 - acc: 0.7921 - val_loss: 0.5046 - val_acc: 0.7624\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3858 - acc: 0.8243 - val_loss: 0.4378 - val_acc: 0.7822\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3746 - acc: 0.8441 - val_loss: 0.4581 - val_acc: 0.8119\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3933 - acc: 0.8144 - val_loss: 0.4492 - val_acc: 0.8218\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3589 - acc: 0.8515 - val_loss: 0.4506 - val_acc: 0.8119\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3914 - acc: 0.8119 - val_loss: 0.4360 - val_acc: 0.8119\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3810 - acc: 0.8342 - val_loss: 0.4337 - val_acc: 0.7921\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3916 - acc: 0.8020 - val_loss: 0.4416 - val_acc: 0.8218\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3509 - acc: 0.8342 - val_loss: 0.4286 - val_acc: 0.8119\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4117 - acc: 0.8069 - val_loss: 0.4648 - val_acc: 0.8119\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3858 - acc: 0.8069 - val_loss: 0.5010 - val_acc: 0.7822\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3646 - acc: 0.8193 - val_loss: 0.4266 - val_acc: 0.8218\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4165 - acc: 0.7822 - val_loss: 0.4303 - val_acc: 0.8317\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3776 - acc: 0.8317 - val_loss: 0.4788 - val_acc: 0.7822\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4150 - acc: 0.7970 - val_loss: 0.4290 - val_acc: 0.8515\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3558 - acc: 0.8243 - val_loss: 0.4432 - val_acc: 0.8218\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3682 - acc: 0.8218 - val_loss: 0.4253 - val_acc: 0.8515\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3958 - acc: 0.7921 - val_loss: 0.4279 - val_acc: 0.8416\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3839 - acc: 0.8366 - val_loss: 0.4418 - val_acc: 0.8317\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3864 - acc: 0.8144 - val_loss: 0.4145 - val_acc: 0.8416\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3667 - acc: 0.8144 - val_loss: 0.4115 - val_acc: 0.8119\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3921 - acc: 0.7772 - val_loss: 0.4099 - val_acc: 0.8218\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3727 - acc: 0.8045 - val_loss: 0.4159 - val_acc: 0.8020\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3853 - acc: 0.8193 - val_loss: 0.4743 - val_acc: 0.7921\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3563 - acc: 0.8119 - val_loss: 0.4240 - val_acc: 0.8614\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3664 - acc: 0.8366 - val_loss: 0.5498 - val_acc: 0.6436\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3956 - acc: 0.7921 - val_loss: 0.4517 - val_acc: 0.8317\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3831 - acc: 0.7797 - val_loss: 0.4421 - val_acc: 0.7921\n",
      "[[73  1]\n",
      " [20  7]]\n",
      "[[73  1]\n",
      " [20  7]]\n",
      "results : acc = 0.875,rec = 0.792,f1 = 0.259,auc = 0.4,aupr = 0.859,auprc = 0.761\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h_0 (M_Nets)                 (None, 1542)              3084      \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 1542)              0         \n",
      "_________________________________________________________________\n",
      "h0 (Nets)                    (None, 550)               4844      \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "h1 (Nets)                    (None, 243)               1775      \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "h2 (Nets)                    (None, 115)               730       \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "h3 (Nets)                    (None, 51)                263       \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "h4 (Nets)                    (None, 18)                87        \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 101 samples\n",
      "Epoch 1/120\n",
      "404/404 [==============================] - 9s 23ms/step - loss: 0.6164 - acc: 0.6436 - val_loss: 0.6727 - val_acc: 0.7327\n",
      "Epoch 2/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6539 - val_acc: 0.7327\n",
      "Epoch 3/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6130 - acc: 0.7351 - val_loss: 0.6440 - val_acc: 0.7327\n",
      "Epoch 4/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6405 - val_acc: 0.7327\n",
      "Epoch 5/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6117 - acc: 0.7351 - val_loss: 0.6429 - val_acc: 0.7327\n",
      "Epoch 6/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6123 - acc: 0.7351 - val_loss: 0.6375 - val_acc: 0.7327\n",
      "Epoch 7/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6120 - acc: 0.7351 - val_loss: 0.6408 - val_acc: 0.7327\n",
      "Epoch 8/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6114 - acc: 0.7351 - val_loss: 0.6451 - val_acc: 0.7327\n",
      "Epoch 9/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6441 - val_acc: 0.7327\n",
      "Epoch 10/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6444 - val_acc: 0.7327\n",
      "Epoch 11/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.6115 - acc: 0.7351 - val_loss: 0.6428 - val_acc: 0.7327\n",
      "Epoch 12/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6425 - val_acc: 0.7327\n",
      "Epoch 13/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6126 - acc: 0.7351 - val_loss: 0.6445 - val_acc: 0.7327\n",
      "Epoch 14/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6143 - acc: 0.7351 - val_loss: 0.6525 - val_acc: 0.7327\n",
      "Epoch 15/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6120 - acc: 0.7351 - val_loss: 0.6453 - val_acc: 0.7327\n",
      "Epoch 16/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6424 - val_acc: 0.7327\n",
      "Epoch 17/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6107 - acc: 0.7351 - val_loss: 0.6426 - val_acc: 0.7327\n",
      "Epoch 18/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6120 - acc: 0.7351 - val_loss: 0.6464 - val_acc: 0.7327\n",
      "Epoch 19/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6111 - acc: 0.7351 - val_loss: 0.6419 - val_acc: 0.7327\n",
      "Epoch 20/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6121 - acc: 0.7351 - val_loss: 0.6430 - val_acc: 0.7327\n",
      "Epoch 21/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6118 - acc: 0.7351 - val_loss: 0.6463 - val_acc: 0.7327\n",
      "Epoch 22/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6108 - acc: 0.7351 - val_loss: 0.6469 - val_acc: 0.7327\n",
      "Epoch 23/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6119 - acc: 0.7351 - val_loss: 0.6466 - val_acc: 0.7327\n",
      "Epoch 24/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6116 - acc: 0.7351 - val_loss: 0.6442 - val_acc: 0.7327\n",
      "Epoch 25/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6470 - val_acc: 0.7327\n",
      "Epoch 26/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6099 - acc: 0.7351 - val_loss: 0.6442 - val_acc: 0.7327\n",
      "Epoch 27/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6449 - val_acc: 0.7327\n",
      "Epoch 28/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6112 - acc: 0.7351 - val_loss: 0.6491 - val_acc: 0.7327\n",
      "Epoch 29/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6113 - acc: 0.7351 - val_loss: 0.6414 - val_acc: 0.7327\n",
      "Epoch 30/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6089 - acc: 0.7351 - val_loss: 0.6429 - val_acc: 0.7327\n",
      "Epoch 31/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6098 - acc: 0.7351 - val_loss: 0.6518 - val_acc: 0.7327\n",
      "Epoch 32/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6081 - acc: 0.7351 - val_loss: 0.6427 - val_acc: 0.7327\n",
      "Epoch 33/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6084 - acc: 0.7351 - val_loss: 0.6501 - val_acc: 0.7327\n",
      "Epoch 34/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6058 - acc: 0.7351 - val_loss: 0.6342 - val_acc: 0.7327\n",
      "Epoch 35/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6053 - acc: 0.7351 - val_loss: 0.6356 - val_acc: 0.7327\n",
      "Epoch 36/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6033 - acc: 0.7376 - val_loss: 0.6525 - val_acc: 0.7327\n",
      "Epoch 37/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.6012 - acc: 0.7450 - val_loss: 0.6378 - val_acc: 0.7327\n",
      "Epoch 38/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5964 - acc: 0.7475 - val_loss: 0.6406 - val_acc: 0.7327\n",
      "Epoch 39/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5942 - acc: 0.7376 - val_loss: 0.6255 - val_acc: 0.7327\n",
      "Epoch 40/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5851 - acc: 0.7525 - val_loss: 0.6690 - val_acc: 0.7129\n",
      "Epoch 41/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5912 - acc: 0.6955 - val_loss: 0.6138 - val_acc: 0.7327\n",
      "Epoch 42/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.7376 - val_loss: 0.6319 - val_acc: 0.7525\n",
      "Epoch 43/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5777 - acc: 0.7599 - val_loss: 0.6035 - val_acc: 0.7426\n",
      "Epoch 44/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5761 - acc: 0.7649 - val_loss: 0.6300 - val_acc: 0.7624\n",
      "Epoch 45/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5697 - acc: 0.6832 - val_loss: 0.6166 - val_acc: 0.7624\n",
      "Epoch 46/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5626 - acc: 0.7500 - val_loss: 0.6027 - val_acc: 0.7624\n",
      "Epoch 47/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5550 - acc: 0.7450 - val_loss: 0.6034 - val_acc: 0.7624\n",
      "Epoch 48/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5484 - acc: 0.7376 - val_loss: 0.6476 - val_acc: 0.6535\n",
      "Epoch 49/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5413 - acc: 0.6906 - val_loss: 0.6105 - val_acc: 0.7426\n",
      "Epoch 50/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5266 - acc: 0.7153 - val_loss: 0.5386 - val_acc: 0.7525\n",
      "Epoch 51/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5469 - acc: 0.7054 - val_loss: 0.6686 - val_acc: 0.4257\n",
      "Epoch 52/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5172 - acc: 0.7599 - val_loss: 0.5542 - val_acc: 0.7723\n",
      "Epoch 53/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5018 - acc: 0.7649 - val_loss: 0.5670 - val_acc: 0.7525\n",
      "Epoch 54/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4951 - acc: 0.7525 - val_loss: 0.5832 - val_acc: 0.7525\n",
      "Epoch 55/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5039 - acc: 0.7871 - val_loss: 0.5625 - val_acc: 0.7525\n",
      "Epoch 56/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4974 - acc: 0.7327 - val_loss: 0.5221 - val_acc: 0.7624\n",
      "Epoch 57/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5357 - acc: 0.6881 - val_loss: 0.5530 - val_acc: 0.7525\n",
      "Epoch 58/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5039 - acc: 0.7822 - val_loss: 0.6582 - val_acc: 0.4851\n",
      "Epoch 59/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4988 - acc: 0.7252 - val_loss: 0.5497 - val_acc: 0.7525\n",
      "Epoch 60/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5039 - acc: 0.7203 - val_loss: 0.5031 - val_acc: 0.7822\n",
      "Epoch 61/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4638 - acc: 0.7228 - val_loss: 0.5005 - val_acc: 0.7822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4741 - acc: 0.7772 - val_loss: 0.5413 - val_acc: 0.7624\n",
      "Epoch 63/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4652 - acc: 0.7995 - val_loss: 0.5773 - val_acc: 0.7228\n",
      "Epoch 64/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4979 - acc: 0.7277 - val_loss: 0.5727 - val_acc: 0.7228\n",
      "Epoch 65/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4633 - acc: 0.7351 - val_loss: 0.4798 - val_acc: 0.7921\n",
      "Epoch 66/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4747 - acc: 0.7574 - val_loss: 0.5519 - val_acc: 0.7426\n",
      "Epoch 67/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4511 - acc: 0.8267 - val_loss: 0.5029 - val_acc: 0.7822\n",
      "Epoch 68/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4666 - acc: 0.7178 - val_loss: 0.4736 - val_acc: 0.7921\n",
      "Epoch 69/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.5025 - acc: 0.7450 - val_loss: 0.6933 - val_acc: 0.4752\n",
      "Epoch 70/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4713 - acc: 0.7748 - val_loss: 0.4898 - val_acc: 0.7624\n",
      "Epoch 71/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4346 - acc: 0.8094 - val_loss: 0.5580 - val_acc: 0.7228\n",
      "Epoch 72/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4433 - acc: 0.7822 - val_loss: 0.5284 - val_acc: 0.7624\n",
      "Epoch 73/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4091 - acc: 0.8218 - val_loss: 0.4679 - val_acc: 0.7723\n",
      "Epoch 74/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4408 - acc: 0.7896 - val_loss: 0.4684 - val_acc: 0.7822\n",
      "Epoch 75/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4574 - acc: 0.8020 - val_loss: 0.5712 - val_acc: 0.6733\n",
      "Epoch 76/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4310 - acc: 0.7772 - val_loss: 0.4765 - val_acc: 0.7624\n",
      "Epoch 77/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3991 - acc: 0.8168 - val_loss: 0.5412 - val_acc: 0.7327\n",
      "Epoch 78/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4512 - acc: 0.7525 - val_loss: 0.4601 - val_acc: 0.7723\n",
      "Epoch 79/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4018 - acc: 0.7946 - val_loss: 0.5165 - val_acc: 0.7723\n",
      "Epoch 80/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4268 - acc: 0.7772 - val_loss: 0.4535 - val_acc: 0.7822\n",
      "Epoch 81/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4125 - acc: 0.7698 - val_loss: 0.4424 - val_acc: 0.8020\n",
      "Epoch 82/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4699 - acc: 0.7351 - val_loss: 0.5428 - val_acc: 0.7030\n",
      "Epoch 83/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3951 - acc: 0.8366 - val_loss: 0.4793 - val_acc: 0.8020\n",
      "Epoch 84/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4020 - acc: 0.8292 - val_loss: 0.4383 - val_acc: 0.8020\n",
      "Epoch 85/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4151 - acc: 0.8094 - val_loss: 0.4670 - val_acc: 0.7822\n",
      "Epoch 86/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4194 - acc: 0.7797 - val_loss: 0.4997 - val_acc: 0.7723\n",
      "Epoch 87/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3775 - acc: 0.8441 - val_loss: 0.4517 - val_acc: 0.7822\n",
      "Epoch 88/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3914 - acc: 0.8342 - val_loss: 0.4511 - val_acc: 0.7822\n",
      "Epoch 89/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4075 - acc: 0.7624 - val_loss: 0.4300 - val_acc: 0.7822\n",
      "Epoch 90/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3949 - acc: 0.7995 - val_loss: 0.4977 - val_acc: 0.7426\n",
      "Epoch 91/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4039 - acc: 0.7822 - val_loss: 0.5370 - val_acc: 0.6931\n",
      "Epoch 92/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4224 - acc: 0.7871 - val_loss: 0.4296 - val_acc: 0.7822\n",
      "Epoch 93/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3828 - acc: 0.8045 - val_loss: 0.4649 - val_acc: 0.7723\n",
      "Epoch 94/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3488 - acc: 0.8193 - val_loss: 0.4194 - val_acc: 0.7921\n",
      "Epoch 95/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3763 - acc: 0.8292 - val_loss: 0.4303 - val_acc: 0.7723\n",
      "Epoch 96/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3689 - acc: 0.8218 - val_loss: 0.4446 - val_acc: 0.7723\n",
      "Epoch 97/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3757 - acc: 0.8366 - val_loss: 0.4874 - val_acc: 0.7426\n",
      "Epoch 98/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3726 - acc: 0.8168 - val_loss: 0.4173 - val_acc: 0.8020\n",
      "Epoch 99/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3549 - acc: 0.8292 - val_loss: 0.4149 - val_acc: 0.7921\n",
      "Epoch 100/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3388 - acc: 0.8441 - val_loss: 0.4129 - val_acc: 0.7822\n",
      "Epoch 101/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3867 - acc: 0.8168 - val_loss: 0.4125 - val_acc: 0.7822\n",
      "Epoch 102/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3904 - acc: 0.8069 - val_loss: 0.4126 - val_acc: 0.7822\n",
      "Epoch 103/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3502 - acc: 0.8564 - val_loss: 0.4597 - val_acc: 0.7723\n",
      "Epoch 104/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3407 - acc: 0.8342 - val_loss: 0.4632 - val_acc: 0.7426\n",
      "Epoch 105/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3915 - acc: 0.7970 - val_loss: 0.4781 - val_acc: 0.7426\n",
      "Epoch 106/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3654 - acc: 0.8441 - val_loss: 0.6454 - val_acc: 0.5743\n",
      "Epoch 107/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4164 - acc: 0.7673 - val_loss: 0.4068 - val_acc: 0.7822\n",
      "Epoch 108/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4085 - acc: 0.7772 - val_loss: 0.4197 - val_acc: 0.8218\n",
      "Epoch 109/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4100 - acc: 0.7921 - val_loss: 0.4061 - val_acc: 0.7822\n",
      "Epoch 110/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3578 - acc: 0.8515 - val_loss: 0.4852 - val_acc: 0.7426\n",
      "Epoch 111/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3483 - acc: 0.8342 - val_loss: 0.4080 - val_acc: 0.7822\n",
      "Epoch 112/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3524 - acc: 0.8490 - val_loss: 0.4079 - val_acc: 0.7723\n",
      "Epoch 113/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3701 - acc: 0.8243 - val_loss: 0.4039 - val_acc: 0.7921\n",
      "Epoch 114/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3697 - acc: 0.7649 - val_loss: 0.4099 - val_acc: 0.8119\n",
      "Epoch 115/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.4472 - acc: 0.7649 - val_loss: 0.4255 - val_acc: 0.7921\n",
      "Epoch 116/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3378 - acc: 0.8564 - val_loss: 0.4207 - val_acc: 0.8020\n",
      "Epoch 117/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3852 - acc: 0.8366 - val_loss: 0.4046 - val_acc: 0.7921\n",
      "Epoch 118/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3381 - acc: 0.8441 - val_loss: 0.4134 - val_acc: 0.7921\n",
      "Epoch 119/120\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 0.3091 - acc: 0.8639 - val_loss: 0.4029 - val_acc: 0.7921\n",
      "Epoch 120/120\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 0.3825 - acc: 0.7946 - val_loss: 0.4017 - val_acc: 0.7822\n",
      "[[70  4]\n",
      " [18  9]]\n",
      "[[70  4]\n",
      " [18  9]]\n",
      "results : acc = 0.692,rec = 0.782,f1 = 0.333,auc = 0.45,aupr = 0.855,auprc = 0.71\n",
      "average value : acc = 0.768,rec = 0.806,f1 = 0.41,auc = 0.515,aupr = 0.889,auprc = 0.769\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590)\n",
    "\n",
    "# random.seed(5)\n",
    "# total_score = []\n",
    "# for i in range(0,5):\n",
    "kfscore = []\n",
    "for train_index, test_index in skf.split(single_x, single_y):\n",
    "    X_train, X_test = single_x[train_index], single_x[test_index]\n",
    "    y_train, y_test = single_y[train_index], single_y[test_index]\n",
    "\n",
    "    single_model = create_model(single_x)\n",
    "\n",
    "    single_model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=120,class_weight={0:0.68,1:1.48},batch_size = 32)  #epochs=50,class_weight={0:0.5,1:1.35},batch_size = 64\n",
    "    y_pred = single_model.predict(X_test)\n",
    "    kfscore.append(evaluates(y_test, y_pred))\n",
    "    results = evaluates(y_test, y_pred)\n",
    "    print(\"results : acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(results[0],3),round(results[1],3),round(results[2],3),round(results[3],3),round(results[4],3),round(results[5],3)))\n",
    "\n",
    "\n",
    "#average\n",
    "kfscores = np.array(kfscore).sum(axis= 0)/5.0\n",
    "print(\"average value : acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(kfscores[0],3),round(kfscores[1],3),round(kfscores[2],3),round(kfscores[3],3),round(kfscores[4],3),round(kfscores[5],3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other omics integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_amp = Omics_data.swaplevel(i=0, j=1, axis=1)[['snv_data','cnv_amp']].swaplevel(i=0, j=1, axis=1)\n",
    "snv_amp_order = snv_amp.columns.levels[0]\n",
    "snv_amp = snv_amp.reindex(columns=snv_amp_order, level=0)\n",
    "multi_x  = snv_amp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590) \n",
    "kfscore = []\n",
    "for train_index, test_index in skf.split(multi_x, y):\n",
    "\n",
    "    X_train, X_test = multi_x[train_index], multi_x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = create_model(multi_x)\n",
    "\n",
    "    model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=120,class_weight={0:0.68,1:1.48},batch_size = 32)  #epochs=50,class_weight={0:0.5,1:1.35},batch_size = 64\n",
    "    y_pred = model.predict(X_test)\n",
    "    kfscore.append(evaluates(y_test, y_pred))\n",
    "    results = evaluates(y_test, y_pred)\n",
    "    print(\"results : acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(results[0],3),round(results[1],3),round(results[2],3),round(results[3],3),round(results[4],3),round(results[5],3)))\n",
    "\n",
    "    \n",
    "kfscores = np.array(kfscore).sum(axis= 0)/5.0\n",
    "print(\"average value : acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(kfscores[0],3),round(kfscores[1],3),round(kfscores[2],3),round(kfscores[3],3),round(kfscores[4],3),round(kfscores[5],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_del = Omics_data.swaplevel(i=0, j=1, axis=1)[['snv_data','cnv_del']].swaplevel(i=0, j=1, axis=1)\n",
    "snv_del_order = snv_del.columns.levels[0]\n",
    "snv_del = snv_del.reindex(columns=snv_del_order, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_del_x  = snv_del.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590) #,shuffle=True\n",
    "\n",
    "\n",
    "total_score  = []\n",
    "for i in range(0,5):\n",
    "    kfscore = []\n",
    "    for train_index, test_index in skf.split(snv_del_x, y):\n",
    "\n",
    "        X_train, X_test = snv_del_x[train_index], snv_del_x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = create_model(snv_del_x)\n",
    "\n",
    "\n",
    "\n",
    "        model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=120,class_weight={0:0.68,1:1.48},batch_size = 32)  #epochs=50,class_weight={0:0.5,1:1.35},batch_size = 64\n",
    "        y_pred = model.predict(X_test)\n",
    "        kfscore.append(evaluates(y_test, y_pred))\n",
    "        print(evaluates(y_test, y_pred))\n",
    "\n",
    "        temp_pd =pd.DataFrame()\n",
    "        temp_pd['sample'] = sample_pro.loc[test_index]['sample'].values\n",
    "\n",
    "        temp_pd['values'] = y_pred\n",
    "\n",
    "        total_pd = pd.concat([total_pd,temp_pd],axis=0)\n",
    "\n",
    "    kfscore = np.array(kfscore).sum(axis= 0)/5.0\n",
    "    total_score.append(kfscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0:x_0,1:x_1}\n",
    "compare_models = [\n",
    "    {\n",
    "        'type': 'sgd',\n",
    "        'id': 'L2 Logistic Regression',\n",
    "        'params': {'loss': 'log', 'penalty': 'l2', 'alpha': 0.01, 'class_weight': class_weight}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'svc',\n",
    "        'id': 'RBF Support Vector Machine ',\n",
    "        'params': {'kernel': 'rbf', 'gamma': 0.001, 'probability': True, 'class_weight': class_weight}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'svc', 'id':\n",
    "        'Linear Support Vector Machine ',\n",
    "        'params': { 'kernel': 'linear','C': 0.1, 'probability': True, 'class_weight': class_weight}  \n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'random_forest',\n",
    "        'id': 'Random Forest',\n",
    "        'params': {'max_depth': None, 'n_estimators': 50, 'bootstrap': False, 'class_weight': class_weight}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'adaboost',\n",
    "        'id': 'Adaptive Boosting',\n",
    "        'params': {'learning_rate': 0.1, 'n_estimators': 50}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'decision_tree',\n",
    "        'id': 'Decision Tree',\n",
    "        'params': {'min_samples_split': 10, 'max_depth': 10}\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_score,pre_score,pre_probe):\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_score, pre_probe, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    aupr = average_precision_score(true_score, pre_probe)\n",
    "    \n",
    "    precision1, recall1, thresholds = precision_recall_curve(true_score, pre_probe)    \n",
    "    auprc  = metrics.auc(recall1, precision1)\n",
    "    \n",
    "    accuracy = accuracy_score(true_score,pre_score)\n",
    "    \n",
    "    f1 = metrics.f1_score(true_score, pre_score)\n",
    "    \n",
    "    precision = metrics.precision_score(true_score,pre_score)\n",
    "    \n",
    "    recall = metrics.recall_score(true_score,pre_score)\n",
    "    \n",
    "    return accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def Creat_SGD(whole_data_x,whole_data_y,train_index,test_index):\n",
    "    \n",
    "    model = SGDClassifier(**compare_models[0]['params'] )  \n",
    "    \n",
    "    model.fit(whole_data_x[train_index],whole_data_y[train_index] )  \n",
    "    \n",
    "    true_score = whole_data_y[test_index] \n",
    "    \n",
    "    pre_score = model.predict(whole_data_x[test_index]) \n",
    "    \n",
    "    pre_probe = model.predict_proba(whole_data_x[test_index])[:, 1] \n",
    "    \n",
    "\n",
    "    accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) \n",
    "    \n",
    "    return accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def Creat_RDF(whole_data_x,whole_data_y,train_index,test_index):\n",
    "     \n",
    "    model = RandomForestClassifier(**compare_models[3]['params'])  \n",
    "\n",
    "    model.fit(whole_data_x[train_index],whole_data_y[train_index] )  \n",
    "    \n",
    "    true_score = whole_data_y[test_index] \n",
    "    \n",
    "    pre_score = model.predict(whole_data_x[test_index]) \n",
    "    \n",
    "    pre_probe = model.predict_proba(whole_data_x[test_index])[:, 1] \n",
    "    \n",
    "\n",
    "    accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) \n",
    "    \n",
    "    return accuracy,recall,f1,auc,aupr,auprc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def Creat_LR(whole_data_x,whole_data_y,train_index,test_index):\n",
    "    \n",
    "    model =  LogisticRegression() \n",
    "\n",
    "    model.fit(whole_data_x[train_index],whole_data_y[train_index] )  \n",
    "    \n",
    "    true_score = whole_data_y[test_index] \n",
    "    \n",
    "    pre_score = model.predict(whole_data_x[test_index]) \n",
    "    \n",
    "    pre_probe = model.predict_proba(whole_data_x[test_index])[:, 1] \n",
    "    \n",
    "\n",
    "    accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) \n",
    "    \n",
    "    return accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import tree\n",
    " \n",
    "def Creat_DTC(whole_data_x,whole_data_y,train_index,test_index):\n",
    "    \n",
    "    DTC_model = tree.DecisionTreeClassifier() \n",
    "    \n",
    "    DTC_model.fit(whole_data_x[train_index],whole_data_y[train_index] )  \n",
    "    \n",
    "    true_score = whole_data_y[test_index] \n",
    "    \n",
    "    pre_score = DTC_model.predict(whole_data_x[test_index]) \n",
    "    \n",
    "    pre_probe = DTC_model.predict_proba(whole_data_x[test_index])[:, 1] \n",
    "    \n",
    "\n",
    "    accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) \n",
    "    \n",
    "    return accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "\n",
    "def Creat_RBFSVM(whole_data_x,whole_data_y,train_index,test_index):\n",
    "\n",
    "    RBFSVM = NuSVC(**compare_models[1]['params'])\n",
    "\n",
    "    RBFSVM.fit(whole_data_x[train_index],whole_data_y[train_index] )  \n",
    "    \n",
    "    true_score = whole_data_y[test_index] \n",
    "    \n",
    "    pre_score = RBFSVM.predict(whole_data_x[test_index]) \n",
    "    \n",
    "    pre_probe = RBFSVM.predict_proba(whole_data_x[test_index])[:, 1] \n",
    "    \n",
    "\n",
    "    accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) \n",
    "    \n",
    "    return accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "\n",
    "def Creat_LinearSVC(whole_data_x,whole_data_y,train_index,test_index):\n",
    "\n",
    "    LSVC = SVC(**compare_models[2]['params'])\n",
    "\n",
    "    LSVC.fit(whole_data_x[train_index],whole_data_y[train_index] )  \n",
    "    \n",
    "    true_score = whole_data_y[test_index] \n",
    "    \n",
    "    pre_score = LSVC.predict(whole_data_x[test_index]) \n",
    "    \n",
    "    pre_probe = LSVC.predict_proba(whole_data_x[test_index])[:, 1] \n",
    "    \n",
    "\n",
    "    accuracy,recall,f1,auc,aupr,auprc = get_metrics(true_score,pre_score,pre_probe) \n",
    "    return accuracy,recall,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6831683168316832, 0.34615384615384615, 0.35999999999999993, 0.5779487179487179, 0.30730105139969904, 0.43484189530585327]\n",
      "[0.6336633663366337, 0.4074074074074074, 0.37288135593220334, 0.5395395395395396, 0.3023724579904799, 0.43969968805391185]\n",
      "[0.7425742574257426, 0.37037037037037035, 0.43478260869565216, 0.6243743743743744, 0.36324860556231064, 0.5325014957636114]\n",
      "[0.594059405940594, 0.3333333333333333, 0.3050847457627119, 0.5708208208208208, 0.29117892163612497, 0.42198795664590616]\n",
      "[0.6633663366336634, 0.3333333333333333, 0.34615384615384615, 0.5580580580580581, 0.30446924057485114, 0.4258148672010058]\n",
      "average value : acc = 0.663,rec = 0.358,f1 = 0.364,auc = 0.574,aupr = 0.314,auprc = 0.451\n"
     ]
    }
   ],
   "source": [
    "#Comparison algorithm five-fold cross-validation\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=10590) #,random_state=10590\n",
    "\n",
    "kfscore = []\n",
    "\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "         \n",
    "    score = list(Creat_DTC(x,y,train_index,test_index))\n",
    "    print(score)                        \n",
    "    kfscore.append(score)\n",
    "                                             \n",
    "\n",
    "kfscores = np.array(kfscore).sum(axis= 0)/5.0     \n",
    "print(\"average value : acc = {},rec = {},f1 = {},auc = {},aupr = {},auprc = {}\".format(round(kfscores[0],3),round(kfscores[1],3),round(kfscores[2],3),round(kfscores[3],3),round(kfscores[4],3),round(kfscores[5],3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnet",
   "language": "python",
   "name": "pnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
